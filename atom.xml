<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YYGCui</title>
  <icon>https://www.gravatar.com/avatar/8623bca8bca8b2403fc46e7694f4b7f0</icon>
  <subtitle>思考自然的本性，抚摸上帝的脉搏</subtitle>
  <link href="http://blog.cuicc.com/atom.xml" rel="self"/>
  
  <link href="http://blog.cuicc.com/"/>
  <updated>2021-12-11T15:07:34.559Z</updated>
  <id>http://blog.cuicc.com/</id>
  
  <author>
    <name>YYGCui</name>
    <email>yygcui@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>记一次内存泄漏定位</title>
    <link href="http://blog.cuicc.com/blog/2021/12/10/checking-for-mem-leaks/"/>
    <id>http://blog.cuicc.com/blog/2021/12/10/checking-for-mem-leaks/</id>
    <published>2021-12-10T14:21:44.000Z</published>
    <updated>2021-12-11T15:07:34.559Z</updated>
    
    <content type="html"><![CDATA[<p>最近测试时发现，运行相对较长一段时间后进程因内存使用超过配额上限而被杀掉，这应该是内存缓慢增长导致的，也就是说出现了内存泄漏。这个进程代码是用C++实现的，且基本没有使用<code>malloc/free</code>, <code>new/delete</code>等显式的内存申请释放，但代码中大量使用了标准库的容器类。这种因为业务逻辑导致容器没有清除导致的内存泄露，之前一直没有找到很好的定位手段，已知的工具<code>valgrind</code>貌似不能用来定位这种方式的泄露。</p><p>通过内外网搜索，找到了一些基于内存采样的分析工具，如<code>google-perftools</code>里的<code>tcmalloc</code>，及<code>bytehound</code>，本文主要记录下使用<code>tcmalloc</code>定位内存泄漏的方法。</p><h2 id="google-perftools"><a class="header-anchor" href="#google-perftools"></a>google-perftools</h2><p><a href="https://github.com/gperftools/gperftools">google-perftools</a>是Google开源的一个高性能的多线程的<code>malloc</code>实现集，号称当前最快的<code>malloc</code>，使用它可以提高内存访问性能，在我们的测试中，有大约单核10%的CPU性能提升。同时，它还集成了<code>heap-checker</code>，<code>heap-profiler</code>，<code>cpu-profiler</code>等内存和cpu检查<a href="https://github.com/gperftools/gperftools/wiki">分析工具</a>。这里主要使用<code>heap-profiler</code>来定位内存泄漏问题。</p><h3 id="tcmalloc库"><a class="header-anchor" href="#tcmalloc库"></a>tcmalloc库</h3><p>ubuntu上可以直接通过<code>apt</code>安装</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install -y google-perftools</span><br><span class="line"></span><br><span class="line"># 相关路径如下</span><br><span class="line"># /usr/bin/google-pprof</span><br><span class="line"># /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4</span><br></pre></td></tr></table></figure><p>有两种方式来使用tcmalloc库，一种是在编译时链接，然后运行时通过环境变量启用不同的工具，官方wiki看起来是推荐这种方式的。命令如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc [...] -o myprogram -ltcmalloc</span><br><span class="line"># HEAPPROFILE设置输出分析文件的前缀</span><br><span class="line">HEAPPROFILE=/tmp/myprogram ./myprogram</span><br></pre></td></tr></table></figure><p>另一种方式是通过<code>PRELOAD</code>的方式优先加载该动态链接库，好处是它不用重新编译代码，且可以覆盖该程序及其他在此之后链接库里的相同函数实现，实现全局使用的目的。命令如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">env LD_PRELOAD=&quot;/usr/lib/libtcmalloc.so&quot; HEAPPROFILE=/tmp/myprogram ./myprogram</span><br></pre></td></tr></table></figure><h3 id="内存分析"><a class="header-anchor" href="#内存分析"></a>内存分析</h3><p>通过上述启动程序后，每隔10s钟会在指定的输出路径输出内存采样文件，如<code>/tmp/myprogram.0001.heap</code>。通过一个简单的示例程序看下其过程。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># test.cpp</span><br><span class="line">#include &lt;vector&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;cstdlib&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void test() &#123;</span><br><span class="line">    vector&lt;int&gt; testv;</span><br><span class="line">    for (int i = 0; i &lt; 10000; i++) &#123;</span><br><span class="line">        testv.push_back(i);</span><br><span class="line">    &#125;</span><br><span class="line">    # 退出不释放内存</span><br><span class="line">    exit(1);</span><br><span class="line">&#125;</span><br><span class="line">int main(void) &#123;</span><br><span class="line">    test();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该示例通过<code>vector</code>申请了<code>10000*sizeof(int)</code>大小左右的内存，然后没有释放。编译并预加载<code>tcmalloc</code>执行。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ test.cpp -o test</span><br><span class="line">env LD_PRELOAD=&quot;/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4&quot; HEAPPROFILE=/tmp/test ./test</span><br><span class="line"># 执行完成后看到以下文件</span><br><span class="line">/tmp/test.0001.heap</span><br></pre></td></tr></table></figure><p>使用<code>google-pprof</code>查看可以该文件，通过不同的参数可以指定显示方式，甚至web显示也可以。比如用<code>--test</code>参数显示成文本，用<code>--gv</code>或者<code>--pdf</code>可以图形化显示，如这里存到pdf文件中。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ google-pprof --pdf test /tmp/test.0001.heap &gt; test.0001.heap.pdf</span><br></pre></td></tr></table></figure><p>通过下图可以直观的看到<code>test</code>函数<code>alloc</code>了内存，没有<code>dealloc</code>过。</p><p><img src="/images/test-0001-heap-pdf.png" alt=""></p><h3 id="内存泄漏定位"><a class="header-anchor" href="#内存泄漏定位"></a>内存泄漏定位</h3><p>那么，在复杂的程序中，既有申请又有释放，内存一直缓慢增长该怎么取分析定位呢？如果直接查看单个文件，并无法说明内存只有申请没有释放。这里会用到<code>pprof</code>比较两个heap文件查看差异的方法。比如运行相对较长时间程序，获得了<code>myprogram.0001.heap ... myprogram.0234.heap</code> 这些采样数据，同时通过观察进程内存在这段时间内明显增长。可以通过以下命令对比两个文件：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ google-pprof --pdf --base /tmp/test.0010.heap test /tmp/test.0234.heap &gt; test.compare.pdf</span><br></pre></td></tr></table></figure><p>生成的pdf和上图类似，不同点在于该pdf中显示的相对值，就是0234申请的内存减去0010申请的值。可以直观的看到哪些函数相对申请了占比大的内存，大大缩小了排查范围，然后通过阅读这些函数就可以找到具体哪些容器存在未清除的问题，比如没有<code>clear</code>或<code>erase</code>。</p><p>这里取第0010个heap文件是因为程序前期初始化等申请一些内存，这部分先排除在外，避免大量定位。这里可以灵活运用，比如可以先看单个文件哪些申请了大量内存再做比较。</p><h2 id="bytehound"><a class="header-anchor" href="#bytehound"></a>bytehound</h2><p><a href="https://github.com/koute/bytehound">bytehound</a>是一款<code>Linux</code>平台的内存分析工具，具有丰富的前端界面，可以看趋势图、火焰图、内存申请调用栈等等。与上面不同的是它通过续写的方式生成一个<code>.dat</code>文件。</p><p>它的缺点是生成的文件非常大，从笔者的测试看，该文件一分钟增加2G左右，对于缓慢增长来说，运行几个小时文件大小吃不消。再者，虽然火焰图比较直观可以看出内存热点(类似cpu性能热点分析)，但是没有内存申请比较，不太容易缩小排查范围。</p><p>因为生成文件太大的问题，没有详细使用该工具，如有兴趣，可以参考他的<a href="https://koute.github.io/bytehound/">详细文档</a></p><h2 id="扩展资料"><a class="header-anchor" href="#扩展资料"></a>扩展资料</h2><ol><li><a href="https://github.com/gperftools/gperftools/wiki">google-perftools官方wiki</a> - 官方wiki对该工具各方面都有详尽的说明，想了解其他功能细节可以参看</li><li><a href="https://segmentfault.com/a/1190000040982400">内存泄漏的定位与排查：Heap Profiling 原理解析</a> - 该文章详细介绍了<code>heap profile</code>的原理，主流工具<code>profile</code>的实现细节等，该文中还提到了<code> gprof, Valgrind and gperftools</code>等工具评估链接，对于想了解原理的同学建议阅读。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近测试时发现，运行相对较长一段时间后进程因内存使用超过配额上限而被杀掉，这应该是内存缓慢增长导致的，也就是说出现了内存泄漏。这个进程代码是用C++实现的，且基本没有使用&lt;code&gt;malloc/free&lt;/code&gt;, &lt;code&gt;new/delete&lt;/code&gt;等显式</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="C/C++" scheme="http://blog.cuicc.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>线程池并行化重构</title>
    <link href="http://blog.cuicc.com/blog/2021/12/03/refactor-in-parallel-with-multi-threads/"/>
    <id>http://blog.cuicc.com/blog/2021/12/03/refactor-in-parallel-with-multi-threads/</id>
    <published>2021-12-03T14:24:56.000Z</published>
    <updated>2021-12-04T15:00:01.904Z</updated>
    
    <content type="html"><![CDATA[<p>最近业务新特性开发，由原来的单个action变成了多个action，最后取一个最优action。由于action变多，运行时间也相应多了几倍，action之间是相互独立，互不影响的，那么就想通过并行化的方法提升下性能，这个时候自然而然就想到了线程池。本文记录一下此次并行化重构业务代码时遇到的一些有意思的点。</p><h2 id="线程池"><a class="header-anchor" href="#线程池"></a>线程池</h2><p>模块中本来就包含线程框架，可以适当修改支持线程池，这里没啥大问题。业务代码action处理函数的改造主要在于函数输出，由原来的串行执行使用的成员变量改为变量数组，对应于线程池的个数。原有的依次比较改成最后遍历数组比较取最优。这块重构问题主要是内存问题，有些输出变量是对输入变量的局部更新，但是该变量是很大的数据结构，直接变成数组，造成内存使用增加很多，当前通过增加输出数据结构解决，这里的坑和多线程无关，另外单独介绍。</p><h2 id="单例"><a class="header-anchor" href="#单例"></a>单例</h2><p>这块业务代码有一个特色，就是单例使用特别多，且单例不仅仅是状态资源管理类，同时还是业务功能类。这里单例使用的是否合理，软件架构设计的是否合理不做深入讨论。当前只讨论怎么重构支持多线程。</p><h3 id="重构为类成员变量"><a class="header-anchor" href="#重构为类成员变量"></a>重构为类成员变量</h3><p>首先想到的方法是，既然不是全局的状态资源管理类，那么改成类成员比较合理，这样多线程处理时可以像上面的函数输出，改成数组就能满足需求。但通过阅读代码发现单例互相调用，随处调用等等，这种方法难以实现。</p><h3 id="重构为多单例"><a class="header-anchor" href="#重构为多单例"></a>重构为多单例</h3><p>这种方法比较省事，把原来的静态实例变成静态实例数组，获取单例接口通过增加参数来区分获取的是哪一个实例，从而和线程对应起来。代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static const MyClass&amp; GetInstance(uint8_t threadIndex) &#123;</span><br><span class="line">    static MyClass instance[THREAD_POOL_SIZE];</span><br><span class="line">    return instance[threadIndex];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多线程处理没有问题了，现在的问题变成如何获取<code>threadIndex</code>。</p><p>一个方法是给线程池的各线程命名，建立线程名称与<code>threadIndex</code>的map关系，这样在线程内可以通过系统接口获取线程名称，再通过map得到<code>threadIndex</code>。这种方法使用起来比较方便，但是有一个问题，单例特别多且高频调用，频繁调用系统接口比较影响性能。</p><p>另一种方法是通过参数传递进去，根据业务代码特点，每个类都有一个初始化配置接口<code>InitConfig</code>，这个接口在系统启动时执行一次。那么可以给每个类增加一个成员变量<code>threadIndex_</code>，在线程入口函数类的初始化时，遍历入口多单例并把<code>index</code>传入。在把action处理函数提交给线程池处理时，增加<code>index</code>参数，这样每个类在调用单例时都是通过传入的<code>index</code>调用的。代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MyClass::InitConfig(uint8_t index) &#123;</span><br><span class="line">    threadIndex_ = index;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 入口初始化时对多单例的初始化</span><br><span class="line">for (uint8_t i = 0; i &lt; THREAD_POOL_SIZE) &#123;</span><br><span class="line">    MyClass::GetInstance(i).InitConfig(i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># MyClass类中调用其他单例时</span><br><span class="line">OtherClass::GetInstance(threadIndex_).HandleFunc(...)</span><br></pre></td></tr></table></figure><p>这种方法相对比较可行，就是修改非常多，每一个调用单例且会更新的类都要修改。</p><p>单例修改完成后，使用线程池调式时发现还是会coredump，不用想肯定是多线程同时读写同一份数据造成的。通过调用栈看到的函数调用关系，看不出来具体问题点在哪里，虽然每次调用栈都不太一样，但是出问题的类及函数是相同的，且看到是同一个结构里的容器拷贝出了问题。通过增加打印及阅读代码，发现了另一个坑…</p><h2 id="static变量"><a class="header-anchor" href="#static变量"></a>static变量</h2><p>某些类成员函数中，局部变量定义时使用了static，但是没有使用历史值，猜测是想为了避免频繁构造析构该变量。但是C++中类中出现的static变量，不管是类成员变量还是函数局部变量，是独立于类实例的，所有该类的实例共享一份static变量。这就很清楚了，多线程调用时，这些线程共享了这一个变量，同时读写时出现踩内存问题。</p><p>回到局部变量使用static上，在面向过程实现中，staitc局部变量可以保证该变量的作用域只在函数内，避免使用全局变量造成全局可见，起到很好的封装作用。但是在面向对象实现中，这种隐藏在层层逻辑下的static局部变量是有很大的隐患的，因为它不是类的成员变量，却又所有实例共享一份。定义成普通类成员变量一样可以避免频繁构造析构，且重用该变量的值。</p><p>通过以上修改，终于调通了并行化~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近业务新特性开发，由原来的单个action变成了多个action，最后取一个最优action。由于action变多，运行时间也相应多了几倍，action之间是相互独立，互不影响的，那么就想通过并行化的方法提升下性能，这个时候自然而然就想到了线程池。本文记录一下此次并行化重</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="C/C++" scheme="http://blog.cuicc.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>恢复Hexo博客环境</title>
    <link href="http://blog.cuicc.com/blog/2021/11/30/recover-environment-for-writing/"/>
    <id>http://blog.cuicc.com/blog/2021/11/30/recover-environment-for-writing/</id>
    <published>2021-11-30T12:31:47.000Z</published>
    <updated>2021-12-01T13:50:32.111Z</updated>
    
    <content type="html"><![CDATA[<p>博客荒废了好些年了，这段时间觉得没有大的、好的主题可以写，就一直处于断更状态。最近发现就当笔记记录一些东西备查也是挺好，如果再次过程中还能对他人有一点帮助，那就更好了。是时候捡起来继续了，首先要恢复出本地的写作及部署环境，这里记录一下以备下次使用…</p><h2 id="WSL环境"><a class="header-anchor" href="#WSL环境"></a>WSL环境</h2><p>如果直接使用Windows或Mac等原生系统，可以跳过此步。从Windows支持Linux环境后，个人习惯用<code>WSL</code>，即保留Windows桌面的便捷性，又能兼顾Linux高效的命令操作。<br>安装步骤如下：</p><ol><li>打开“启用或关闭Windows功能”，勾选“适用于Linux的Windows子系统”。</li><li>从Microsoft Store中搜索你喜欢的Linux版本，比如Ubuntu，然后安装。</li></ol><p>安装完成后，安装powerline字体，参考<a href="https://github.com/powerline/fonts">官方指南</a>，需要注意的是因为使用的terminal是Windows的，所以要在Windows中安装，然后在terminal的字体设置中选择powerline相关字体。</p><p>个人比较喜欢用<code>oh-my-zsh</code>，安装完成后修改主题为<code>ZSH_THEME=&quot;agnoster&quot;</code>。enjoy it~</p><h2 id="Hexo环境"><a class="header-anchor" href="#Hexo环境"></a>Hexo环境</h2><p>这一步没什么花头，直接参照<a href="https://hexo.io/zh-cn/docs/">官方指南</a>安装Node.js和Git，然后通过npm安装Hexo即可。</p><h2 id="配置Hexo工程"><a class="header-anchor" href="#配置Hexo工程"></a>配置Hexo工程</h2><p>如果本地没有存储Source备份，需要从Github端clone一份</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b &lt;Source分支名&gt; https://github.com/&lt;用户名&gt;/&lt;Git库名&gt;.git</span><br></pre></td></tr></table></figure><p>其下操作步骤一样，进入Git仓库目录，执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure><p>由于之前的package.json比较老，执行install之后报了一堆npm的错误，形如</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">found XXX vulnerabilities (XXX low, XXX moderate, XXX high)</span><br><span class="line">run `npm audit fix` to fix them</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>在执行<code>npm audit fix</code>或<code>npm audit fix --force</code>后依然无法解决这个报错。这是因为该工程配置的依赖包版本太老了，npm检查后认为这些包存在安全隐患。最简单的方式就是升级到最新版本。</p><h3 id="Hexo升级"><a class="header-anchor" href="#Hexo升级"></a>Hexo升级</h3><p>由于package.json里配置了默认版本，所以首先要检查是否有新版本，然后更新json，命令如下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装npm-check用来检查是否需要升级插件</span></span><br><span class="line">sudo npm install -g npm-check</span><br><span class="line">npm-check</span><br><span class="line"><span class="comment"># 安装npm-upgrade用来更新json</span></span><br><span class="line">sudo npm install -g npm-upgrade</span><br><span class="line">npm-upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新全局插件</span></span><br><span class="line">sudo npm update -g</span><br><span class="line"><span class="comment"># 更新本工程插件</span></span><br><span class="line">npm update --save</span><br></pre></td></tr></table></figure><p>更新完成后，可以用<code>hexo version</code>查看hexo及其依赖插件版本。</p><h3 id="其他告警"><a class="header-anchor" href="#其他告警"></a>其他告警</h3><ol><li>安装到最新版后，发现有报config参数deprecated，可以直接搜索相关参数看官方文档解决。<br>如安装5.0后遇到<code>external_link</code>参数问题</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INFO  Validating config</span><br><span class="line">WARN  Deprecated config detected: &quot;external_link&quot; with a Boolean value is deprecated. ...</span><br><span class="line"></span><br><span class="line"># 新格式如下</span><br><span class="line">external_link:</span><br><span class="line">    enable: true|false</span><br></pre></td></tr></table></figure><ol start="2"><li>执行<code>hexo s</code>后，有报循环依赖的告警，如下</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency</span><br><span class="line">(Use `node --trace-warnings ...` to show where the warning was created)</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency</span><br></pre></td></tr></table></figure><p>搜索发现是依赖的某个插件导致，不解决也不影响使用，暂时没管。相关<a href="https://www.haoyizebo.com/posts/710984d0/">解决链接</a></p><p>接下来，就可以<code>hexo new</code>继续写作之旅了~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;博客荒废了好些年了，这段时间觉得没有大的、好的主题可以写，就一直处于断更状态。最近发现就当笔记记录一些东西备查也是挺好，如果再次过程中还能对他人有一点帮助，那就更好了。是时候捡起来继续了，首先要恢复出本地的写作及部署环境，这里记录一下以备下次使用…&lt;/p&gt;
&lt;h2 id=&quot;</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="hexo" scheme="http://blog.cuicc.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>我的2017个人总结</title>
    <link href="http://blog.cuicc.com/blog/2017/12/31/my-personal-review-2017/"/>
    <id>http://blog.cuicc.com/blog/2017/12/31/my-personal-review-2017/</id>
    <published>2017-12-31T07:19:25.000Z</published>
    <updated>2019-04-01T13:24:17.440Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>燕子去了，有再來的時候；楊柳枯了，有再青的時候；桃花謝了，有再開的時候。但是，聰明的，你告訴我，我們的日子為什麼一去不復返呢？──是有人偷了他們罷：那是誰？又藏在何處呢？是他們自己逃走了罷：現在又到了那裡呢？</p><footer><strong>朱自清</strong><cite><a href="https://zh.wikisource.org/wiki/%E5%8C%86%E5%8C%86">匆匆</a></cite></footer></blockquote><p>每年这个时候总结一下，看看<a href="/blog/2017/01/02/my-personal-review-2016/" title="去年的目标">去年的目标</a>实现的怎么样，今年有哪些计划。</p><p>2017年最大的收获是小女的降临，带给我们太多的惊喜，太多的欢乐，更惊叹生命的神奇。从一事无知的小婴儿，到第一次发音（哭声之外），第一次抓头发，第一次吐泡泡，第一次抬头，第一次翻身，第一次爬，长出第一颗牙，认识爸爸妈妈，听懂爸爸妈妈说话，慢慢学走路… 太多的惊奇。2018年让我们探索更多的惊奇。</p><p>2017年最大的变化是由二人世界变成了三口之家。以前的随性而为，现在的三思而不行，在小宝宝身上以及家庭琐事上倾注了几乎所有的时间与精力。2018年希望能找到一定的平衡，对宝宝有高质量的陪伴，同时也有自己的时间，二人世界的时间。</p><p>2017年最大的欠缺是没有学好养娃这门学问。养娃远没有喂饱，穿暖，逗乐这么简单。以宝宝宝宝睡眠为例，为什么晚上易醒，醒来易哭，是饿了吗，是不困吗，什么是睡眠训练，怎么训练等等。2018年希望能在读书计划里加入育儿类书籍，打好理论基础，懂得宝宝各阶段的心理状态，应对方法。</p><p>2017年最大的无奈是工作被变动。由原来的接触各种新技术，广而不深的技术开发到技术单一，深而不广的产品开发。无奈的地方在于无休止的加班，越做越窄的工作内容而又暂时无法逃离。2018年希望在做不完的工作中能扩充自己的技能，继续保持对行业、科技、产品、趋势、模式的好奇心。</p><p>2017年最大的坚持是健身与读书。从家里徒手加哑铃，到公司健身房器械，虽然一直耿耿于怀的体重没有上去，但身体更好了，精神状态更好了。上半年读了不少书，有管理、有散文、有小说、有历史、有传记，下半年因为工作太累的原因，几乎没读。2018年希望继续坚持锻炼身体，以增肌为目标；希望继续坚持读书，利用好上下班的通勤时间，增加专业书籍的阅读量。</p><p>2018年的目标：</p><ol><li>有空多陪伴宝宝，解放宝妈，让宝妈有更多的时间做自己的事情；育儿理论基础增强，从各种育儿书，心理学等开始。</li><li>‎身体与灵魂，继续在路上。坚持健身，目标增肌增重。坚持读书，各种有趣的书，能写写读书笔记。</li><li>‎探索工作的多种可能，坚持各种博客杂文的积累下，多读几本技术专业书籍，提高综合知识面。</li><li>‎能规划一次长途旅行，去看看风景，看看人文，看看世界。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;&lt;p&gt;燕子去了，有再來的時候；楊柳枯了，有再青的時候；桃花謝了，有再開的時候。但是，聰明的，你告訴我，我們的日子為什麼一去不復返呢？──是有人偷了他們罷：那是誰？又藏在何處呢？是他們自己逃走了罷：現在又到了那裡呢？&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之多网络策略</title>
    <link href="http://blog.cuicc.com/blog/2017/09/10/kubernetes-network-policy/"/>
    <id>http://blog.cuicc.com/blog/2017/09/10/kubernetes-network-policy/</id>
    <published>2017-09-10T04:28:33.000Z</published>
    <updated>2019-04-01T13:24:17.434Z</updated>
    
    <content type="html"><![CDATA[<p>网络策略(<code>Network Policy</code>)是<code>Kubernetes</code>提供的一种规范，它描述了一组<code>Pod</code>是如何被允许相互通信的，以及和其他端点是如何通信的。<code>Kubernetes</code>只提供了这样的机制，具体功能由网络插件(<code>Network Plugins</code>)实现，流行的网络插件有很多，但并不是所有的网络插件都提供了网络策略功能，如<code>flannel</code>就没有提供这样的功能，目前已知的支持网络策略的有<code>Calico</code>, <code>Cilium</code>, <code>Kube-router</code>, <code>Romana</code>, <code>Weave Net</code>, <code>Canal</code>。</p><p>网络策略的应用和<code>Kubernetes</code>中很多操作类似，是通过<code>labels</code>来选取一组<code>Pods</code>的，然后再配置具体的规则(目前的实现都是通过配置<code>iptables rule</code>)来控制什么流量被允许发送到这组选取的<code>Pods</code>。</p><p><em>注:</em> 笔者使用的<strong>Kubernetes 1.6</strong>版本中网络策略还处于<code>beta</code>状态，其配置和<strong>Kubernetes 1.7</strong>中网络策略正式版略有差异。这里略作批注。</p><h2 id="网络策略"><a class="header-anchor" href="#网络策略"></a>网络策略</h2><p>使用网络策略的一般步骤如下(以<code>Calico</code>为例):</p><h3 id="配置网络策略"><a class="header-anchor" href="#配置网络策略"></a>配置网络策略</h3><ol><li>修改<code>kube-apiserver</code>的配置文件，添加配置项<code>--runtime-config=extensions/v1beta1/networkpolicies=true</code>，表示启用网络策略(<strong>Kubernetes 1.6</strong>版本中)</li><li>修改<code>kubelet</code>的配置文件，添加配置项<code>--network-plugin=cni</code>，表示使用CNI网络插件</li><li>根据<code>calico</code>相应版本的<a href="https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/">安装文档</a>，安装<code>calico</code>插件，<strong>Calico Kubernetes Hosted Install</strong>方式比较简单。</li></ol><h3 id="使用网络策略"><a class="header-anchor" href="#使用网络策略"></a>使用网络策略</h3><p><code>kubernetes</code>官方文档有<a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">详细的说明</a>，这里简要列一下几个关键配置。</p><ol><li><p>默认配置下，<code>Pods</code>是不做隔离的，即集群内所有<code>Pod</code>之间都是互通的。<br>a. <strong>Kubernetes 1.6</strong>版本中在使用网络策略之前，需要先配置<code>namespace</code>为默认隔离，配置如下：</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;mynamespace&quot;,</span><br><span class="line">        &quot;labels&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;mynamespace&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">            &quot;net.beta.kubernetes.io/network-policy&quot;: &quot;&#123;\&quot;ingress\&quot;: &#123;\&quot;isolation\&quot;: \&quot;DefaultDeny\&quot;&#125;&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时，该<code>namespace</code>下的所有<code>Pod</code>都是隔离状态的，不接收任何来源的流量。</p><p>b. <strong>Kubernetes 1.7</strong>版本中直接通过网络策略配置，即配置网络策略的应用网络策略规则，未配置网络策略的还是未隔离状态。</p></li><li><p>使用标签选择器配置一组<code>Pod</code>的网路策略，即接收哪些来源的流量， 示例如下(<strong>Kubernetes 1.6</strong>版本<code>apiVersion</code>不同)，该配置表示：</p><ul><li>在名为<code>default</code>的命名空间中隔离所有标签为<code>role=db</code>的<code>Pod</code>， 如果没有隔离的话(<strong>Kubernetes 1.7</strong>版本)。</li><li>允许标签为<code>project=myproject</code>的命名空间中的所有<code>Pod</code>通过<code>TCP</code>连接该<code>default</code>命令空间里的标签为<code>role=db</code>的<code>Pod</code>的<code>6379</code>端口。</li><li>允许标签为<code>role=frontend</code>的<code>defult</code>命名空间中的所有<code>Pod</code>通过<code>TCP</code>连接该<code>default</code>命令空间里的标签为<code>role=db</code>的<code>Pod</code>的<code>6379</code>端口。</li></ul> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">&quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">&quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;test-network-policy&quot;,</span><br><span class="line">    &quot;namespace&quot;: &quot;default&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;spec&quot;: &#123;</span><br><span class="line">    &quot;podSelector&quot;: &#123;</span><br><span class="line">    &quot;matchLabels&quot;: &#123;</span><br><span class="line">        &quot;role&quot;: &quot;db&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;ingress&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;from&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;namespaceSelector&quot;: &#123;</span><br><span class="line">            &quot;matchLabels&quot;: &#123;</span><br><span class="line">                &quot;project&quot;: &quot;myproject&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;podSelector&quot;: &#123;</span><br><span class="line">            &quot;matchLabels&quot;: &#123;</span><br><span class="line">                &quot;role&quot;: &quot;frontend&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;ports&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;protocol&quot;: &quot;TCP&quot;,</span><br><span class="line">            &quot;port&quot;: 6379</span><br><span class="line">        &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>同样的，<strong>Kubernetes 1.7</strong>版本中，也提供了默认策略<br>a. 默认全隔离策略，类似于<strong>Kubernetes 1.6</strong>版本对<code>namespace</code>的配置，作用的命名空间下所有<code>Pod</code>在未应用其他网络策略的情况下是隔离状态。</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;default-deny&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;podSelector&quot;: null</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>b. 全通策略，作用的命名空间下所有<code>Pod</code>可接收任何流量，无视其上配置的其他网络策略。</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;allow-all&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;podSelector&quot;: null,</span><br><span class="line">        &quot;ingress&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="多网络策略"><a class="header-anchor" href="#多网络策略"></a>多网络策略</h2><p>在文章[kubernetes之多网络支持]中，以<code>flannel</code>为例讲述了多网络的配置方法。由于<code>flannel</code>不支持网络策略，这里使用<a href="https://github.com/Huawei-PaaS/CNI-Genie">Huawei-PaaS/CNI-Genie</a>插件为例，<code>CNI-Genie</code>也是集成引导插件，本身不做具体功能，由引用的插件完成网络功能，其支持<code>Calico</code>, <code>Weave Net</code>, <code>Canal</code>, <code>Romana</code>等。</p><h3 id="配置多插件"><a class="header-anchor" href="#配置多插件"></a>配置多插件</h3><p>在前述配置网络策略的基础上，再安装<code>CNI-Genie</code>, <code>Weave Net</code>, <code>Canal</code>, <code>Romana</code>等插件，以上插件官方都有<code>Kubernetes Hosted Install</code>的安装脚本，直接下载应用即可。这里<code>CNI-Genie</code>的配置文件是<code>00-**.conf</code>，而其他插件的配置文件是<code>10-**.conf</code>，所以按优先级默认加载的插件是<code>CNI-Genie</code>。</p><h3 id="使用多网络"><a class="header-anchor" href="#使用多网络"></a>使用多网络</h3><p><code>CNI-Genie</code>使用动态选择插件的策略，即每次部署都可以指定不同的插件，通过<code>Kubernetes</code>的<code>annotations</code>实现，示例如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: mytest</span><br><span class="line">  namespace: mynamespace</span><br><span class="line">  labels:</span><br><span class="line">    name: mytest</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: mytest</span><br><span class="line">      namespace: mynamespace</span><br><span class="line">      labels:</span><br><span class="line">        name: mytest</span><br><span class="line">      annotations:</span><br><span class="line">        cni: &quot;calico,weave&quot;</span><br><span class="line">        multi-ip-preferences: |</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;multi_entry&quot;: 0,</span><br><span class="line">            &quot;ips&quot;: &#123;</span><br><span class="line">              &quot;&quot;: &#123;</span><br><span class="line">                &quot;ip&quot;: &quot;&quot;,</span><br><span class="line">                &quot;interface&quot;: &quot;&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: mytest</span><br><span class="line">          image: mytest:latest</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 21234</span><br></pre></td></tr></table></figure><p>这里<code>annotations</code>添加了两个字段，<code>cni</code>表示该部署使用的网络插件，如这里使用的是<code>Calico</code>和<code>Weave Net</code>。<code>multi-ip-preferences</code>字段用于反填网络插件配置的ip地址和网络编号，以<code>ip1</code>, <code>ip2</code>, … 命名。</p><p><em>注</em>: <code>Calico</code>由于本身实现的问题，笔者在验证时不能作为非第一网络使用，具体参看<a href="https://github.com/projectcalico/cni-plugin/issues/352">github issue</a></p><h3 id="多网络策略-v2"><a class="header-anchor" href="#多网络策略-v2"></a>多网络策略</h3><p>网络策略的实现都是以<code>Kubernetes</code>里的<code>PodIP</code>为入参施加网络规则的，但在多网络配置下只有第一网络的ip被上报给<code>Kubernetes</code>，作为<code>PodIP</code>。也就是说我们无法通过<code>Kubernetes</code>存储的数据获取到多网络地址。这里我们可以利用<code>multi-ip-preferences</code>字段的值来满足定制化需求。</p><p>以<code>Weave Net</code>为例，需要定制其<code>npc</code>实现，所有获取<code>PodIP</code>的地方替换成如下方式获取的ip(获取第二网络地址，这里示例不具有灵活性，可考虑在<code>multi-ip-preferences</code>添加一个字段表示该ip属于哪个插件)。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">func getIPFromAnnotation(pod *coreapi.Pod) string &#123;</span><br><span class="line">var podIP2 string = &quot;&quot;</span><br><span class="line">var mip MultiIPPreferences</span><br><span class="line"></span><br><span class="line">mipJSON, found := pod.ObjectMeta.Annotations[&quot;multi-ip-preferences&quot;]</span><br><span class="line">if found &#123;</span><br><span class="line">if err := json.Unmarshal([]byte(mipJSON), &amp;mip); err == nil &#123;</span><br><span class="line">if value, ok := mip.Ips[&quot;ip2&quot;]; ok &#123;</span><br><span class="line">podIP2 = value</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return podIP2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，我们的多网络配置下，可以使网络策略作用于所有配置网络。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;网络策略(&lt;code&gt;Network Policy&lt;/code&gt;)是&lt;code&gt;Kubernetes&lt;/code&gt;提供的一种规范，它描述了一组&lt;code&gt;Pod&lt;/code&gt;是如何被允许相互通信的，以及和其他端点是如何通信的。&lt;code&gt;Kubernetes&lt;/code&gt;只</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之探针</title>
    <link href="http://blog.cuicc.com/blog/2017/07/23/kubernetes-probe/"/>
    <id>http://blog.cuicc.com/blog/2017/07/23/kubernetes-probe/</id>
    <published>2017-07-23T06:58:58.000Z</published>
    <updated>2019-04-01T13:24:17.424Z</updated>
    
    <content type="html"><![CDATA[<p>探针是<code>kubelet</code>用于周期性诊断容器的一种方式。目前<code>kubenertes</code>提供两种探针，通过调用容器提供的句柄(<code>handler</code>)来实现监测诊断。</p><h2 id="两种探针"><a class="header-anchor" href="#两种探针"></a>两种探针</h2><ul><li><strong>livenessProbe</strong>: 用于探测容器是否处于<code>Running</code>状态，如果该探针返回失败，<code>kubelet</code>将会杀掉容器，并根据<code>restart policy</code>来决定是否重新创建该容器。如果没有配置该探针，默认返回成功的状态，只有容器<code>crash</code>，才会触发失败状态返回。</li><li><strong>readinessProbe</strong>: 用于探测容器是否可以处理服务请求，如果该探针失败，端点控制器将会把该<code>Pod</code>的IP从关联的<code>Service</code>中删除掉。如果没有配置该探针，默认返回成功的状态。</li></ul><h2 id="三种操作"><a class="header-anchor" href="#三种操作"></a>三种操作</h2><ul><li><strong>ExecAction</strong>: 在容器中执行命令行，如果命令的退出状态是0，则认为探针的状态是成功。</li><li><strong>TCPSocketAction</strong>: 向容器指定端口上发送TCP请求，如果该端口已被监听，则认为探针的状态是成功。</li><li><strong>HTTPGetAction</strong>: 向容器指定端口和路径发送HTTP GET请求，如果返回状态码处于200到400之间，则认为探针的状态是成功。</li></ul><h2 id="四种场景"><a class="header-anchor" href="#四种场景"></a>四种场景</h2><ul><li><strong>Default</strong>: 不配置探针时，容器处于不健康的状态(如<code>crash</code>)时，<code>kubelet</code>也会杀掉容器；容器正常初始化后，就认为是可以提供服务的状态。</li><li><strong>Custom</strong>: 在某种情况下，进程无法正常提供功能，但容器依然处于健康状态，则可以通过配置<code>liveness</code>探针实现杀掉容器； 进程初始化事件比较长，则可以通过配置<code>readiness</code>探针实现服务可用。</li><li><strong>Reset</strong>: 某些进程处于中间过程状态，但又希望从初始状态开始时，可以通过配置<code>liveness</code>探针实现，同时提供复位接口，如请求复位接口，则探针返回失败状态，从而实现复位操作。默认返回成功状态。</li><li><strong>OutOfService</strong>: 在进行服务升级时，需要将服务临时下线，可以通过配置<code>readiness</code>探针实现，同时提供服务下线接口，如请求下线接口，则探针返回失败状态，从而实现下线操作。默认返回成功状态。</li></ul><p><em>参考:</em></p><ul><li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes"><em>Pod Lifecycle - Container probes</em></a></li><li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/"><em>Configure Liveness and Readiness Probes</em></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;探针是&lt;code&gt;kubelet&lt;/code&gt;用于周期性诊断容器的一种方式。目前&lt;code&gt;kubenertes&lt;/code&gt;提供两种探针，通过调用容器提供的句柄(&lt;code&gt;handler&lt;/code&gt;)来实现监测诊断。&lt;/p&gt;
&lt;h2 id=&quot;两种探针&quot;&gt;&lt;a clas</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之多网络支持</title>
    <link href="http://blog.cuicc.com/blog/2017/05/14/kubernetes-multi-networks/"/>
    <id>http://blog.cuicc.com/blog/2017/05/14/kubernetes-multi-networks/</id>
    <published>2017-05-14T03:30:55.000Z</published>
    <updated>2019-04-01T13:24:17.416Z</updated>
    
    <content type="html"><![CDATA[<p>某些场景下，我们需要多网络的支持，如<code>eth0</code>用于业务功能，<code>eth1</code>用于配置管理功能，那么<code>kubernetes</code>下该如何实现呢？</p><a href="/blog/2017/04/30/kubernetes-network/" title="上一篇">上一篇</a> 我们着重分析了各层级之间网络通信的方式，以及内外网之间的网络通信，这些通信方式的探讨都是基于单一网络的。<p><code>kubernetes</code>网络默认只支持单一网络，使用<code>noop</code>网络插件。<code>kubernetes</code>网络是以<code>Plugin</code>的方式实现的，它支持符合<code>CNI</code>规范的插件，通过<code>--network-plugin=</code>来指定，这就意味着我们可以定制网络方案。</p><p>关于<code>kubernets</code>网络插件，<a href="https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/">官方文档</a>有详细的描述，这里简单介绍一下:</p><p>网络插件还处于<code>alpha</code>阶段，其内容会经常发生变化。目前支持两种网络插件</p><ul><li>CNI plugin: 符合<code>CNI</code>规范的插件，其规范请参看<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md">官方文档</a>。</li><li>kubenet plugin：这个可看作是<code>kubernentes</code>官方提供的符合CNI规范的插件，基于<code>cbr0</code>，使用<code>CNI</code>的<code>bridge</code>和<code>local-host</code>插件。</li></ul><p>那么，要实现定制化的网络，只需按<code>CNI</code>规范实现<code>Add</code>和<code>Remove</code>接口即可。<code>kubernetes</code>多网络方案就是以<code>CNI</code>插件的方式实现的。以下操作基于<code>Ubuntu 14.04</code>，除<code>etcd</code>操作外，其他操作所有节点都要执行。</p><h2 id="准备工作"><a class="header-anchor" href="#准备工作"></a>准备工作</h2><ul><li>已部署多节点<code>kubernetes</code>集群，<code>overlay</code>网络使用<code>flannel</code></li><li>已安装<code>golang</code>编译环境</li><li>部署节点上已安装<code>bridge-utils</code>, <code>conntrack</code>和<code>nsenter</code></li><li>从<code>github</code>上下载<a href="https://github.com/Intel-Corp/multus-cni">multus-cni</a>，该插件实现多网络功能，具体网络功能由以下插件实现</li><li>[可选]从<code>github</code>上下载<a href="https://github.com/Intel-Corp/sriov-cni">sriov-cni</a>，该插件实现SR-IOV功能</li><li>从<code>github</code>上下载<a href="https://github.com/containernetworking/cni">cni</a>，基础插件库，包含<code>bridge</code>, <code>flannel</code>, <code>ipam</code>等</li></ul><h2 id="CNI插件"><a class="header-anchor" href="#CNI插件"></a>CNI插件</h2><p>将<code>multus-cni</code>, <code>sriov-cni</code>, <code>cni</code>放在<code>go</code>编译目录下，如<code>~/go/src/</code>下，分别编译三个插件，在各自目录下执行<code>./build.sh</code>。编译成功后，生成的二进制文件位于<code>./bin</code>下。</p><p>创建目录<code>/opt/cni/bin</code>，将编译好的二进制文件拷贝到该目录下。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/cni/bin</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/multus-cni/ &amp;&amp; ./build.sh</span><br><span class="line">cp ./bin/* /opt/cni/bin/</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/sriov-cni/ &amp;&amp; ./build.sh</span><br><span class="line">cp ./bin/* /opt/cni/bin/</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/cni/ &amp;&amp; ./build.sh</span><br><span class="line">cp ./bin/* /opt/cni/bin/</span><br></pre></td></tr></table></figure><h2 id="配置flannel网络"><a class="header-anchor" href="#配置flannel网络"></a>配置flannel网络</h2><p>以下操作除步骤4只需要在<code>master</code>节点操作外，其他步骤各节点都需要执行。</p><ol><li>创建该<code>flannel</code>网络使用的网桥，如<code>kbr1</code></li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brctl addbr kbr1</span><br></pre></td></tr></table></figure><ol start="2"><li>创建存放flannel网络配置的目录</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /run/flannel/networks</span><br></pre></td></tr></table></figure><ol start="3"><li>仿照<code>/run/flannel/subnets.env</code>文件，在<code>/run/flannel/networks</code>下创建配置文件，如<code>subnets2.env</code>，使用不同的网络段，如</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /run/flannel/subnets.env /run/flannel/networks/subnets2.env</span><br><span class="line">vim /run/flannel/networks/subnets2.env</span><br><span class="line"><span class="comment">#modify as follows</span></span><br><span class="line">FLANNEL_NETWORK=173.17.0.0/16</span><br><span class="line">FLANNEL_SUBNET=173.17.76.1/24</span><br><span class="line">FLANNEL_MTU=1400</span><br><span class="line">FLANNEL_IPMASQ=<span class="literal">true</span></span><br></pre></td></tr></table></figure><ol start="4"><li>将该网络段注册到<code>etcd</code>，注意使用不同的前缀，如原网络使用的是<code>/coreos.com/network/</code>，这里使用<code>/k8s/network2/</code>。再者默认的<code>vlan index</code>是1，所以这里<code>VNI</code>为2</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/opt/bin/etcdctl <span class="built_in">set</span> /k8s/network2/config <span class="string">&#x27;&#123; &quot;Network&quot;: &quot;173.17.0.0/16&quot;, &quot;Backend&quot;: &#123; &quot;Type&quot;: &quot;vxlan&quot;, &quot;VNI&quot;: 2 &#125; &#125;&#x27;</span></span><br></pre></td></tr></table></figure><ol start="5"><li>使用上述配置启动新的<code>flannel daemon</code>，<a href="https://github.com/coreos/flannel/blob/master/Documentation/running.md#multiple-networks">参考文档</a>，其中<code>--etcd-endpoints=http://127.0.0.1:4001 --ip-masq --iface=172.16.1.171</code>来自于<code>/etc/default/flannel</code>文件</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/opt/bin/flanneld -subnet-file /run/flannel/networks/subnets2.env -etcd-prefix=/k8s/network2 --etcd-endpoints=http://127.0.0.1:4001 --ip-masq --iface=172.16.1.171 &amp;</span><br></pre></td></tr></table></figure><ol start="6"><li>创建<code>flannel</code>数据存储目录，存储<code>subnets2.env</code>网络相关的数据</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/cni/flannel/2</span><br></pre></td></tr></table></figure><h2 id="配置multus-cni"><a class="header-anchor" href="#配置multus-cni"></a>配置multus-cni</h2><p>在<code>cni-conf-dir</code>(默认为<code>/etc/cni/net.d/</code>)下创建配置文件<code>test.conf</code>，其内容如下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;multus-demo-network&quot;</span>,</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;multus&quot;</span>,</span><br><span class="line">    <span class="string">&quot;delegates&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;flannel.2&quot;</span>,</span><br><span class="line">                <span class="string">&quot;subnetFile&quot;</span>: <span class="string">&quot;/run/flannel/networks/subnets2.env&quot;</span>,</span><br><span class="line">                <span class="string">&quot;dataDir&quot;</span>: <span class="string">&quot;/var/lib/cni/flannel/2&quot;</span>,</span><br><span class="line">                <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;bridge&quot;</span>: <span class="string">&quot;kbr1&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;flannel.1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;subnetFile&quot;</span>: <span class="string">&quot;/run/flannel/subnet.env&quot;</span>,</span><br><span class="line">                <span class="string">&quot;dataDir&quot;</span>: <span class="string">&quot;/var/lib/cni/flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;masterplugin&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;bridge&quot;</span>: <span class="string">&quot;docker0&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;isDefaultGateway&quot;</span>: <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该文件的作用是，配置两个<code>flannel</code>网络，指定了各自的<code>subnet</code>配置文件，数据存储位置<code>dataDir</code>，使用的网桥。其中<code>flannel.1</code>有<code>masterplugin</code>属性，其意为该网络会上报给<code>kubelet</code>。</p><h2 id="配置kubelet"><a class="header-anchor" href="#配置kubelet"></a>配置kubelet</h2><p><code>kubelet</code>的配置文件为<code>/etc/default/kubelet</code>, 在其行尾加上<code>--network-plugin=cni</code>。 如果上述的<code>cni bin</code>和<code>cni conf</code>不想放在默认目录下，这里可以使用<code>--cni-bin-dir</code>和<code>--cni-conf-dir</code>指定目录。</p><p>然后重启<code>kubelet</code>进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">service kubelet restart</span><br><span class="line">service kubelet status</span><br></pre></td></tr></table></figure><h2 id="Enjoy-it"><a class="header-anchor" href="#Enjoy-it"></a>Enjoy it</h2><p>现在，启动的<code>pod</code>都具有两个网络<code>eth0</code>和<code>net0</code>(<code>multus-cni</code>多网络是以<code>net0</code>, <code>net1</code> … <code>netn</code>命名的)。每个网络使用不同的<code>flannel</code>网络，网络间是隔离的，<code>vlan index</code>不同。如果需要更多的网络，只需增加配置即可。</p><p>该方案的缺点是配置是固定的，不能动态增删，需要重启<code>kubelet</code>。对每个<code>pod</code>而言，网络个数不能动态配置，依赖于整体方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;某些场景下，我们需要多网络的支持，如&lt;code&gt;eth0&lt;/code&gt;用于业务功能，&lt;code&gt;eth1&lt;/code&gt;用于配置管理功能，那么&lt;code&gt;kubernetes&lt;/code&gt;下该如何实现呢？&lt;/p&gt;
&lt;a href=&quot;/blog/2017/04/30/kuber</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
    <category term="flannel" scheme="http://blog.cuicc.com/tags/flannel/"/>
    
    <category term="multi-networks" scheme="http://blog.cuicc.com/tags/multi-networks/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之网络分析</title>
    <link href="http://blog.cuicc.com/blog/2017/04/30/kubernetes-network/"/>
    <id>http://blog.cuicc.com/blog/2017/04/30/kubernetes-network/</id>
    <published>2017-04-30T12:50:45.000Z</published>
    <updated>2019-04-01T13:24:17.408Z</updated>
    
    <content type="html"><![CDATA[<p><code>Kubernetes</code>是一个开源的容器集群管理平台，可用来自动化部署、扩展和运维应用容器。关于这个平台本身的各组件及具体功能不在本文讨论范围，本文主要关注<code>kubernetes</code>的网络方案。在讨论网络之前有必要先了解下相关概念，这些概念和网络息息相关。</p><h2 id="基本概念"><a class="header-anchor" href="#基本概念"></a>基本概念</h2><p><code>Containers</code>是最小的资源单位，用于轻松地打包应用程序及相关配置。但在<code>kubernetes</code>中，容器不是操作的最小单位，甚至容器本身对<code>kubernetes</code>是不可见的，而是通过包装在外面的<code>Pod</code>进行资源的管理。</p><p><code>Pods</code>是最小的部署单位，是部署在<code>kubernetes</code>中的应用的一个实例。可包含一组相关容器，<code>Pod</code>内共享的存储资源，一个唯一的网络IP以及一些选项配置容器该怎样运行。<code>Pod</code>中的所有容器共享一个网络IP，容器间可直接用<code>localhost</code>访问。</p><p><code>Replica sets</code>是<code>ReplicationController</code>的下一代实现，它和后者基本上是一样的，除了对选择器<code>Selector</code>的支持不一样。该控制器用来保证始终都有一定数量的<code>Pod</code>副本在运行，它会自动替换故障/被删除/被终止的副本。也就是说，少于设定的固定数量时，会自动创建到达该数量；多于该数量时，会自动删除到该数量。官方不建议直接使用该控制器，可用更高层的<code>Deployment</code>来管理。</p><p><code>Deployment</code>为<code>Pods</code>和<code>Replica sets</code>提供了声明更新，也就是说该控制器用来保证达到你描述的期望状态。使用该控制器可以方便的更新<code>Pods</code>(滚动升级)，如更新了容器镜像；可以方面的回滚到之前的部署版本；可以随时暂停和启动部署。</p><p><code>Service</code>有时也被称为微服务，是一个抽象的概念，它定义了一组<code>Pods</code>以及访问它们的策略。<code>Pods</code>是通过标签选择器<code>Label Selector</code>被集合在一起的。该抽象层屏蔽了后端的<code>Pods</code>副本，对外呈现一个访问入口。这样即使后端被替换，对外也是不感知的。所以，不管是对内还是对外提供的功能，都以<code>Service</code>作为服务入口是合理的做法。</p><p><code>Service</code>和<code>Deployment</code>可以看作是同一级的概念，<code>Service</code>用于<code>Pods</code>对外提供服务的管理，<code>Deployment</code>用于<code>Pods</code>本身的管理。以上各个概念之间的关系如下图：</p><img src="/images/k8s-concepts.png" class="" title="Kubernetes概念关系图"><p><code>Nodes</code>是指<code>kubernetes</code>集群的节点，提供能力的机器，如虚拟机等，这里列举一下便于下面的网络讨论。</p><h2 id="网络方案"><a class="header-anchor" href="#网络方案"></a>网络方案</h2><p>基于以上的概念，可以看到涉及到的网络通信有容器间的通信，<code>Pod</code>间的通信，服务间的通信，跨节点的通信，以及延伸一下跨集群的通信。那么这些网络通信在<code>kubernetes</code>里都是如何实施的呢？<code>kubernetes</code>官方给出了一个使用<code>OpenVSwitch</code>的<a href="https://kubernetes.io/docs/admin/ovs-networking/">网络方案</a>。这里基于这个网络方案图扩展一下，试图涵盖所有的网络连接类型。如下图所示，针对每种网络连接类型，后面会详细讨论。</p><img src="/images/k8s-network.png" class="" title="Kubernetes网络方案图"><h3 id="Container-to-Container"><a class="header-anchor" href="#Container-to-Container"></a>Container-to-Container</h3><p>上面我们已经提到，<code>kubernetes</code>不会直接操作容器本身，对外呈现的最小操作单位是<code>Pod</code>，这里容器之间的通信是指一个<code>Pod</code>内的容器之间如何通信。我们观察一个<code>Pod</code>里的资源时，会发现有一个自己启动的<code>pause</code>容器，这个容器的作用是为<code>Pod</code>提供网络，所有其他的容器(也就是我们通过模板启动的容器)，都是共享<code>pause</code>容器网络的。在实现上，如<code>Docker</code>提供了<code>--net=container:ID</code>这样的选项。</p><p>每个<code>pod</code>对外呈现一个唯一的IP，<code>Pod</code>内的各容器共享这个IP，也就是说各容器处于同一网络空间中，可直接使用<code>localhost</code>互相访问，需要注意的是各容器使用的端口不能冲突，可以认为<code>IP:Port</code>能够唯一确定一个容器。类比一个系统内的多个网络进程。</p><h3 id="Pod-to-Pod"><a class="header-anchor" href="#Pod-to-Pod"></a>Pod-to-Pod</h3><p><code>kubernetes</code>网络实现基于以下三个原则：</p><ul><li>所有容器和其他容器的通信不需要NAT</li><li>所有<code>node</code>和容器间的通信不需要NAT</li><li>容器自己看到的IP就是对外呈现的IP</li></ul><p>那么，这是如何做到的呢？在同一<code>node</code>时，是通过容器网桥实现的，如<code>Docker</code>默认使用的网桥<code>Docker0</code>；在跨<code>node</code>通信时，是通过<code>node</code>间的<code>overlay network</code>实现互联的，如<code>flannel</code>, <code>OpenVSwitch</code>提供的<code>VxLAN tunnel</code>。官方列举了更多的<code>overlay network</code>实现，<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">参考链接</a>。</p><h3 id="Pod-to-Service"><a class="header-anchor" href="#Pod-to-Service"></a>Pod-to-Service</h3><p>作为前端的<code>Service</code>与作为后端的<code>Pods</code>之间是通过<code>kubernetes</code>的组件<code>kube-proxy</code>实现通信的。<code>kube-proxy</code>为<code>Service</code>实现了虚拟IP的形式，即<code>ClusterIP</code>。有两种代理模式，<code>userspace</code>和<code>iptables</code>。</p><ul><li><code>userspace</code>模式下，需要在本<code>node</code>上分配<code>proxy port</code>，该port被代理到后端的<code>Pods</code>，这样来自<code>ClusterIP:Port</code>的信息被重定向到<code>proxy port</code>，然后代理到后端的<code>Pods</code>。</li><li><code>iptables</code>模式下，<code>kube-proxy</code>通过直接增删<code>iptables</code>规则实现重定向转发。它比<code>userspace</code>模式更快更可靠，缺点是当前<code>Pod</code>无响应时，它无法自动重试其他<code>Pod</code>，需要借助<code>readiness probes</code>实现。</li></ul><p>关于两种模式更详细的描述参考<a href="https://kubernetes.io/docs/concepts/services-networking/service/">官网文档</a></p><h3 id="Service-to-External"><a class="header-anchor" href="#Service-to-External"></a>Service-to-External</h3><p><code>Service</code>是以<code>ClusterIP</code>的形式对外提供服务的，但<code>ClusterIP</code>是集群内的虚拟IP网络。那么和集群外是如何通信的呢？可以通过以下方式实现：</p><ul><li><p><code>NodePort</code>: <code>kubernetes</code>从配置的端口范围(默认配置30000-32767)内分配一个端口，每个节点都会把该端口上的信息转发到<code>Service</code>中。这种方式可以通过集群内的任一节点<code>NodeIP:NodePort</code>访问到<code>Service</code>。这意味着整个集群最多只支持6万多个这种类型的服务。该类型的服务同样会分配一个内部的<code>ClusterIP</code>。</p></li><li><p><code>LoadBalancer</code>: 依赖于外部云提供商提供的服务均衡器，这同样需要<code>kubernetes</code>有相应的插件支持，具体的服务均衡策略由外部均衡器负责，信息将被定向到后端的<code>Pods</code>。这种类型的服务下，某些云提供商支持配置<code>LoadBalancerIP</code>，除此之外，上述的<code>ClusterIP</code>和<code>NodePort</code>也同样会分配以便正确的路由到<code>Service</code>。</p></li><li><p><code>ExternalName</code>: 该类型和上述几种不一样，它不需要代理或转发，它是通过<code>kube-dns</code>解析<code>CNAME</code>记录的方式重定向url实现的。</p></li></ul><p>从上面可以看出，<code>ClusterIP</code>, <code>NodePort</code>, <code>LoadBalancer</code>这三种类型是层层嵌套实现的。但对云提供商没有严格要求这样做，只是目前的API是这样的。</p><p>除了这几种服务类型之外，还可以使用<code>ExternalIPs</code>实现集群内外的互通，所谓的<code>ExternalIP</code>是指能够被路由到<code>kubernetes</code>节点的IP的，在公有云上，也就是我们所说的公网IP。<code>ExternelIPs</code>可以和任一类型的<code>Service</code>一起使用。</p><p>具体配置模板可参考<a href="https://kubernetes.io/docs/concepts/services-networking/service/">官网文档</a></p><h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2><p>至此，已涵盖网络方案图里的所有通信类型。在使用上做几点总结：</p><ul><li><p><code>Pod</code>(应用)的各<code>Container</code>(进程)通信可以看作是<code>VM</code>上各进程间的通信，<code>Pod</code>类似<code>VM</code>。</p></li><li><p><code>Pod</code>作为功能提供方时，以<code>Service</code>方式提供，屏蔽后端的具体实现，不直接对外暴露<code>Pod</code>。</p></li><li><p>集群<code>node</code>间的<code>overlay</code>网络不要和大网互通，保持集群的私密性。需要和外部交互时，通过<code>Service</code>。</p></li><li><p>集群内外通信，大网IP充足时，使用<code>ExternalIPs</code>，不拘泥于<code>Service</code>类型，否则使用<code>NodePort</code>，私有集群下基本够用。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt;是一个开源的容器集群管理平台，可用来自动化部署、扩展和运维应用容器。关于这个平台本身的各组件及具体功能不在本文讨论范围，本文主要关注&lt;code&gt;kubernetes&lt;/code&gt;的网络方案。在讨论网络之前有必要先了解下相关概念，</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="docker" scheme="http://blog.cuicc.com/tags/docker/"/>
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Sails:Node.js的MVC框架</title>
    <link href="http://blog.cuicc.com/blog/2017/04/09/Sails-MVC-framework-for-Node-js/"/>
    <id>http://blog.cuicc.com/blog/2017/04/09/Sails-MVC-framework-for-Node-js/</id>
    <published>2017-04-09T08:57:09.000Z</published>
    <updated>2019-04-01T13:24:17.401Z</updated>
    
    <content type="html"><![CDATA[<p><code>Sails</code>是<code>Node.js</code>上最流行的<code>MVC</code>架构模式的web框架，在设计上参考了<code>Ruby on Rails</code>的MVC框架模式，它是基于<code>Node.js</code>上最火爆的web框架<code>Express</code>开发的。 和其他的MVC框架不同的是，Sails的<code>MC</code>在服务端，而<code>V</code>在客户端，提供可扩展的、面向服务的数据驱动API。在使用上和其他知名的MVC框架类似，如PHP的<code>CodeIgnite</code>。</p><h2 id="基本用法"><a class="header-anchor" href="#基本用法"></a>基本用法</h2><p><code>Sails</code>在使用上提供了极大的便利性，创建一个项目使用命令<code>sails new &lt;project name&gt;</code>，运行则在项目目录下执行<code>sails lift</code>，然后可以通过<code>ip:1337</code>访问，如<code>localhost:1337</code>。</p><p>在开发上可使用命令<code>sails generate api cats</code>来生成<code>controller</code>和<code>model</code>，分别是<code>api/controllers/CatsController.js</code>和<code>api/models/Cats.js</code>。<code>view</code>则放在<code>views</code>目录下，支持多种模板语言，如<code>ejs</code>, <code>swig</code>等。</p><p>这里不深入探讨基本用法，主要侧重在<code>Sails</code>比较具有代表性的两个功能上，<code>Blueprints</code>和<code>Waterline</code>。</p><h2 id="Blueprints"><a class="header-anchor" href="#Blueprints"></a>Blueprints</h2><p><code>Blueprints</code>旨在减少代码数量及节约时间，它提供了一种快速生成API <code>routes</code>和<code>actions</code>(actions是指controller里定义的方法)的方法。<code>blueprint API</code>由两部分组成：<code>blueprint routes</code>和<code>blueprint actions</code>。</p><h3 id="Blueprint-Actions"><a class="header-anchor" href="#Blueprint-Actions"></a>Blueprint Actions</h3><p><code>Blueprint actions</code>是指一些通用方法，它们作用于任何<code>controller</code>来操作它的同名<code>model</code>，例如<code>CatsController.js</code>需要有<code>Cats.js</code>。这些方法是内置方法，即使<code>controller</code>是空的情况下也可以使用。方法如下：<code>find</code>, <code>findOne</code>, <code>create</code>, <code>update</code>, <code>destroy</code>, <code>populate</code>, <code>add</code>, <code>remove</code>，这些方法也就是下面的数据模型操作的<code>Waterline</code>所提供的方法。</p><h3 id="Blueprint-routes"><a class="header-anchor" href="#Blueprint-routes"></a>Blueprint routes</h3><p><code>Blueprint routes</code>是在执行<code>sails lift</code>时根据<code>controller</code>, <code>model</code>, <code>config</code>自动生成的路由。默认情况下，一个route指向一个action。有以下三种路由配置，配置文件位于<code>config/blueprints.js</code>。</p><ul><li><p><strong>RESTful routes</strong> 可通过RESTful接口直接对model进行CRUD操作。如<code>GET /user</code>将获取user列表，对应于<code>user.find()</code>; <code>POST /user</code>将增加一个user，对应于<code>user.create()</code>。RESTful路由最好使用<code>policies</code>进行保护以免未授权的用户访问。</p></li><li><p><strong>Shortcut routes</strong> 和<code>RESTful routes</code>类似，不同的是可直接把<code>action</code>编码在url中，如<code>/user/create?name=joe</code>可实现上面的<code>POST</code>方法的功能。而在这里都是<code>GET</code>操作。该路由适合在开发调试阶段使用，产品环境最好关闭。</p></li><li><p><strong>Action routes</strong> 当你在<code>controller</code>中实现了一些自定义的方法时，该功能可自动生成对应的路由，如<code>CatsController.js</code>中有方法<code>meow</code>，那么可通过<code>/cats/meow</code>接口访问。这里和其他<code>MVC</code>自动生成<code>controller</code>的路由一样的用法。和上面不同的是，自定义方法时同名<code>model</code>不是必须的。</p></li></ul><h2 id="Waterline"><a class="header-anchor" href="#Waterline"></a>Waterline</h2><p><code>Waterline</code>是数据无关的一个抽象适配层，让你在操作数据时无需关心底层数据库类型，不用写某种数据库专用的操作代码。其底层支持<code>SQL</code>型和<code>NoSQL</code>型数据库, 如<code>MySQL</code>, <code>MongoDB</code>等。对接某一具体数据库时，你所需要做的就是在<code>config/connections.js</code>里配置适配器，在<code>config/models.js</code>配置<code>models</code>默认连接的具体适配器，当然也可以在某一具体<code>model</code>里指定连接的适配器。这样，需要切换数据库时，只需修改连接的适配器即可，不需要修改一行代码。</p><p><code>model</code>中的数据模型结构如下，虽然某些字段看起来时<code>SQL</code>型数据库专用的，但定义了这些字段并不影响<code>NoSQL</code>型数据库使用。这里该<code>model</code>中的<code>connection</code>定义会覆盖掉<code>config/models.js</code>里的定义。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Model example</span></span><br><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  <span class="attr">connection</span>: <span class="string">&#x27;MySQLDB&#x27;</span>,</span><br><span class="line">  <span class="attr">tableName</span>: <span class="string">&#x27;users&#x27;</span>,</span><br><span class="line">  <span class="attr">attributes</span>: &#123;</span><br><span class="line">    <span class="attr">id</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;integer&#x27;</span>,</span><br><span class="line">      <span class="attr">unique</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">primaryKey</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">columnName</span>: <span class="string">&#x27;the_primary_key&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">name</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;string&#x27;</span>,</span><br><span class="line">      <span class="attr">columnName</span>: <span class="string">&#x27;full_name&#x27;</span></span><br><span class="line">    &#125;，</span><br><span class="line"></span><br><span class="line">    <span class="attr">getFullName</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">   <span class="attr">enroll</span>: <span class="function"><span class="keyword">function</span> (<span class="params">options, cb</span>) </span>&#123;</span><br><span class="line">       ...</span><br><span class="line">       cb(err, data);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的<code>model</code>示例可以看到，除了属性字段定义外，还有一些函数定义。这里看到的是我们自定义的函数，<code>Sails</code>还提供了一些内置函数。我们还发现函数可以在属性内，也可以在属性外，下面详细介绍一下。</p><h3 id="Model-Method"><a class="header-anchor" href="#Model-Method"></a>Model Method</h3><p>模型方法也称为静态方法或者类方法，放在面向对象里很好理解，就是该类提供的静态方法，不需要实例化可直接使用的方法。上面放在<code>attributes</code>外定义的方法就是模型方法。<code>Sails</code>提供的内置模型方法涵盖了增删改查，具体方法列表看<a href="http://sailsjs.com/documentation/reference/waterline-orm/models">官方文档</a>。除了这些方法外，还支持动态查找功能，以上面的<code>model</code>为例，该<code>model</code>有属性<code>id</code>和<code>name</code>，那么就有动态查找方法<code>findById</code>和<code>findByName</code>。</p><p>需要注意的是，模型静态方法都是异步方法，方法有两个参数，第一个是输入值，第二个是回调函数。输入值最好是一个完整记录或者时主键。自定义模型静态方法的好处是你可以把数据操作方法放在<code>controller</code>之外，放在<code>model</code>里，这样你在其他<code>controller</code>中也可以重用，当然前提是与<code>req</code>和<code>res</code>无关的操作。</p><h3 id="Attribute-Method"><a class="header-anchor" href="#Attribute-Method"></a>Attribute Method</h3><p>属性方法也称为记录方法或者实例方法，顾名思义，它是作用于某一实例或某一记录的方法。放在<code>attributes</code>内定义的方法就是自定义属性方法，当然<code>Sails</code>也提供了一些内置的属性方法，包括<code>.toJSON()</code>, <code>.save()</code>, <code>.toObject()</code>，详细介绍看<a href="http://sailsjs.com/documentation/reference/waterline-orm/records">官方文档</a>。</p><p>除了内置方法<code>.save()</code>外，属性方法都应当是同步的方法。因为自定义异步属性方法时，很难保证不出现意外结果。在命名属性方法时，最好加上前缀<code>is</code>，<code>get</code>等以区分其他属性，并对方法提供一定的自解释。</p><h3 id="more…"><a class="header-anchor" href="#more…"></a>more…</h3><p>这里只是管中窥豹，只介绍了最表面的冰山一角，以说明Waterline的功能强大，其他还有<code>Associations</code>, <code>Validations</code>等等，如有兴趣，强烈建议看一下<a href="http://sailsjs.com/documentation/concepts/models-and-orm">官方文档</a>。</p><h2 id="官方文档"><a class="header-anchor" href="#官方文档"></a>官方文档</h2><ul><li><p>工程结构请参考<a href="http://sailsjs.com/documentation/anatomy">APP Structure</a></p></li><li><p>基本概念请参考<a href="http://sailsjs.com/documentation/concepts">Concepts</a></p></li><li><p>接口使用请参考<a href="http://sailsjs.com/documentation/reference">API Reference</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Sails&lt;/code&gt;是&lt;code&gt;Node.js&lt;/code&gt;上最流行的&lt;code&gt;MVC&lt;/code&gt;架构模式的web框架，在设计上参考了&lt;code&gt;Ruby on Rails&lt;/code&gt;的MVC框架模式，它是基于&lt;code&gt;Node.js&lt;/code&gt;</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="Node.js" scheme="http://blog.cuicc.com/tags/Node-js/"/>
    
    <category term="Sails" scheme="http://blog.cuicc.com/tags/Sails/"/>
    
    <category term="MVC" scheme="http://blog.cuicc.com/tags/MVC/"/>
    
  </entry>
  
  <entry>
    <title>Node.js抛异常ECONNRESET退出</title>
    <link href="http://blog.cuicc.com/blog/2017/03/26/nodejs-ECONNRESET/"/>
    <id>http://blog.cuicc.com/blog/2017/03/26/nodejs-ECONNRESET/</id>
    <published>2017-03-26T06:15:53.000Z</published>
    <updated>2019-04-01T13:24:17.393Z</updated>
    
    <content type="html"><![CDATA[<p>项目中需要对接公司域账户对其他模块提供鉴权服务。为方便实现Restful接口，以及学习一门没用过的技术，于是决定使用Node.js开发实现。</p><h2 id="LDAP鉴权服务接口"><a class="header-anchor" href="#LDAP鉴权服务接口"></a>LDAP鉴权服务接口</h2><p>该服务实现两个功能，一个是和LDAP服务器对接鉴权域登录，一个是对外以Restful API的方式提供服务。Node.js的库<a href="http://ldapjs.org/">ldapjs</a>和<a href="https://expressjs.com/">Express</a>可以很简单的完成这两个功能。实现大体框架如下</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> ldap = <span class="built_in">require</span>(<span class="string">&#x27;ldapjs&#x27;</span>);</span><br><span class="line">...</span><br><span class="line"><span class="keyword">var</span> app = express();</span><br><span class="line"></span><br><span class="line">app.post(</span><br><span class="line">    <span class="string">&#x27;auth&#x27;</span>,</span><br><span class="line">    <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">var</span> user = &#123;</span><br><span class="line">            <span class="attr">username</span>: req.body.username,</span><br><span class="line">            <span class="attr">password</span>: req.body.password,</span><br><span class="line">            <span class="attr">dn</span>      : <span class="string">&#x27;&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">var</span> adminClient = ldap.creatClient(&#123;<span class="attr">url</span>:url&#125;);</span><br><span class="line">        adminClient.bind(admin.dn, admin.password, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>)</span>&#123;</span><br><span class="line">            assert.ifError(err);</span><br><span class="line"></span><br><span class="line">            adminClient.search(base, opts, <span class="function"><span class="keyword">function</span>(<span class="params">err, search</span>)</span>&#123;</span><br><span class="line">                search.on(<span class="string">&#x27;searchEntry&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">entry</span>)</span>&#123;</span><br><span class="line">                    user.dn = entry.dn; </span><br><span class="line">                    <span class="keyword">var</span> userClient = ldap.createClient(&#123;<span class="attr">url</span>:url&#125;);</span><br><span class="line">                    userClient.bind(user.dn, user.password, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>)</span>&#123;</span><br><span class="line">                        <span class="keyword">if</span>(err)&#123;</span><br><span class="line">                            res.json(&#123;<span class="string">&#x27;status&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;message&#x27;</span>:<span class="string">&#x27;invalid password&#x27;</span>&#125;);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        res.json(&#123;<span class="string">&#x27;status&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;message&#x27;</span>:<span class="string">&#x27;auth ok&#x27;</span>&#125;);</span><br><span class="line">                    &#125;);</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">                search.on(<span class="string">&#x27;end&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>)</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(user.dn === <span class="string">&#x27;&#x27;</span>)&#123;</span><br><span class="line">                        res.json(&#123;<span class="string">&#x27;status&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;invalid user&#x27;</span>&#125;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">8080</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;listening on port 8080&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>完成后，使用postman测试了下，功能没有问题。但程序会在十几分钟后抛出异常，退出执行。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">events.js:<span class="number">72</span></span><br><span class="line">        <span class="keyword">throw</span> er; </span><br><span class="line">              ^</span><br><span class="line"><span class="built_in">Error</span>: read ECONNRESET</span><br><span class="line">    at errnoException (net.js:<span class="number">900</span>:<span class="number">11</span>)</span><br><span class="line">    at TCP.onread (net.js:<span class="number">555</span>:<span class="number">19</span>)</span><br></pre></td></tr></table></figure><p>遂Google了一下Nodejs ECONNRESET。</p><h2 id="Node-js-ECONNRESET"><a class="header-anchor" href="#Node-js-ECONNRESET"></a>Node.js ECONNRESET</h2><p>stackoverflow上有一个问答专门探讨这个<a href="http://stackoverflow.com/questions/17245881/node-js-econnreset">问题</a>，简单摘录一下回答</p><blockquote><p>“ECONNRESET” means the other side of the TCP conversation abruptly closed its end of the connection. This is most probably due to one or more application protocol errors. You could look at the API server logs to see if it complains about something.</p><footer><strong>e-sushi</strong><cite><a href="http://stackoverflow.com/a/17637900">ECONNRESET</a></cite></footer></blockquote><p>ECONNRESET表示TCP会话的另一端突然断开了连接。很大可能性是由应用的协议出错造成的。这里我有两个连接，一个是Restful接口的连接，一个是ldap的连接。</p><blockquote><p>I had a similar problem where apps started erroring out after an upgrade of Node. I believe this can be traced back to Node release v0.9.10 this item:</p><p>net: don’t suppress ECONNRESET (Ben Noordhuis)</p><p>Previous versions wouldn’t error out on interruptions from the client. A break in the connection from the client throws the error ECONNRESET in Node. I believe this is intended functionality for Node, so the fix (at least for me) was to handle the error, which I believe you did in unCaught exceptions. Although I handle it in the net.socket handler.</p><footer><strong>John Williams</strong><cite><a href="http://stackoverflow.com/a/17798353">ECONNRESET</a></cite></footer></blockquote><p>从Node v0.9.10开始不再压制ECONNRESET，之前的版本从客户端中断时不会报错。现在从客户端中断会抛出ECONNRESET错误，这是Node的预期功能。解决方法是处理这个错误，因为这是一个未捕获的异常。</p><h2 id="原因分析"><a class="header-anchor" href="#原因分析"></a>原因分析</h2><p>综上可总结该问题的原因：</p><ol><li>Node退出是因为出现未捕获的异常，异常为<code>read ECONNRESET</code>错误。</li><li><code>ECONNRESET</code>是因为TCP连接的对端(通常是server)突然断开了连接。server一般都设置了<code>keepalive</code>，对于不活动的连接会超时断开。</li><li>客户端请求完成后没有主动断开连接。</li></ol><h2 id="解决方法"><a class="header-anchor" href="#解决方法"></a>解决方法</h2><p>简单的解决方法就是捕获这个异常，如果无法定位出具体出这个异常的地方，可以在进程级捕获进行分析。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">process.on(<span class="string">&#x27;uncaughtException&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(err.stack);</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">&#x27;NOT exit...&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>而在本例中，作为客户端请求的是ldap，ldap服务器断开了不活动的连接，应该由ldap来捕获异常，但<a href="http://ldapjs.org/client.html">官方文档</a>并没有相关说明。在github该库的<a href="https://github.com/mcavage/node-ldapjs/issues/318">issue</a>中找到了捕获方法。client有监听error事件功能，以及可以设置client自动重连，官方文档未更新。基本用法如下：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> client = ldap.creatClient(&#123;<span class="attr">url</span>:url, <span class="attr">reconnect</span>: <span class="literal">true</span>&#125;);</span><br><span class="line">...</span><br><span class="line">client.on(<span class="string">&#x27;error&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(err);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>对于小的应用请求而言，client主动断开连接是比较优雅的做法，根据该issue，client具有<code>destroy</code>方法，可以主动销毁创建的client对象。基本用法如下：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">client.unbind();</span><br><span class="line">client.destroy();</span><br></pre></td></tr></table></figure><p>但测试了一下并没有起作用。这里采用client捕获异常防止进程退出的方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;项目中需要对接公司域账户对其他模块提供鉴权服务。为方便实现Restful接口，以及学习一门没用过的技术，于是决定使用Node.js开发实现。&lt;/p&gt;
&lt;h2 id=&quot;LDAP鉴权服务接口&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#LDAP鉴权服务接口</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="Node.js" scheme="http://blog.cuicc.com/tags/Node-js/"/>
    
  </entry>
  
  <entry>
    <title>心智是否成熟</title>
    <link href="http://blog.cuicc.com/blog/2017/03/12/grow-up/"/>
    <id>http://blog.cuicc.com/blog/2017/03/12/grow-up/</id>
    <published>2017-03-12T12:05:40.000Z</published>
    <updated>2019-04-01T13:24:17.380Z</updated>
    
    <content type="html"><![CDATA[<p>职场中，我们经常听到招聘要找一个心智成熟的人；生活中，我们经常听到说一个人很幼稚，不成熟，即使年龄已经不小。那么，到底什么是心智？心智成熟的表现是什么？或者说怎么去做一个心智成熟的人呢？学习摘抄了一下，与君共勉。</p><h2 id="什么是心智"><a class="header-anchor" href="#什么是心智"></a>什么是心智</h2><p>心智的定义，我看了下<a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E7%81%B5">维基百科</a>和<a href="http://baike.baidu.com/item/%E5%BF%83%E6%99%BA">百度百科</a>。相比较而言，我更喜欢百度百科的描述，相对更容易理解一点。</p><blockquote><p>心智是人们的心理与智能的表现。</p><p>心智定义：即是指人们对已知事物的沉淀和储存，通过生物反应而实现动因的一种能力总和。它涵盖了“哲学”对已知事物的积累和储存，结合了“生物学”的大脑信息处理，即“生物反应”，运用了为实现某种欲需（动因）而从事的“心理”活动，从而达到为实现动因结果而必须产生的智能力和“潜能”力。</p><p>一个人的“心智”指的是他各项思维能力的总和，用以感受、观察、理解、判断、选择、记忆、想像、假设、推理，而后根据指导其行为。</p><footer><strong>百度百科</strong><cite><a href="http://baike.baidu.com/item/%E5%BF%83%E6%99%BA">心智</a></cite></footer></blockquote><p>心智也可以简化为两个关键词：思维和智力。<br>那么如果去判断一个人心智是否成熟/怎么去做一个心智成熟的人呢，也主要从这两个方面来看。</p><h2 id="成熟的心智"><a class="header-anchor" href="#成熟的心智"></a>成熟的心智</h2><p>Google了一下心智成熟，发现有两个描述比较好，一个比较详尽且有对比，但不知道出处。另一个比较精炼，出自于《King, Warrior, Magician, Lover 》。这两个描述基本主旨是相似的。这既可以用来判断，也可以查找不足，努力成长。</p><h3 id="详尽的描述"><a class="header-anchor" href="#详尽的描述"></a>详尽的描述</h3><blockquote><p>1.心智成熟的人， 在日常的生活工作中，为人处世，行事判断有主见，有原则，不以别人的喜恶行为来左右自己的行事处世标准。</p><p>2.心智成熟的人， 承认人性中有光明的一面，有黑暗的一面，有慈善的一面，有阴暗的一面，有优点又有缺点，并有容忍和谅解的胸襟。</p><p>3.心智成熟的人， 能够坦然地接受对方的一切优点和缺点，懂得学会与别人如何相处之道。</p><p>4.心智成熟的人， 会从很多不同的视角看问题，而孩子气的人， 通常只从自己的角度看问题！</p><p>5.心智成熟的人， 明白良好的动机未必带来良好的效果，艰苦的付出未必收到丰硕的成果，了解手段与目的之不可分割。</p><p>6.“不以人废言”，懂得“以事论事”而“不以人论事”的道理。承认真理的绝对性，不看人的地位的高低而断言论是非。</p><p>7.面对批评， 成熟的人， 会心平气和， 想想道理， 努力改进 ；不成熟的人，则会垂头丧气， 或暴怒不已。</p><p>8.出状况时，成熟的人习惯反省，并乐意致歉；不成熟的人，只会指责他人，从不道歉。</p><p>9.心智成熟的人，因充满自信而心有余力，总是善意解读他人之言行，并且有礼回应；不成熟的人，缺乏自信而敏感多疑，认为别人的言行总是另有目的，忍不住会语带挑衅地回应。</p><p>10.遇到心情低谷时，成熟的人，会为自己的心情负责，想的是：“我该做些什么，可以让事情好转？”；不成熟的人，则是要他人为自己情绪负责，想的是：“ TA该做什么，才能让我的心情好转？” 。</p><p>11.成熟的人，会利用幽默感调整心情，自我解嘲时，能用旁观者视角，读出其中有趣，而轻松化解情绪；不成熟的人，则是用幽默来仓皇掩盖心中情绪，自我解嘲后，心情往往更难堪而低迷。</p><p>12.在人际关系中，成熟的人常说：“我愿意……”，主动付出爱；不成熟的人总是说：“我需要……”，只会提要求。</p><p>13.明白“人比人气死人”的道理，不拿自己跟别人滥加比较。不要勉强自己去做天才明星。百万富翁屈指可数，平凡人总是大多数。明白富人有富人的烦恼，凡人有凡人乐趣。</p><p>14.了解人与人之间的沟通乃是世上最难最难也是最有意义的一件事情，而封闭自傲的心灵正是沟通的最大敌人。</p><p>15.能够独立思考或作正确的决定。做事不会反复无常，对重要的决定事项，无须依赖别人而能够独立判断。</p><footer><strong>豆瓣</strong><cite><a href="https://www.douban.com/group/topic/29621603/">如何看一个人心智是否成熟</a></cite></footer></blockquote><h3 id="精炼的描述"><a class="header-anchor" href="#精炼的描述"></a>精炼的描述</h3><blockquote><p>• 他们沉稳，处事不惊。能够在危险中保持镇定。<br>• 他们不容易被冒犯，却很容易能给人带来安全和可靠感。<br>• 他们从不寻求关注和爱护。他们生活的趋势是给于他人认同，给于爱。<br>• 他们习惯于慷慨的给于他人帮助。他们深知，助人强者无不自强。<br>• 他们的生活有确定的使命，行动和思维从不混乱。<br>• 他们能够忍耐痛苦，但依旧敞开心活着。他们不怕被骗，被看不起。<br>• 他们从来不为自己辩解，因为他们知道自己是谁。</p><footer><strong>Robert Moore / Douglas Gillette </strong><cite>King Warrior Magician Lover</cite></footer></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;职场中，我们经常听到招聘要找一个心智成熟的人；生活中，我们经常听到说一个人很幼稚，不成熟，即使年龄已经不小。那么，到底什么是心智？心智成熟的表现是什么？或者说怎么去做一个心智成熟的人呢？学习摘抄了一下，与君共勉。&lt;/p&gt;
&lt;h2 id=&quot;什么是心智&quot;&gt;&lt;a class=&quot;h</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="心智" scheme="http://blog.cuicc.com/tags/%E5%BF%83%E6%99%BA/"/>
    
  </entry>
  
  <entry>
    <title>我的2016个人总结</title>
    <link href="http://blog.cuicc.com/blog/2017/01/02/my-personal-review-2016/"/>
    <id>http://blog.cuicc.com/blog/2017/01/02/my-personal-review-2016/</id>
    <published>2017-01-02T04:34:46.000Z</published>
    <updated>2019-04-01T13:24:17.373Z</updated>
    
    <content type="html"><![CDATA[<p>时间过得很快，转眼又是一年过去了。我还记得年初给老大们分享外企与私企工作异同时，有这样一个观点：所谓人傻钱多活少，并不是一个良好的状态，上班整天无所事事，下班一样也无所事事，看似有大把的时间，在这样的状态下，有再多的时间还是啥也不想干。</p><p>这一年，不是产品合作开发，就是支援产品开发。尤其是下半年，充分感受了产品开发的忙、累，比所谓的996更变态。同样地在这样一种身心疲惫的工作状态下，对很多事情都是有心无力。</p><p>这两种状态从侧面印证了我的论断：保持一定的忙碌状态，这样所有的爱好与习惯都是有条不紊的坚持下去。</p><p>还记得2015年，坚持了一年的身体锻炼，读了数十本不同种类的书。基于这美好的过去一年，曾写下2016年的目标。回首过去这一年，锻炼身体懈怠了，书读的少了，新东西学的半途而废了，没有一个坚持下来的。客观原因是上下班路程远，花的时间多；支援产品太忙太累。主观原因是心理上懈怠了，忘了坚持的意义。虽然如此，过去这一年还是有些需要总结的地方。</p><p>这一年，实现了每年一次长途旅行的目标。仍然没有走出亚洲，希望能有机会去欧洲、美洲走一遭。这一次去的是台湾，完全没有语言障碍的地方。台湾给我印象最深的是人文，礼貌、素质、秩序、友好，体现得淋漓尽致；故宫博物院的文物藏品玲琅满目，手艺与想象的集大成者，更不用说其历史价值了。</p><p>这一年，在休养了半年后，终于成功研发了2.1版 — 小咕咚，马上就要发布了，嗯。这是这一年最大的事，最欣慰的事，最期待的事。每天讲故事时的胎动，想想就开心。</p><p>这一年，又一次换了住处，方便老婆上下班，方便照顾即将迎来的小生命。</p><p>这一年，倾其所有，负债累累，搞了一个户口本。算是给自己一个交代，给老婆一个交代，给孩子一个交代。</p><p>这一年，去支援产品开发，在忙死、累死的背后，看到更多的是无谓的加班加点，是管理混乱导致，更深层还是制度使然。制度对人的塑造程度达到惊人的可怕地步。</p><p>这一年，原有的坚持慢慢被消磨殆尽，就连周末都难以再拾起运动，拿起书本。纵使记得“身体与灵魂必须有一个在修bug”，身心俱疲之下难以做到身体力行。</p><p>2017年，首要的任务是多赚钱，多赚钱，多赚钱。</p><p>2017年，我希望锻炼强大的内心，纵使心累，仍不忘坚持初心。</p><p>2017年，我仍希望坚持锻炼，保证健康的体魄。</p><p>2017年，我仍希望坚持读书，保证知识的宽度。</p><p>2017年，我仍希望坚持学习，保证技术的深度。</p><p>2017年，带着孩子，一起欣赏花花草草，虫鱼鸟兽，世间万物，锦绣繁华。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;时间过得很快，转眼又是一年过去了。我还记得年初给老大们分享外企与私企工作异同时，有这样一个观点：所谓人傻钱多活少，并不是一个良好的状态，上班整天无所事事，下班一样也无所事事，看似有大把的时间，在这样的状态下，有再多的时间还是啥也不想干。&lt;/p&gt;
&lt;p&gt;这一年，不是产品合作开</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>从免费抽奖到一元众筹</title>
    <link href="http://blog.cuicc.com/blog/2016/03/27/free-lottery-vs-one-cny-crowdfunding/"/>
    <id>http://blog.cuicc.com/blog/2016/03/27/free-lottery-vs-one-cny-crowdfunding/</id>
    <published>2016-03-27T06:28:22.000Z</published>
    <updated>2019-04-01T13:24:17.367Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现一个很有意思的转变，互联网平台或商家开始搞“一元众筹”推广模式，各商家的叫法不一，但玩法是一样的：一块钱参与抽奖，每到一定人数(通常是商品的售价)，抽取一人获奖得到该商品。那么相对于原来的免费抽奖，除了一块钱还有什么不一样呢？我尝试从以下几个方面对比一下:</p><span id="more"></span><h3 id="免费抽奖"><a class="header-anchor" href="#免费抽奖"></a>免费抽奖</h3><ul><li>推广模式：商家或平台提供奖品，参与抽奖获得一个抽奖号，分享到微博微信等社交平台额外获取多个抽奖号。</li><li>推广成本：从长期来看这是一笔不小的广告费。</li><li>用户心态：对用户来说，通常毫不犹豫地点击按钮参与抽奖，并且参与人数众多，热门奖品通常数十万人，抽到的概率很小。因为免费，用户可能对商家或平台几乎没有啥关注，仅仅为了抽奖而已。</li><li>推广收益：可以快速提高注册用户量。可能初期推广效果比较好。利于融资？</li></ul><h3 id="一元众筹"><a class="header-anchor" href="#一元众筹"></a>一元众筹</h3><ul><li>推广模式：用户一块钱买一个抽奖号，每到一定人数(通常是商品的售价)，众筹成功，从中抽取一人获得奖品。同时每次参与可获取一定的优惠券(比如5元优惠券)。</li><li>推广成本：充分利用众筹这一概念，不用付出成本。</li><li>用户心态：用户肯付出一元的成本，通常会考虑是否有在该商家或平台消费的可能性，优惠券的作用。</li><li>推广收益：筛选用户，增加目标用户转化率和用户粘性。</li></ul><h3 id="一元众筹平台"><a class="header-anchor" href="#一元众筹平台"></a>一元众筹平台</h3><p>在写这篇文章的时候，google了一下，发现有好多专门做低额众筹的平台。玩法和上述基本一样，不同的是只是纯众筹而已，没有优惠券返还，众筹份额不一定是一元。<br>好奇这些平台如何盈利呢？简单对比了几个商品，这些平台上奖品众筹价比实际售价高出不少，只要卖出去就可以稳赚不赔。这应该是这类平台的盈利模式吧。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近发现一个很有意思的转变，互联网平台或商家开始搞“一元众筹”推广模式，各商家的叫法不一，但玩法是一样的：一块钱参与抽奖，每到一定人数(通常是商品的售价)，抽取一人获奖得到该商品。那么相对于原来的免费抽奖，除了一块钱还有什么不一样呢？我尝试从以下几个方面对比一下:&lt;/p&gt;</summary>
    
    
    
    <category term="业界追踪" scheme="http://blog.cuicc.com/categories/%E4%B8%9A%E7%95%8C%E8%BF%BD%E8%B8%AA/"/>
    
    
    <category term="众筹" scheme="http://blog.cuicc.com/tags/%E4%BC%97%E7%AD%B9/"/>
    
    <category term="营销" scheme="http://blog.cuicc.com/tags/%E8%90%A5%E9%94%80/"/>
    
  </entry>
  
  <entry>
    <title>我的2015个人总结</title>
    <link href="http://blog.cuicc.com/blog/2016/01/02/my-personal-review-2015/"/>
    <id>http://blog.cuicc.com/blog/2016/01/02/my-personal-review-2015/</id>
    <published>2016-01-02T13:28:52.000Z</published>
    <updated>2019-04-01T13:24:17.361Z</updated>
    
    <content type="html"><![CDATA[<p>2015年对我来讲，是不太顺利的一年，经历了各种不好的事。人未三十而立，却已尝尽人生百态的感觉。</p><p>年初制定的计划，完成的并不好，甚至已经看不懂当初的简写是啥了，惭愧惭愧。这也和当初的目标太笼统有关。</p><p>这一年，坚持读书，时有断续，也看了好些本书，一些晦涩的书或者英文原版书看了看了开头挖了坑，一直没有填上。有小说，有科幻，有经济，有科普。</p><p>这一年，最欣慰的是坚持锻炼身体，唯一坚持到现在的一件事。无论是从P4P的level 1到疯狂level 2，还是转战到keep，一直打卡保持到现在。无论锻炼些什么，总之身体状态感觉还不错。希望能一直坚持下去。</p><p>这一年，经过一年的漫长等待，老婆的肺部阴影终于消失不见。差点喜极而泣！一年的原因不明，一年的担忧忐忑，终于在最后这一刻都放下。</p><p>这一年，也曾动摇过换个看似比较有前途的职业，不管是没有相关工作经验，还是开价太高，结果还是没有走出去。想开了也好，新兴也好，传统也好，都是为了生活，努力做好每一份工作吧。</p><p>这一年，前前后后经历过很多项目，总结了一些思考，但总感觉有点单薄，无法形成自己的方法论。虽不能左右大环境，希望可以形成自己的方法论，不求指导别人，但求指导自己。</p><p>这一年，还是无法平静自己的内心，每当夜深人静，还时常想起过去的一些事。一直耿耿于怀，多想再多几年时光可以陪在家人身旁。</p><p>2016年，我希望能够坚持运动，健康生活从每一天开始。</p><p>2016年，我希望能像坚持运动一样坚持读几本有意思的书。</p><p>2016年，我希望能够每段时间学习一样新东西，领域不限，先从感兴趣的开始。</p><p>2016年，我希望能安定下来，能够基于2.0版本开发出2.1版本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;2015年对我来讲，是不太顺利的一年，经历了各种不好的事。人未三十而立，却已尝尽人生百态的感觉。&lt;/p&gt;
&lt;p&gt;年初制定的计划，完成的并不好，甚至已经看不懂当初的简写是啥了，惭愧惭愧。这也和当初的目标太笼统有关。&lt;/p&gt;
&lt;p&gt;这一年，坚持读书，时有断续，也看了好些本书，一</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>技术开发的一些思考</title>
    <link href="http://blog.cuicc.com/blog/2015/12/06/thinking-about-technoloy-development/"/>
    <id>http://blog.cuicc.com/blog/2015/12/06/thinking-about-technoloy-development/</id>
    <published>2015-12-06T08:52:35.000Z</published>
    <updated>2019-04-01T13:24:17.354Z</updated>
    
    <content type="html"><![CDATA[<h3 id="技术开发是什么"><a class="header-anchor" href="#技术开发是什么"></a>技术开发是什么</h3><p>维基百科上没有相关词条，百度百科解释如下：</p><blockquote><p>技术开发（Technical Development）是把研究所得到的发现或一般科学知识应用于产品和工艺上的技术活动。 工业企业技术开发的对象主要有：产品的开发、设备与工具的开发、生产工艺的开发、能源与原材料的开发、改善环境的技术开发等。不同的企业可根据不同的情况选择技术开发的重点。</p><footer><strong>技术开发</strong><cite><a href="http://baike.baidu.com/view/1273954.htm">百度百科</a></cite></footer></blockquote><p>归纳总结一下，现在的技术开发无外乎以下两点：</p><ol><li>发明创造新技术解决(潜在)问题</li><li>组合现有前沿技术解决(潜在)问题</li></ol><p>对大多数企业来说，大多数时候都是在用第2点。能够做到第1点的少之又少。</p><span id="more"></span><h3 id="技术开发做什么"><a class="header-anchor" href="#技术开发做什么"></a>技术开发做什么</h3><p>我所理解的技术开发要快速做出产品原型，验证是否可用于正式产品中。基于这个理解，技术开发需要做以下两点：</p><ol><li>可行性验证，验证该技术方案是否可行，能否达到需求的目标</li><li>可用性实施，在可行性基础上，该技术方案能否易于实施，达到可用易用的程度。</li></ol><p><em>对产品实践来说，真正的技术积累来自于可用性，可行性无法识别问题点</em></p><h3 id="技术开发问题点"><a class="header-anchor" href="#技术开发问题点"></a>技术开发问题点</h3><p>通常我们的开发方式，我们的架构演进方式是：</p><ol><li>先实现，先达到需求的目标</li><li>再优化，优化设计不好的地方</li><li>服务化，服务化改造</li><li>合适化，选择合适的技术实现</li></ol><h4 id="我们遇到的问题"><a class="header-anchor" href="#我们遇到的问题"></a>我们遇到的问题</h4><ol><li>只有大饼，没有实施目标</li><li>大饼的概念，大饼的概念图，怎么做饼？</li><li>SE/项目经理职责不明确<ol><li>目标具体化及分解</li><li>软件架构设计</li></ol></li><li>项目经理太弱势<ol><li>项目实施决策</li><li>技术背景权威</li><li>迭代划分实施</li><li>责任划分跟踪</li><li>迭代目标评估</li></ol></li><li>不思求变<ol><li>历史包袱太重，如何平衡兼容与创新</li><li>拥抱先进生产力工具，提高效率</li></ol></li></ol><h4 id="结果如何"><a class="header-anchor" href="#结果如何"></a>结果如何</h4><ol><li>原型基本就是过家家</li><li>假装能以及解决了问题</li><li>自以为做的很高大上</li><li>盲目追求/包装新概念</li></ol><h3 id="技术开发怎么做"><a class="header-anchor" href="#技术开发怎么做"></a>技术开发怎么做</h3><p>回到最初的看法，把技术开发团队想象成是一家创业公司，应该怎么做。</p><p>从想法/需求到快速实现原型，到投入市场验证，到不断迭代优化，到用户体验良好的产品。</p><p>对于我们来说，看起来是这样的：</p><ol><li>需求分析出明确目标，目标分解，架构设计，迭代划分</li><li>从原型最小集出发，每个迭代都是可用的(可投入“市场”验证)</li><li>根据市场反馈，迭代优化，再次循环</li></ol><p>从具体开发来说：</p><ol><li>每次迭代目标对齐，做什么</li><li>每次迭代需求与设计明确</li><li>每次迭代各模块自我充分的分析与设计</li><li>每次迭代完成系统是可以用的，保证这个基本点</li></ol><p><em>暂时想到这么多</em></p><p><em>仅从个人角度看，感觉有点片面，从高层看是否如此呢</em></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;技术开发是什么&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#技术开发是什么&quot;&gt;&lt;/a&gt;技术开发是什么&lt;/h3&gt;
&lt;p&gt;维基百科上没有相关词条，百度百科解释如下：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;技术开发（Technical Development）是把研究所得到的发现或一般科学知识应用于产品和工艺上的技术活动。 工业企业技术开发的对象主要有：产品的开发、设备与工具的开发、生产工艺的开发、能源与原材料的开发、改善环境的技术开发等。不同的企业可根据不同的情况选择技术开发的重点。&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;技术开发&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;http://baike.baidu.com/view/1273954.htm&quot;&gt;百度百科&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;归纳总结一下，现在的技术开发无外乎以下两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;发明创造新技术解决(潜在)问题&lt;/li&gt;
&lt;li&gt;组合现有前沿技术解决(潜在)问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对大多数企业来说，大多数时候都是在用第2点。能够做到第1点的少之又少。&lt;/p&gt;</summary>
    
    
    
    <category term="职场感悟" scheme="http://blog.cuicc.com/categories/%E8%81%8C%E5%9C%BA%E6%84%9F%E6%82%9F/"/>
    
    
    <category term="technology" scheme="http://blog.cuicc.com/tags/technology/"/>
    
  </entry>
  
  <entry>
    <title>tips for git submodule</title>
    <link href="http://blog.cuicc.com/blog/2015/10/25/tips-for-git-submodule/"/>
    <id>http://blog.cuicc.com/blog/2015/10/25/tips-for-git-submodule/</id>
    <published>2015-10-25T06:41:56.000Z</published>
    <updated>2019-04-01T13:24:17.347Z</updated>
    
    <content type="html"><![CDATA[<p>近来使用<code>git submodule</code>来管理项目，趟过一些坑，整理记录一下。</p><p>##为啥使用submodule</p><p>Git官网如是说，简单的说，就是在引入第三方库时，或者一些公共模块的管理时，可以使用submodule，既单独管理更新，又能很方便的引入使用。</p><blockquote><p>A submodule allows you to keep another Git repository in a subdirectory of your repository. The other repository has its own history, which does not interfere with the history of the current repository. This can be used to have external dependencies such as third party libraries for example.</p><footer><strong>Git</strong><cite><a href="https://git-scm.com/docs/git-submodule">git-submodule Document</a></cite></footer></blockquote><span id="more"></span><p>##Add submodule</p><p>在一个repo中加入submodule的命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] add [-b &lt;branch&gt;] [-f|--force] [--name &lt;name&gt;]</span><br><span class="line">              [--reference &lt;repository&gt;] [--depth &lt;depth&gt;] [--] &lt;repository&gt; [&lt;path&gt;]</span><br></pre></td></tr></table></figure><p>在add一个submodule之后，在当前repo下便会生成一个<code>.gitmodules</code>文件，该文件记录submodule的相关信息，其内容如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[submodule &quot;submodule-name&quot;]</span><br><span class="line">        path = path name</span><br><span class="line">        url = https://github.com/submodule-name.git</span><br></pre></td></tr></table></figure><p>##update submodule</p><p>clone一个repo后，其submodule只会显示一个目录，其内容是空的，这时需要update各个submodule，其命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] init [--] [&lt;path&gt;…​]</span><br><span class="line">git submodule [--quiet] update [--init] [--remote] [-N|--no-fetch]</span><br><span class="line">              [-f|--force] [--rebase|--merge] [--reference &lt;repository&gt;]</span><br><span class="line">              [--depth &lt;depth&gt;] [--recursive] [--] [&lt;path&gt;…​]</span><br></pre></td></tr></table></figure><p>更新操作需要先init以下，然后再update。该两个操作也可以合并为一个命令完成，就是在update时加入<code>--init</code>参数。</p><p>如果需要从远程repo中update submodule，需要在update时加入<code>--remote</code>参数，这样会pull下来server上的最新版。</p><p>##modify submodule repo</p><p>更改submodule的repo地址，没有直接的命令可以完成，需要修改前面提到的<code>.gitmodules</code>文件，将<code>url</code>改成要更改成的repo地址。然后执行如下命令</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] sync [--recursive] [--] [&lt;path&gt;…​]</span><br></pre></td></tr></table></figure><p>##remove submodule</p><p>删除submodule的命令的过程比较繁多，需要多个命令才能完成，其命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mv asubmodule asubmodule_tmp</span><br><span class="line">git submodule [--quiet] deinit [-f|--force] [--] &lt;path&gt;…​   </span><br><span class="line">git rm asubmodule</span><br><span class="line"># if you want to leave it in your working tree</span><br><span class="line">git rm --cached asubmodule</span><br><span class="line">mv asubmodule_tmp asubmodule</span><br><span class="line">rm -rf .git/modules/asubmodule</span><br></pre></td></tr></table></figure><p>##modify submodule content</p><p>update之后的submodule是不属于任何一个branch的，也就是无branch的。submodule的HEAD是处于<code>detached HEAD</code>状态的。这样，如果要更改submodule的内容，需要首先切换到要更新的branch，然后按正常的git流程add/commit/pull/push等操作。</p><p>如果直接修改了submodule的内容，然后commit了该修改，那么在push时会出现up-to-update的情况。这时可以用如下命令挽救</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yygcui@ubuntu$ git checkout master</span><br><span class="line">Warning: you are leaving 1 commit behind, not connected to</span><br><span class="line">any of your branches:</span><br><span class="line"></span><br><span class="line">  &lt;commit id&gt; forget to check out master</span><br><span class="line"></span><br><span class="line">If you want to keep them by creating a new branch, this may be a good time</span><br><span class="line">to do so with:</span><br><span class="line"></span><br><span class="line"> git branch new_branch_name &lt;commit id&gt;</span><br><span class="line"></span><br><span class="line">Switched to branch &#x27;master&#x27;</span><br><span class="line">yygcui@ubuntu$ git cherry-pick &lt;commit id&gt;</span><br><span class="line">yygcui@ubuntu$ git push</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;近来使用&lt;code&gt;git submodule&lt;/code&gt;来管理项目，趟过一些坑，整理记录一下。&lt;/p&gt;
&lt;p&gt;##为啥使用submodule&lt;/p&gt;
&lt;p&gt;Git官网如是说，简单的说，就是在引入第三方库时，或者一些公共模块的管理时，可以使用submodule，既单独管理更新，又能很方便的引入使用。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A submodule allows you to keep another Git repository in a subdirectory of your repository. The other repository has its own history, which does not interfere with the history of the current repository. This can be used to have external dependencies such as third party libraries for example.&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;https://git-scm.com/docs/git-submodule&quot;&gt;git-submodule Document&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="git" scheme="http://blog.cuicc.com/tags/git/"/>
    
    <category term="submodule" scheme="http://blog.cuicc.com/tags/submodule/"/>
    
  </entry>
  
  <entry>
    <title>mysql掉电后无法启动 InnoDB: is in the future!</title>
    <link href="http://blog.cuicc.com/blog/2015/10/12/mysql-can-not-startup-after-loss-power/"/>
    <id>http://blog.cuicc.com/blog/2015/10/12/mysql-can-not-startup-after-loss-power/</id>
    <published>2015-10-12T13:59:26.000Z</published>
    <updated>2019-04-01T13:24:17.338Z</updated>
    
    <content type="html"><![CDATA[<p>公司在节假日会断电，十一忘记了关掉服务器，openstack在系统非正常关机后，无法启动。看了下日志，发现是其使用的mysql起不来。该数据库存储了所有的虚拟机相关信息，若是修复不好，损失惨重啊(别问我为什么没备份，我也不知道…)</p><p>分析mysql启动失败的原因，只能从log入手了，打开log发现最后的日志是</p><span id="more"></span><figure class="highlight bash"><figcaption><span>mysql.log</span></figcaption><table><tr><td class="code"><pre><span class="line">error: <span class="string">&#x27;Can&#x27;</span>t connect to <span class="built_in">local</span> MySQL server through socket <span class="string">&#x27;/var/run/mysqld/mysqld.sock&#x27;</span> (2)<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check that mysqld is running and that the socket: &#x27;</span>/var/run/mysqld/mysqld.sock<span class="string">&#x27; exists!</span></span><br></pre></td></tr></table></figure><p>根据log查看了下，mysqld.sock是存在。google了下这个error，根据一些文档试了下，发现根本没有什么作用，也就是说这可能不是出错的原因。只好继续向前翻log，发现每次试图启动mysql时，都有大量如下日志，我怀疑是因为突然掉电，导致有些log没有写入系统，所以出现了序列号不一致情况。</p><figure class="highlight bash"><figcaption><span>mysql.log</span></figcaption><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">InnoDB: Error: page 570 <span class="built_in">log</span> sequence number 7289495</span><br><span class="line">InnoDB: is <span class="keyword">in</span> the future! Current system <span class="built_in">log</span> sequence number 5574939.</span><br><span class="line">InnoDB: Your database may be corrupt or you may have copied the InnoDB</span><br><span class="line">InnoDB: tablespace but not the InnoDB <span class="built_in">log</span> files. See</span><br><span class="line">InnoDB: http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html</span><br><span class="line">InnoDB: <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure><p>再次google这个error，发现了这样的一篇博文<a href="https://boknowsit.wordpress.com/2012/12/22/mysql-log-is-in-the-future/">MySQL log is in the future!</a>，这篇博文的方法简单易懂，但是首要问题是我的mysql无法启动，无法启动就不能备份数据。同时也看了下log中提到的<a href="http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html">Forcing InnoDB Recovery</a>。</p><p>Forcing InnoDB Recovery提供了6个等级的修复模式，需要注意的是值大于3的时候，会对数据文件造成永久的破坏，不可恢复。六个等级的介绍摘抄如下：</p><figure class="highlight plaintext"><figcaption><span>Forcing InnoDB Recovery</span></figcaption><table><tr><td class="code"><pre><span class="line">1 (SRV_FORCE_IGNORE_CORRUPT)</span><br><span class="line"></span><br><span class="line">Lets the server run even if it detects a corrupt page. Tries to make SELECT * FROM tbl_name jump over corrupt index records and pages, which helps in dumping tables.</span><br><span class="line"></span><br><span class="line">2 (SRV_FORCE_NO_BACKGROUND)</span><br><span class="line"></span><br><span class="line">Prevents the master thread and any purge threads from running. If a crash would occur during the purge operation, this recovery value prevents it.</span><br><span class="line"></span><br><span class="line">3 (SRV_FORCE_NO_TRX_UNDO)</span><br><span class="line"></span><br><span class="line">Does not run transaction rollbacks after crash recovery.</span><br><span class="line"></span><br><span class="line">4 (SRV_FORCE_NO_IBUF_MERGE)</span><br><span class="line"></span><br><span class="line">Prevents insert buffer merge operations. If they would cause a crash, does not do them. Does not calculate table statistics. This value can permanently corrupt data files. After using this value, be prepared to drop and recreate all secondary indexes.</span><br><span class="line"></span><br><span class="line">5 (SRV_FORCE_NO_UNDO_LOG_SCAN)</span><br><span class="line"></span><br><span class="line">Does not look at undo logs when starting the database: InnoDB treats even incomplete transactions as committed. This value can permanently corrupt data files.</span><br><span class="line"></span><br><span class="line">6 (SRV_FORCE_NO_LOG_REDO)</span><br><span class="line"></span><br><span class="line">Does not do the redo log roll-forward in connection with recovery. This value can permanently corrupt data files. Leaves database pages in an obsolete state, which in turn may introduce more corruption into B-trees and other database structures.</span><br></pre></td></tr></table></figure><p>使用方法如下，在mysql配置文件中，添加或修改以下配置的值</p><figure class="highlight bash"><figcaption><span>my.cnf</span></figcaption><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_force_recovery = 1</span><br></pre></td></tr></table></figure><p>根据查到的博文提到的方法，我的修复步骤如下：</p><ul><li>因为我无法启动mysql，所以首先要想办法启动mysql，然后dump数据。从innodb_force_recovery的值1开始尝试，看mysql能否在该修复模式下启动，不到万不得已，不要尝试值为4及以上。</li><li>在我这里，mysql在值为2时可以启动，这是stop掉数据库，然后备份数据</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service mysql stop</span><br><span class="line">mysqldump -u root -p --all-databases &gt; all-databases.sql</span><br></pre></td></tr></table></figure> <ul><li>删除掉出错的数据文件</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv ib_logfile0 ib_logfile0.bak</span><br><span class="line">mv ib_logfile1 ib_logfile1.bak</span><br><span class="line">mv ibdata1 ibdata1.bak</span><br></pre></td></tr></table></figure><ul><li>启动mysql，然后从备份文件恢复数据</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service mysql start</span><br><span class="line">mysql -u root -p &lt; all-databases.sql</span><br></pre></td></tr></table></figure><ul><li>因为在修复模式下，在插入数据时报错，也就是说此时是不能写入数据的。所以就关闭掉了修复模式</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_force_recovery = 0</span><br></pre></td></tr></table></figure><p>restart mysql后，再次恢复数据</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service mysql restart</span><br><span class="line">mysql -u root -p &lt; all-databases.sql</span><br></pre></td></tr></table></figure><ul><li>再次重启下mysql，现在mysql可以正常启动了，并且数据也回复成功。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;公司在节假日会断电，十一忘记了关掉服务器，openstack在系统非正常关机后，无法启动。看了下日志，发现是其使用的mysql起不来。该数据库存储了所有的虚拟机相关信息，若是修复不好，损失惨重啊(别问我为什么没备份，我也不知道…)&lt;/p&gt;
&lt;p&gt;分析mysql启动失败的原因，只能从log入手了，打开log发现最后的日志是&lt;/p&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="mysql" scheme="http://blog.cuicc.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>容器化编译和部署</title>
    <link href="http://blog.cuicc.com/blog/2015/09/20/compile-and-deploy-using-docker/"/>
    <id>http://blog.cuicc.com/blog/2015/09/20/compile-and-deploy-using-docker/</id>
    <published>2015-09-20T08:12:48.000Z</published>
    <updated>2019-04-01T13:24:17.330Z</updated>
    
    <content type="html"><![CDATA[<p>容器不是一个新技术，lxc已经存在了很长时间，但Docker却使它更加方便易用。Docker火了之后，我一直没有明白它为啥这么火，除了它宣称的轻量化之外，还有什么。它能做的事情，虚拟机都可以做，并且虚拟机有更好的隔离性。</p><p>在使用场景上，貌似布道的更多的是环境一致性，即开发、测试、部署环境都能很好的保持一致。而至于在生产环境中使用它有什么好处，除了DevOps所倡导的自动化，简化运维，我就没有其他概念了。</p><p>最近在研究微服务的东西，那么微服务必然需要DevOps，必然也就需要高度自动化。Docker，或者说容器，很好的迎合了这一契机。可以说Docker极大的简化了自动化部署的难度。本文就从最近的实践看一看以前没发现的好处。</p><span id="more"></span><h2 id="用源码直接编译部署"><a class="header-anchor" href="#用源码直接编译部署"></a>用源码直接编译部署</h2><p>这种方式直接从VCS仓库下载源码，安装相关依赖库，然后编译安装，生成Docker镜像。其Dockerfile可能是这样的，以构建运行ubuntu的镜像为例。关于Dockerfile语法等可以参考<a href="https://docs.docker.com/reference/builder/">Dockerfile reference</a></p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    build-essential \</span><br><span class="line">    automake \</span><br><span class="line">    libtool \</span><br><span class="line">    git \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home/ &amp;&amp; git clone http://github.com/yygcui/myapp.git</span><br><span class="line"></span><br><span class="line"># compile and install</span><br><span class="line">RUN cd /home/myapp \</span><br><span class="line">    &amp;&amp; ./configure \</span><br><span class="line">    &amp;&amp; make \</span><br><span class="line">    &amp;&amp; make install \</span><br><span class="line"></span><br><span class="line"># clean source code and some tools </span><br><span class="line">RUN rm -rf /home/myapp \</span><br><span class="line">    &amp;&amp; apt-get remove --purge -y git build-essential automake libtool</span><br><span class="line"></span><br><span class="line"># set run cmd</span><br><span class="line">ENTRYPOINT [&quot;myapp.bin&quot;]</span><br><span class="line">CMD [&quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><p>从Dockerfile流程可以看出，这种方法比较简单直接，省去了软件打包的过程，省去了管理安装包的麻烦，直接安装在构建镜像中。但是也带来了一些缺点，比如为防止源码泄露需要清理，在闭源的情况下，只能发布构建好的镜像；深入一点分析，各种测试结果无法复用，比如集成测试有其他部件出现bug，这可能要重新从头执行整个流程。</p><h2 id="用源码编译成可执行包构建部署"><a class="header-anchor" href="#用源码编译成可执行包构建部署"></a>用源码编译成可执行包构建部署</h2><p>这种思路相当于在上面的基础上进行了编译和部署的分离。分别用不同的镜像来构建。比如编译阶段，我可以预先构建好编译基础镜像，包含基本的编译工具，节省安装时间。而在构建部署阶段，直接用纯净的基础镜像，避免安装不必要的软件包，更利于环境一致性。</p><h3 id="容器化编译"><a class="header-anchor" href="#容器化编译"></a>容器化编译</h3><p>容器化编译可以参考docker本身的编译过程，这里简化一下，该过程需要额外构建以下文件：Makefile(用来自动化容器编译的Makefile，非app的Makefile)，编译脚本，编译镜像(Dockerfile)。</p><p>Makefile主要做了三件事：创建映射目录，构建编译镜像，启动编译容器进行编译。Makefile简单示例如下。</p><figure class="highlight plaintext"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">.PHONY: all</span><br><span class="line"></span><br><span class="line">BIND_DIR := package</span><br><span class="line">DOCKER_MOUNT := $(if $(BIND_DIR),-v &quot;$(CURDIR)/$(BIND_DIR):/home/$(BIND_DIR)&quot;)</span><br><span class="line">DOCKER_IMAGE := myapp-compile</span><br><span class="line">DOCKER_RUN := docker run --rm -it --privileged $(DOCKER_MOUNT) &quot;$(DOCKER_IMAGE)&quot;</span><br><span class="line"></span><br><span class="line">default: all</span><br><span class="line">all: build</span><br><span class="line">    $(DOCKER_RUN) /home/build.sh</span><br><span class="line"></span><br><span class="line">build: package</span><br><span class="line">    docker build -t &quot;$(DOCKER_IMAGE)&quot; .</span><br><span class="line"></span><br><span class="line">package:</span><br><span class="line">    mkdir -p ./package</span><br></pre></td></tr></table></figure><p>编译脚本封装了源码的编译，以及编译后的打包等工作。可执行文件与编译出来的依赖库以及打包文件都放在package目录下，这样在host上也可以访问。</p><figure class="highlight plaintext"><figcaption><span>build.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># make it like a atom operate</span><br><span class="line">cd /home/myapp \</span><br><span class="line">&amp;&amp; ./configure --prefix=/home/package \</span><br><span class="line">&amp;&amp; make \</span><br><span class="line">&amp;&amp; make install</span><br><span class="line"></span><br><span class="line">#build rpm/deb/tar package if needed</span><br><span class="line">#cd /home/package \</span><br><span class="line">#&amp;&amp; tar -czvf myapp.tar.gz ./bin ./lib ./doc install.sh</span><br></pre></td></tr></table></figure><p>编译镜像的Dockerfile和上面的源码直接编译的差不多，只不过不包括编译部分。同时基础镜像也可以用已经构建好的编译基础镜像。这里只需要安装myapp依赖的库以及相应的下载工具即可。</p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example for compile</span><br><span class="line">FROM ubuntu-compile:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    git \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home/ &amp;&amp; git clone http://github.com/yygcui/myapp.git</span><br><span class="line"></span><br><span class="line">COPY build.sh /home/build.sh</span><br></pre></td></tr></table></figure><p>这样，你的下一步流程可以对该软件包进行各种测试，通过后可以上传到二进制包管理库。后续用到该软件时，都直接从二进制库下载。</p><h3 id="容器化部署"><a class="header-anchor" href="#容器化部署"></a>容器化部署</h3><p>这里部署的概念只是紧接着编译测试后如何构建部署镜像。部署镜像依赖于上一步的二进制包。其Dockerfile可能是这样的。</p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example for deploy</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    wget \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home \</span><br><span class="line">    &amp;&amp; wget http://artifactory.com/yygcui/0.0.1/myapp.tar.gz \</span><br><span class="line">    &amp;&amp; tar -xzvf myapp.tar.gz \</span><br><span class="line">    &amp;&amp; cd myapp \</span><br><span class="line">    &amp;&amp; ./install.sh</span><br><span class="line"></span><br><span class="line"># set run cmd</span><br><span class="line">ENTRYPOINT [&quot;myapp.bin&quot;]</span><br><span class="line">CMD [&quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><h2 id="总结一下"><a class="header-anchor" href="#总结一下"></a>总结一下</h2><p>从源码直接构建部署镜像，流程简单易行，自动化比较容易；但高度依赖于测试自动化，在构建的过程中需要完成基本的测试。而且每次都从源码构建，不利于前一步结果的复用(如进程测试、系统测试)。</p><p>容器化编译和容器化部署分成独立的两个过程，更像传统的流程。各种测试结果基本可以复用，但是增加了自动化的难度，管理二进制包的麻烦。</p><p>两种方法最终产生的部署镜像是一样的，具体用哪一种取决于你的构建流程。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;容器不是一个新技术，lxc已经存在了很长时间，但Docker却使它更加方便易用。Docker火了之后，我一直没有明白它为啥这么火，除了它宣称的轻量化之外，还有什么。它能做的事情，虚拟机都可以做，并且虚拟机有更好的隔离性。&lt;/p&gt;
&lt;p&gt;在使用场景上，貌似布道的更多的是环境一致性，即开发、测试、部署环境都能很好的保持一致。而至于在生产环境中使用它有什么好处，除了DevOps所倡导的自动化，简化运维，我就没有其他概念了。&lt;/p&gt;
&lt;p&gt;最近在研究微服务的东西，那么微服务必然需要DevOps，必然也就需要高度自动化。Docker，或者说容器，很好的迎合了这一契机。可以说Docker极大的简化了自动化部署的难度。本文就从最近的实践看一看以前没发现的好处。&lt;/p&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="docker" scheme="http://blog.cuicc.com/tags/docker/"/>
    
    <category term="compile" scheme="http://blog.cuicc.com/tags/compile/"/>
    
    <category term="deploy" scheme="http://blog.cuicc.com/tags/deploy/"/>
    
  </entry>
  
  <entry>
    <title>微服务</title>
    <link href="http://blog.cuicc.com/blog/2015/07/22/microservices/"/>
    <id>http://blog.cuicc.com/blog/2015/07/22/microservices/</id>
    <published>2015-07-22T13:12:31.000Z</published>
    <updated>2019-05-19T09:25:56.795Z</updated>
    
    <content type="html"><![CDATA[<p><em>翻译自Martin Fowler的<a href="http://martinfowler.com/articles/microservices.html">microservices</a>, 翻译于2015年7月22日。翻译尽量贴近原文，减少意译带入的个人观点，如有不当之处，请指正。</em></p><p>在过去几年中，“微服务架构”这一术语如雨后春笋般涌现出来，它描述了一种将软件应用程序设计为一组可独立部署的服务的特定方式。虽然这种架构风格没有明确的定义，但在组织、业务能力上有一些共同的特征：自动化部署，端点智能化，语言和数据的去中心化控制。</p><span id="more"></span><p>“微服务” - 软件架构拥挤大街上的有一个新术语。虽然我们自然的倾向是轻蔑的一瞥将它一带而过，然而我们发现这一术语描述了一种越来越吸引人的软件系统风格。我们已看到，在过去的几年中有许多项目使用了这种风格，并且到目前为止结果都还不错，以致于这已变成了我们同事在构建企业级应用程序时默认使用的架构风格。然而，遗憾的是并没有太多的信息来概述什么是微服务风格以及怎样用这种风格。</p><p>简单来说，微服务架构风格<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>是一种将一个单一应用程序开发为一组小型服务的方法，每个服务运行在自己的进程中，服务间通信采用轻量级通信机制(通常用HTTP资源API)。这些服务围绕业务能力构建并且可通过全自动部署机制独立部署。这些服务共用一个最小型的集中式的管理，服务可用不同的语言开发，使用不同的数据存储技术。</p><p>与单体风格作对比有助于开始解释微服务风格：单体应用程序被构建为单一单元。企业级应用程序通常由三部分组成：客户端侧用户接口(由运行于开发机上的浏览器里的HTML页面和Javascript组成)，数据库(由插入到通用关系型数据库管理系统中的许多数据表格组成)，服务端应用程序。服务端应用程序处理HTTP请求，执行领域逻辑，从数据库中检索、更新数据，选择、填充将要发送到浏览器的HTTP视图。服务端应用程序是一个单一的逻辑可执行单体<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。系统的任何改变都将牵涉到重新构建和部署服务端的一个新版本。</p><p>这样的单体服务器是构建这样一个系统最自然的方式。处理请求的所有逻辑都运行在一个单一进程中，允许你使用编程语言的基本特性将应用程序划分类、函数和命名空间。你认真的在开发机上运行测试应用程序，并使用部署管道来保证变更已被正确地测试并部署到生产环境中。该单体的水平扩展可以通过在负载均衡器后面运行多个实例来实现。</p><p>单体应用程序可以是成功的，但人们日益对他们感到挫败，尤其是随着更多的应用程序被部署在云上。变更周期被捆绑在一起 —— 即使只变更应用程序的一部分，也需要重新构建并部署整个单体。长此以往，通常将很难保持一个良好的模块架构，这使得很难变更只发生在需要变更的模块内。程序扩展要求进行整个应用程序的扩展而不是需要更多资源的应用程序部分的扩展。</p><img src="/images/sketch.png" class="" title="单体和微服务"><p>图1: 单体和微服务</p><p>这些挫败导向了微服务架构风格：构建应用程序为服务套件。除了服务是可独立部署、可独立扩展的之外，每个服务都提供一个固定的模块边界。甚至允许不同的服务用不同的的语言开发，由不同的团队管理。</p><p>我们不会声称微服务风格是新颖的、创新的，其本质至少可以回溯到Unix的设计哲学。但我们的确认为没有足够的人仔细考虑微服务架构，并且如果使用它很多软件实现将会更好。</p><h2 id="微服务架构的特征"><a class="header-anchor" href="#微服务架构的特征"></a>微服务架构的特征</h2><p>我们无法给出微服务架构风格的一个正式定义，但我们可以尝试去描述我们看到的符合该架构的一些共性。就概述共性的任何定义来说，并非所有的微服务架构风格都有这些共性，但我们期望大多数微服务架构风格展现出大多数特性。虽然本文作者一直是这个相当松散的社区的活跃用户，我们的目的是试图描述我们工作中和我们知道的一些团队的相似努力中的所见所闻。特别是我们不会制定一些可遵守的定义。</p><h3 id="通过服务组件化"><a class="header-anchor" href="#通过服务组件化"></a>通过服务组件化</h3><p>只要我们一直从事软件行业，一个愿望就是通过把组件插在一起构建系统，如同我们看到的现实世界中事物的构造方式一样。在最近的二十年中，我们看到作为大多数语言平台一部分的公共库的大量汇编工作取得了很大的进展。</p><p>当谈到组件时，我们遭遇困难的定义：组件是什么。我们的定义是：组件是一个可独立替换和独立升级的软件单元。</p><p>微服务架构将使用库，但组件化软件的主要方式是分解成服务。我们把库定义为链接到程序并使用内存函数调用来调用的组件，而服务是一种进程外的组件，它通过web服务请求或rpc(远程过程调用)机制通信(这和很多面向对象程序中的服务对象的概念是不同的<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。)</p><p>使用服务作为组件而不是使用库的一个主要原因是服务是可独立部署的。如果你有一个应用程序<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>是由单一进程里的多个库组成，任何一个组件的更改都导致必须重新部署整个应用程序。但如果应用程序可分解成多个服务，那么单个服务的变更只需要重新部署该服务即可。当然这也不是绝对的，一些变更将会改变服务接口导致一些协作，但一个好的微服务架构的目的是通过内聚服务边界和按合约演进机制来最小化这些协作。</p><p>使用服务作为组件的另一个结果是一个更加明确的组件接口。大多数语言没有一个好的机制来定义一个明确的<a href="http://martinfowler.com/bliki/PublishedInterface.html">发布接口</a>。通常只有文档和规则来预防客户端打破组件的封装，这导致组件间过于紧耦合。服务通过明确的远程调用机制可以很容易的避免这些。</p><p>像这样使用服务确实有一些缺点，远程调用比进程内调用更昂贵，因此远程API被设计成粗粒度，这往往更不便于使用。如果你需要更改组件间的责任分配，当你跨进程边界时，这样的行为动作更难达成。</p><p>直观的估计，我们观察到服务与运行时进程一一映射，但这仅仅是直观的估计而已。一个服务可能由多进程组成，这些进程总是被一起开发和部署，比如只被这个服务使用的应用进程和数据库。</p><h3 id="围绕业务能力组织"><a class="header-anchor" href="#围绕业务能力组织"></a>围绕业务能力组织</h3><p>当想要把大型应用程序拆分成部件时，通常管理层聚焦在技术层面，导致UI团队、服务侧逻辑团队、数据库团队的划分。当团队按这些技术线路划分时，即使是简单的更改也会导致跨团队的时间和预算审批。一个聪明的团队将围绕这些优化，两害取其轻 - 只把业务逻辑强制放在它们会访问的应用程序中。换句话说，逻辑无处不在。这是Conway法则<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>在起作用的一个例子。</p><blockquote><p>任何设计系统(广泛定义的)的组织将产生一种设计，他的结构就是该组织的通信结构。</p><footer><strong>-- Melvyn Conway</strong><cite>1967</cite></footer></blockquote><img src="/images/conways-law.png" class="" title="Conway法则"><p>图2: Conway法则在起作用</p><p>微服务采用不同的分割方法，划分成围绕业务能力组织的服务。这些服务采取该业务领域软件的宽栈实现，包括用户接口、持久化存储和任何外部协作。因此，团队都是跨职能的，包括开发需要的全方位技能：用户体验、数据库、项目管理。</p><img src="/images/PreferFunctionalStaffOrganization.png" class=""><p>图3: 团队边界增强的服务边界</p><p><a href="www.comparethemarket.com">www.comparethemarket.com</a>是按这种方式组织的一个公司。跨职能团队负责创建和运营产品，产品被划分成若干个体服务，这些服务通过消息总线通信。</p><p>大型单体应用程序也总是可以围绕业务能力来模块化，虽然这不是常见的情况。当然，我们将敦促创建单体应用程序的大型团队将团队本身按业务线拆分。我们看到这种情况的主要问题是他们趋向于围绕太多的上下文进行组织。如果单体横跨了多个模块边界，对团队个体成员来说，很难把它们装进他们的短期记忆里。另外，我们看到模块化的路线需要大量的规则来强制实施。服务组件所要求的更加明确的分离，使得它更容易保持团队边界清晰。</p><blockquote><h3 id="侧边栏：微服务有多大？"><a class="header-anchor" href="#侧边栏：微服务有多大？"></a>侧边栏：微服务有多大？</h3><p>虽然，“微服务”已成为这种架构风格的代称，这个名字确实会导致不幸的聚焦于服务的大小，并为“微”由什么组成争论不休。在与微服务实践者的对话中，我们发现有各种大小的服务。最大的服务报道遵循亚马逊两匹萨团队(也就是，整个团队吃两个披萨就吃饱了)的理念，这意味着团队不超过12个人。在更小的规模大小上，我们看到这样的安排，6人团队将支持6个服务。</p><p>这导致这样一个问题，在服务每12个人和服务每1个人的大小范围内，是否有足够大的不同使他们不能被集中在同一微服务标签下。目前，我们认为最好把它们组合在一起。但随着深入探索这种风格，我们一定有可能改变我们的看法。</p></blockquote><h3 id="是产品不是项目"><a class="header-anchor" href="#是产品不是项目"></a>是产品不是项目</h3><p>我们看到大多数应用程序开发工作使用一个项目模式：目标是交付将要完成的一些软件。完成后的软件被交接给维护组织，然后它的构建团队就解散了。</p><p>微服务支持者倾向于避免这种模式，而是认为一个团队应该负责产品的整个生命周期。对此一个共同的启示是亚马逊的理念 <a href="https://queue.acm.org/detail.cfm?id=1142065">“you build, you run it”</a> ，开发团队负责软件的整个产品周期。这使开发者经常接触他们的软件在生产环境如何工作，并增加与他们的用户联系，因为他们必须承担至少部分的支持工作。</p><p>产品思想与业务能力紧紧联系在一起。要持续关注软件如何帮助用户提升业务能力，而不是把软件看成是将要完成的一组功能。</p><p>没有理由说为什么同样的方法不能用在单体应用程序上，但服务的粒度更小，使得它更容易在服务开发者和用户之间建立个人关系。</p><h3 id="智能端点和哑管道"><a class="header-anchor" href="#智能端点和哑管道"></a>智能端点和哑管道</h3><p>当在不同进程间创建通信结构时，我们已经看到了很多的产品和方法，把显著的智慧强压进通信机制本身。一个很好的例子就是企业服务总线(ESB)，在ESB产品中通常为消息路由、编排(choreography)、转化和应用业务规则引入先进的设施。</p><p>微服务社区主张另一种方法：智能端点和哑管道。基于微服务构建的应用程序的目标是尽可能的解耦和尽可能的内聚 - 他们拥有自己的领域逻辑，他们的行为更像经典UNIX理念中的过滤器 - 接收请求，应用适当的逻辑并产生响应。使用简单的REST风格的协议来编排他们，而不是使用像WS-Choreography或者BPEL或者通过中心工具编制(orchestration)等复杂的协议。</p><p>最常用的两种协议是使用资源API的HTTP请求-响应和轻量级消息传送<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。对第一种协议最好的表述是</p><blockquote><p>本身就是web，而不是隐藏在web的后面。</p><footer><strong>--</strong><cite><a href="http://www.amazon.com/gp/product/0596805829?ie=UTF8&tag=martinfowlerc-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0596805829">Ian Robinson</a></cite></footer></blockquote><p>微服务团队使用的规则和协议，正是构建万维网的规则和协议(在更大程度上，是UNIX的)。从开发者和运营人员的角度讲，通常使用的资源可以很容易的缓存。</p><p>第二种常用方法是在轻量级消息总线上传递消息。选择的基础设施是典型的哑的(哑在这里只充当消息路由器) - 像RabbitMQ或ZeroMQ这样简单的实现仅仅提供一个可靠的异步交换结构 - 在服务里，智能仍旧存活于端点中，生产和消费消息。</p><p>单体应用中，组件都在同一进程内执行，它们之间通过方法调用或函数调用通信。把单体变成微服务最大的问题在于通信模式的改变。一种幼稚的转换是从内存方法调用转变成RPC，这导致频繁通信且性能不好。相反，你需要用粗粒度通信代替细粒度通信。</p><h3 id="去中心化治理"><a class="header-anchor" href="#去中心化治理"></a>去中心化治理</h3><p>集中治理的一个后果是单一技术平台的标准化发展趋势。经验表明，这种方法正在收缩 - 不是每个问题都是钉子，不是每个问题都是锤子。我们更喜欢使用正确的工具来完成工作，而单体应用程序在一定程度上可以利用语言的优势，这是不常见的。</p><p>把单体的组件分裂成服务，在构建这些服务时可以有自己的选择。你想使用Node.js开发一个简单的报告页面？去吧。用C++实现一个特别粗糙的近乎实时的组件？好极了。你想换用一个更适合组件读操作数据的不同风格的数据库？我们有技术来重建它。</p><p>当然，仅仅因为你可以做些什么，而不意味着你应该这样做 - 但用这种方式划分系统意味着你可以选择。</p><p>团队在构建微服务时也更喜欢用不同的方法来达标。他们更喜欢生产有用的工具这种想法，而不是写在纸上的标准，这样其他开发者可以用这些工具解决他们所面临的相似的问题。有时，这些工具通常在实施中收获并与更广泛的群体共享，但不完全使用一个内部开源模型。现在git和github已经成为事实上的版本控制系统的选择，在内部开放源代码的实践也正变得越来越常见。</p><blockquote><h3 id="侧边栏：微服务和SOA"><a class="header-anchor" href="#侧边栏：微服务和SOA"></a>侧边栏：微服务和SOA</h3><p>当我们谈论微服务时，一个常见问题是它是否仅仅是十年前我们看到的面向服务的架构(SOA)。这一点是有可取之处的，因为微服务风格和SOA赞同的某些主张十分相似。然而，问题是SOA意味着<a href="http://martinfowler.com/bliki/ServiceOrientedAmbiguity.html">很多不同的东西</a>，而大多数时候，我们遇到的所谓的SOA和这里我们描述的风格明显不同，这种不同通常由于SOA专注于用于集成单体应用的ESB。</p><p>特别是我们已看到太多的搞砸的服务导向的实现，从趋向于隐藏ESB中的复杂性<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>，到花费数百万并不产生任何价值的失败的多年举措，到积极抑制变化的集中治理模型，这有时很难看到过去的这些问题。</p><p>当然，微服务社区用到的许多技术从开发者在大型组织机构整合服务的经验中成长。<a href="http://martinfowler.com/bliki/TolerantReader.html">Tolerant Reader</a>模式就是这样的一个例子。使用简单协议是衍生自这些经验的另一个方法，使用网络的努力已做出远离中央标准的反应，坦率地说，中心标准已达到<a href="http://wiki.apache.org/ws/WebServiceSpecifications">令人叹为观止</a>的复杂性。(任何时候，你需要一个本体来管理你的本体，你知道你深陷困境。)</p><p>SOA的这种常见表现使得一些微服务倡导者完全拒绝SOA标签，尽管其他人认为微服务是SOA的一种形式<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>，也许服务导向做得对。无论哪种方式，事实上，SOA意味着如此不同的事情，这意味着有一个术语来更清晰地定义这种架构风格是有价值的。</p></blockquote><p>Netflix是遵守这一理念的很好的例子。尤其是，以库的形式分享有用的且经过市场检验的代码，这激励其他开发者用类似的方式解决相似的问题，同时还为采用不同方法敞开了大门。共享库倾向于聚焦在数据存储、进程间通信和我们接下来要深入讨论的基础设施自动化的共性问题。</p><p>对为服务社区来说，开销特别缺乏吸引力。这并不是说社区不重视服务合约。恰恰相反，因为他们有更多的合约。只是他们正在寻找不同的方式来管理这些合约。像<a href="http://martinfowler.com/bliki/TolerantReader.html">Tolerant Reader</a>和消费者驱动的契约(<a href="http://martinfowler.com/articles/consumerDrivenContracts.html">Consumer-Driven Contracts</a>)这样的模式通常被用于微服务。<br>这些援助服务合约在独立进化。执行消费者驱动的合约作为构建的一部分，增加了信心并对服务是否在运作提供了更快的反馈。事实上，我们知道澳大利亚的一个团队用消费者驱动的合约这种模式来驱动新业务的构建。他们使用简单的工具定义服务的合约。这已变成自动构建的一部分，即使新服务的代码还没写。服务仅在满足合约的时候才被创建出来 - 这是在构建新软件时避免&quot;YAGNI&quot;<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>困境的一个优雅的方法。围绕这些成长起来的技术和工具，通过减少服务间的临时耦合，限制了中心合约管理的需要。</p><blockquote><h3 id="侧边栏：许多语言，许多选项"><a class="header-anchor" href="#侧边栏：许多语言，许多选项"></a>侧边栏：许多语言，许多选项</h3><p>JVM作为平台的成长就是在一个共同平台内混合语言的最新例子。几十年来，破壳到高级语言利用高层次抽象的优势已成为一种普遍的做法。如同下拉到机器硬件，用低层次语言写性能敏感的代码一样。然而，很多单体不需要这个级别的性能优化和常见的更高层次的抽象，也不是DSL的。相反，单体通常是单一语言的并趋向于限制使用的技术的数量<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。</p></blockquote><p>也许去中心化治理的最高境界就是亚马逊广为流传的build it/run it理念。团队要对他们构建的软件的各方面负责，包括7*24小时的运营。这一级别的责任下放绝对是不规范的，但我们看到越来越多的公司让开发团队负起更多责任。Netflix是采用这一理念的另一家公司<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。每天凌晨3点被传呼机叫醒无疑是一个强有力的激励，使你在写代码时关注质量。这是关于尽可能远离传统的集中治理模式的一些想法。</p><h3 id="去中心化数据管理"><a class="header-anchor" href="#去中心化数据管理"></a>去中心化数据管理</h3><p>数据管理的去中心化有许多不同的呈现方式。在最抽象的层面上，这意味着使系统间存在差异的世界概念模型。在整合一个大型企业时，客户的销售视图将不同于支持视图，这是一个常见的问题。客户的销售视图中的一些事情可能不会出现在支持视图中。它们确实可能有不同的属性和(更坏的)共同属性，这些共同属性在语义上有微妙的不同。</p><p>这个问题常见于应用程序之间，但也可能发生在应用程序内部，尤其当应用程序被划分成分离的组件时。一个有用的思维方式是有界上下文(<a href="http://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>)内的领域驱动设计(Domain-Driven Design, DDD)理念。DDD把一个复杂域划分成多个有界的上下文，并且映射出它们之间的关系。这个过程对单体架构和微服务架构都是有用的，但在服务和上下文边界间有天然的相关性，边界有助于澄清和加强分离，就像业务能力部分描述的那样。</p><blockquote><h3 id="侧边栏：久经考验的标准和执行标准"><a class="header-anchor" href="#侧边栏：久经考验的标准和执行标准"></a>侧边栏：久经考验的标准和执行标准</h3><p>这有一点分裂，微服务团队倾向于避开企业架构组规定的那种严格的执行标准，但又很乐意使用甚至传教开放标准，比如HTTP、ATOM和其他威格士。</p><p>关键的区别是如何定制标准和如何执行。由诸如IETF等组织管理的标准仅当在世界范围内有几个有用的实现时才变成标准，这往往会从成功的开源项目成长起来。</p><p>这些标准是远离企业世界的标准。往往被一个几乎没有近期编程经验的或受供应商过度影响的组织开发的。</p></blockquote><p>和概念模型的去中心化决策一样，微服务也去中心化数据存储决策。虽然单体应用程序更喜欢单一的逻辑数据库做持久化存储，但企业往往倾向于一系列应用程序共用一个单一的数据库 - 这些决定是供应商授权许可的商业模式驱动的。微服务更倾向于让每个服务管理自己的数据库，或者同一数据库技术的不同实例，或完全不同的数据库系统 - 这就是所谓的混合持久化(<a href="http://martinfowler.com/bliki/PolyglotPersistence.html">Polyglot Persistence</a>)。你可以在单体应用程序中使用混合持久化，但它更常出现在为服务里。</p><img src="/images/decentralised-data.png" class="" title="去中心化数据"><p>对跨微服务的数据来说，去中心化责任对管理升级有影响。处理更新的常用方法是在更新多个资源时使用事务来保证一致性。这个方法通常用在单体中。</p><p>像这样使用事务有助于一致性，但会产生显著地临时耦合，这在横跨多个服务时是有问题的。分布式事务是出了名的难以实现，因此微服务架构强调<a href="http://www.eaipatterns.com/ramblings/18_starbucks.html">服务间的无事务协作</a>，对一致性可能只是最后一致性和通过补偿操作处理问题有明确的认知。</p><p>对很多开发团队来说，选择用这样的方式管理不一致性是一个新的挑战，但这通常与业务实践相匹配。通常业务处理一定程度的不一致，以快速响应需求，同时有某些类型的逆转过程来处理错误。这种权衡是值得的，只要修复错误的代价小于更大一致性下损失业务的代价。</p><h3 id="基础设施自动化"><a class="header-anchor" href="#基础设施自动化"></a>基础设施自动化</h3><p>在过去的几年中，基础设施自动化已经发生了巨大的变化，特别是云和AWS的演化已经降低了构建、部署和运维微服务的操作复杂度。</p><p>许多用微服务构建的产品或系统是由在<a href="http://martinfowler.com/bliki/ContinuousDelivery.html">持续部署</a>和它的前身<a href="http://martinfowler.com/articles/continuousIntegration.html">持续集成</a>有丰富经验的团队构建的。团队用这种方式构建软件，广泛使用了基础设施自动化。如下面的构建管线图所示：</p><img src="/images/basic-pipeline.png" class="" title="基础构建管道"><p>图5: 基础构建管道</p><p>因为这不是一篇关于持续交付的文章，我们这里将之光住几个关键特性。我们希望有尽可能多的信心，我们的软件正在工作，所以我们运行大量的<strong>自动化测试</strong>。促进科工作软件沿管道线“向上”意味着我们<strong>自动化部署</strong>到每个新的环境中。</p><p>一个单体应用程序可以十分愉快地通过这些环境被构建、测试和推送。事实证明，一旦你为单体投入了自动化生产之路，那么部署更多的应用程序似乎也不会更可怕。请记住，持续部署的目标之一是使部署枯燥，所以无论是一个或三个应用程序，只要它的部署仍然枯燥就没关系<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>。</p><blockquote><h3 id="侧边栏：使它容易做正确的事情"><a class="header-anchor" href="#侧边栏：使它容易做正确的事情"></a>侧边栏：使它容易做正确的事情</h3><p>我们发现，作为持续交付和持续部署的一个后果，增加自动化的一个副作用是创造有用的工具，以帮助开发人员和运营人员。用于创造人工制品、管理代码库、起立(standing up)简单服务或添加标准监控和日志记录的工具现在都是很常见的。web上最好的例子可能是<a href="http://netflix.github.io/">Netflix的开源工具集</a>，但也有其他我们广泛使用的工具，如<a href="http://dropwizard.codahale.com/">Dropwizard</a>。</p></blockquote><p>我们看到团队使用大量的基础设施自动化的另一个领域是在生产环境中管理微服务时。与我们上面的断言(只要部署是枯燥的)相比，单体和微服务没有太大的差别，各运营场景可以明显不同。</p><img src="/images/micro-deployment.png" class="" title="微部署"><p>图6: 模块部署常常不同</p><h3 id="为失效设计"><a class="header-anchor" href="#为失效设计"></a>为失效设计</h3><p>使用服务作为组件的一个结果是，应用程序需要被设计成能够容忍服务失效。任何服务调用都可能因为供应者不可用而失败，客户端必须尽可能优雅的应对这种失败。与单体应用设计相比这是一个劣势，因为它引入额外的复杂性来处理它。结果是，微服务团队不断反思服务失效如何影响用户体验。Netflix的<a href="https://github.com/Netflix/SimianArmy">Simian Army</a>在工作日诱导服务甚至是数据中心故障来测试应用程序的弹性和监测。</p><p>在生产环境中的这种自动化测试足够给大多数运营团队那种不寒而栗，通常在结束一周的工作之前。这不是说单体风格不能够进行完善的监测设置，只是在我们的经验中比较少见。</p><blockquote><h3 id="侧边栏：断路器和产品就绪代码"><a class="header-anchor" href="#侧边栏：断路器和产品就绪代码"></a>侧边栏：断路器和产品就绪代码</h3><p><a href="http://martinfowler.com/bliki/CircuitBreaker.html">断路器(Circuit Breaker)</a>与其他模式如Bulkhead和Timeout出现在<a href="http://www.amazon.com/gp/product/B00A32NXZO?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00A32NXZO">《Release it!》</a>中。这些模式是被一起实现的，在构建通信应用程序时，它们是至关重要的。<a href="http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html">这篇Netflix博文</a>很好的解释了使用这些模式的应用程序。</p></blockquote><p>既然服务随时都可能失败，那么能够快速检测故障，如果可能的话，能自动恢复服务是很重要的。微服务应用程序投入大量比重来进行应用程序的实时监测，既检查构形要素(每秒多少次数据请求)，又检查业务相关指标(例如每分钟收到多少订单)。语义监测可以提供一套早期预警系统，触发开发团队跟进和调查。</p><p>这对微服务架构特别重要，因为微服务偏好编排和事件协作，这会带来突发行为。虽然很多专家称赞偶然涌现的价值，事实的真相是，突发行为有时可能是一件坏事请。监测对于快速发现不良突发行为是至关重要的，所以它可以被修复。</p><p>单体可以被构建成和微服务一样透明 - 事实上，它们应该是透明的。不同的是，你绝对需要知道在不同进程中运行的服务是否断开。对同一进程中的库来说，这种透明性是不大可能有用的。</p><blockquote><h3 id="侧边栏：同步调用被认为是有害的"><a class="header-anchor" href="#侧边栏：同步调用被认为是有害的"></a>侧边栏：同步调用被认为是有害的</h3><p>任何时候，在服务间有大量的同步调用，你将遇到停机的乘法效应。简单地说，就是你的系统的停机时间编程各个组件停机时间的乘积。你面临一个选择，让你的调用变成异步或者管理停机时间。<a href="http://xn--www-lp6e.guardian.co.uk">在www.guardian.co.uk</a>，他们已在新平台实现了一个简单的规则 - 每个用户请求一个同步调用，而在Netflix，他们的平台API重设计成在API交换结构(fabric)建立异步性。</p></blockquote><p>微服务团队希望看到为每个单独的服务设置的完善的监控和日志记录，比如控制面板上显示启动/关闭状态和各种各样的运营和业务相关指标。断路器状态、当前吞吐量和时延的详细信息是我们经常遇到的其他例子。</p><h3 id="进化式设计"><a class="header-anchor" href="#进化式设计"></a>进化式设计</h3><p>微服务从业者，通常有进化式设计背景并且把服务分解看做是进一步的工具，使应用程序开发者能够控制他们应用程序中的变更而不减缓变更。变更控制并不一定意味着变更的减少 - 用正确的态度和工具，你可以频繁、快速且控制良好的改变软件。</p><p>当你试图把软件系统组件化时，你就面临着如何划分成块的决策 - 我们决定分割我们的应用的原则是什么？组件的关键特性是独立的更换和升级的理念<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup> - 这意味着我们要找到这样的点，我们可以想象重写组件而不影响其合作者。事实上很多微服务群组通过明确地预期许多服务将被废弃而不是长期演进来进一步找到这些点。</p><p>卫报网站是被设计和构建成单体应用程序的一个好例子，但它已向微服务方向演化。网站的核心仍是单体，但他们喜欢通过使用调用单体API构建的微服务添加新功能。这种方法对天然临时性的特性特别方便，比如处理体育赛事的专题页面。网站的这样一部分可以使用快速开发语言迅速的被放在一起，并且一旦赛事结束立即删除。在金融机构中，我们看到类似的方法，为一个市场机会添加新服务，并在几个月甚至几周后丢弃掉。</p><p>强调可替代性是模块设计更一般原则的一个特例，它是通过变更模式来驱动模块化的<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>。你想保持在同一模块中相同时间改变的事情。系统中很少变更的部分应该和正在经历大量扰动的部分放在不同的服务里。如果你发现你自己不断地一起改变两个服务，这是它们应该被合并的一个标志。</p><p>把组件放在服务中，为更细粒度的发布计划增加了一个机会。对单体来说，任何变更都需要完整构建和部署整个应用程序。而对微服务来说，你只需要重新部署你修改的服务。这可以简化和加速发布过程。坏处是，你必须担心一个服务的变化会阻断其消费者。传统的集成方法试图使用版本管理解决这个问题，但是微服务世界的偏好是<a href="http://martinfowler.com/articles/enterpriseREST.html#versioning">只把版本管理作为最后的手段</a>。我们可以避免大量的版本管理，通过把服务设计成对他们的提供者的变化尽可能的宽容。</p><h2 id="微服务是未来吗？"><a class="header-anchor" href="#微服务是未来吗？"></a>微服务是未来吗？</h2><p>我们写这篇文章的主要目的是讲解微服务的主要思想和原则。通过花时间做这件事情，我们清楚地认为微服务架构风格是一个重要的思想 - 它值得为企业应用程序认真考虑。我们最近用这种风格构建了一些系统，也知道别人用这种风格并赞成这种风格。</p><p>那些我们知道的以某种方式开拓这种架构风格的包括亚马逊，Netflix，<a href="http://www.theguardian.com/">卫报</a>，<a href="https://gds.blog.gov.uk/">英国政府数字服务部门</a>，<a href="http://martinfowler.com/articles/realestate.com.au">realestate.com.au</a>，前锋和<a href="http://www.comparethemarket.com/">comparethemarket.com</a>。2013年的会议电路中全是正向微服务类别转移的公司 - 包括Travis CI。此外还有大量的组织长期以来一直在做可归为微服务类别的事情，但是还没有使用这个名字。(这通常被称为SOA - 虽然，正如我们说过的，SOA有许多矛盾的形式。<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>)</p><p>尽管有这些积极的经验，但是，我们并不认为我们确信微服务是软件架构的未来发展方向。虽然到目前为止，与单体应用程序相比，我们的经验是正面的，但我们意识到这样的事实，并没有经过足够的时间使我们做出充分的判断。</p><p>通常，你的架构决策的真正后果是在你做出这些决定的几年后才显现的。我们已经看到对模块化有强烈愿望的一个好团队用单体架构构建的项目，已经衰败了多年。很多人相信微服务是不太可能出现这种衰败的，因为服务界限是明确的，并且很难围绕它打补丁。然而，知道我们看到经过足够岁月的足够的系统，我们不能真正评估微服务架构有多么成熟。</p><p>人们当然有理由希望微服务是多么不成熟。在组件化中做任何努力，成功取决于软件在多大程度上适用于组件化。很难弄清楚组件边界在哪里。进化式设计承认获取正确边界的困难性和使它们易于重构的重要性。但当你的组件是带有远程通信的服务时，那么重构它比重构带有进程内库的服务难很多。跨服务边界移动代码是很困难的，任何接口变更都需要在参与者之间进行协调，需要添加向后兼容层，并且测试也变得更加复杂。</p><blockquote><h3 id="侧边栏：《构建微服务》"><a class="header-anchor" href="#侧边栏：《构建微服务》"></a>侧边栏：《构建微服务》</h3><p>我们的同事Sam Newman花费2014年的大部分时间写了<a href="http://www.amazon.com/gp/product/1491950358?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491950358">一本书</a>，捕捉了我们构建微服务的经验。如果你想深入到这个话题中，这应该是你的下一步。</p></blockquote><p>另一个问题是，如果组件不组成的干净利索，那么所有你做的是将复杂度从组件内部转移到组件之间的连接。不仅仅是把复杂性移到周围，它将复杂性移动到一个不太明确、难以控制的地方。在没有服务间的凌乱连接的情况下，当你在看一个小的、简单的组件内部时，你可以很容易的认为事情是更好的。</p><p>最后，有团队技能的因素。更熟练的团队倾向于采用新技术。但是对更熟练的团队更有效的一种技术不一定适合于不太熟练的团队。我们已经看到大量的例子，不太熟练的团队构建了凌乱的单体架构，但这需要时间去看当微服务发生这种凌乱时会发生什么。一个差的团队总是创建一个差的系统 - 很难讲在这个例子中微服务会减少这种凌乱还是使它更糟糕。</p><p>我们听到的一个合理的说法是，你不应该从微服务架构开始。相反，从单体开始，使它保持模块化，一旦单体成为问题时把它分解成微服务。(虽然这个建议是不理想的，因为一个好的进程内接口通常不是一个好的服务接口。)</p><p>所以我们怀着谨慎乐观的态度写了这篇文章。到目前为止，我们已经看到关于微服务风格足以觉得这是一条值得探索的路。我们不能肯定地说，我们将在哪里结束，但软件开发的挑战之一是，你只能基于目前能拿到手的不完善的信息作出决定。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>2011年5月在威尼斯召开的软件架构研讨会上，“微服务”这一术语被讨论用来描述参与者一直在探索的一种常见的架构风格。2012年5月，该研讨会决定使用“微服务”作为最合适的名字。2012年3月在波兰克拉科夫市举办的33届Degree大会上，James介绍了这些想法作为一个案例研究<a href="http://2012.33degree.org/talk/show/67">微服务 - Java，Unix方式</a>，Fred George也<a href="http://www.slideshare.net/fredgeorge/micro-service-architecure">差不多在同一时间</a>提出。Netflix的Adrian Cockcroft把这种方法描述为“细粒度的SOA”，在网域级开拓了这一风格，还有在该文中提到的许多人 - Joe Walnes, Dan North, Evan Botcher 和 Graham Tackley。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>单体这一术语已被Unix社区使用了一段时间，在<a href="http://www.amazon.com/gp/product/B003U2T5BA?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B003U2T5BA">《Unix编程艺术》</a>中用它来描述非常大的系统。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>很多面向对象的设计人员，包括我们自己，在<a href="http://www.amazon.com/gp/product/0321125215?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321125215">领域驱动设计</a>意义上使用服务对象术语，该对象不依赖于实体执行一个重要进程。这和我们在本文中如何使用“服务”是不同的概念。不幸的是，服务这个词有两个含义，我们不得不忍受这个多义词。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>我们认为<a href="http://martinfowler.com/bliki/ApplicationBoundary.html">应用程序是一个社会结构</a>，它由代码基、功能组、资金体组合在一起。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>原文可在Melvyn Conway的网站上找到，<a href="http://www.melconway.com/Home/Committees_Paper.html">在这里</a>。 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>在极端规模下，组织通常移至二进制协议并权衡规模的透明度。例如<a href="">protobufs</a>。使用二进制协议的系统仍旧展现出智能端点、哑管道。大多数网站，当然绝大多数企业不需要做这种权衡，透明度可以是一个很大的胜利。 <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>我们忍不住提起Jim Webber的说法，ESB全称是<a href="http://www.infoq.com/presentations/soa-without-esb">“令人震惊的意大利面条盒”</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>Netflix使这种联系清晰起来 - 直到最近作为细粒度SOA提及他们的架构风格。 <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>“YAGNI”也就是“You Aren’t Going To Need It(你将不需要它)”是一个<a href="http://c2.com/cgi/wiki?YouArentGonnaNeedIt">XP原则</a>和劝诫，在你知道你需要它们时才添加特性 <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>我们声称单体是单一语言的，这有一点不诚实 - 要在现在web上构建系统，你可能需要知道JavaScript、XHTML、CSS、选择的服务器语言、SQL和ORM方言。很难只用单一语言，但是你知道我的意思。 <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>在2013年11月的Flowcon大会上提交的<a href="http://www.slideshare.net/adrianco/flowcon-added-to-for-cmg-keynote-talk-on-how-speed-wins-and-how-netflix-is-doing-continuous-delivery">这个出色演讲中</a>，Adrian Cockcroft特别提到“开发者自助服务”和“开发者运行他们自己写的代码”(原文如此)。 <a href="#fnref11" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>我们这里有一点不诚实。显然在更复杂的拓扑结构中部署更多的服务要比部署单一单体更困难。幸运的是，模式减少了这种复杂性 - 在工具上的投资仍是必须的。 <a href="#fnref12" class="footnote-backref">↩︎</a></p></li><li id="fn13" class="footnote-item"><p>事实上，Dan North提到这种风格是可更换的组件架构而不是微服务。因为这似乎是在讨论我们更喜欢的后者的一个特征子集。 <a href="#fnref13" class="footnote-backref">↩︎</a></p></li><li id="fn14" class="footnote-item"><p>Kent Beck强调这是他<a href="http://www.amazon.com/gp/product/0321413091?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321413091">《实现模式》</a>一书中的设计原则之一。 <a href="#fnref14" class="footnote-backref">↩︎</a></p></li><li id="fn15" class="footnote-item"><p>SOA几乎是这段历史的根源。我记得当SOA这一术语出现在本世纪初时，有人说“多年来我们一直这样做”。一个理由是，这种风格看其根源是在企业计算早期COBOL程序通过数据文件通信的方式。在另一个方向，有人可能会说微服务和Erlang编程模型相同，但被应用于企业应用程序上下文。 <a href="#fnref15" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;em&gt;翻译自Martin Fowler的&lt;a href=&quot;http://martinfowler.com/articles/microservices.html&quot;&gt;microservices&lt;/a&gt;, 翻译于2015年7月22日。翻译尽量贴近原文，减少意译带入的个人观点，如有不当之处，请指正。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在过去几年中，“微服务架构”这一术语如雨后春笋般涌现出来，它描述了一种将软件应用程序设计为一组可独立部署的服务的特定方式。虽然这种架构风格没有明确的定义，但在组织、业务能力上有一些共同的特征：自动化部署，端点智能化，语言和数据的去中心化控制。&lt;/p&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="microservices" scheme="http://blog.cuicc.com/tags/microservices/"/>
    
    <category term="微服务" scheme="http://blog.cuicc.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>无处不在的长尾</title>
    <link href="http://blog.cuicc.com/blog/2015/05/12/notes-about-the-longtail-theory/"/>
    <id>http://blog.cuicc.com/blog/2015/05/12/notes-about-the-longtail-theory/</id>
    <published>2015-05-12T12:24:28.000Z</published>
    <updated>2019-04-01T13:24:17.312Z</updated>
    
    <content type="html"><![CDATA[<h2 id="80-20法则"><a class="header-anchor" href="#80-20法则"></a>80/20法则</h2><p>传统经济中，经济行为通常满足80/20法则，例如20%的产品创造了80%的销售额。这20%也就是所谓的热门产品。</p><blockquote><p><a href="http://book.douban.com/subject/3038761/" title="《80/20法则》">《80/20法则》</a>认为，少量的原因、投入和付出将获得大量的结果、产出和回报。<br>从该法则可以看出，在原因与结果、投入与产出、付出与回报之间存在着一种内在的失衡。</p></blockquote><h2 id="more-热门经济学"><a class="header-anchor" href="#more-热门经济学"></a><span id="more"></span><br>热门经济学</h2><p>热门之所以存在，是因为供给匮乏，我们没有足够的空间为每一个人提供每一样东西。如果只有那么几个货架、几个波段，唯一明智的做法就是把它们留给最热门的东西。</p><h2 id="地理和物理的限制"><a class="header-anchor" href="#地理和物理的限制"></a>地理和物理的限制</h2><p>热门是怎么产生的呢，热门产品是被大众普遍喜爱的产品。大众之所以体现出一定共性，是因为选择比较少。与其说是大众热门，不如说大众被热门。</p><p>例如电视节目，在有限的时间、有限的频段下，电视台只能靠黄金时间，打造热门节目。<br>例如企业制造，只能主力制造本地所需的产品，削减不需要产品种类。</p><h2 id="丰饶经济学"><a class="header-anchor" href="#丰饶经济学"></a>丰饶经济学</h2><p>当我们文化中的供需瓶颈开始消失，所有产品都能被人取得的时候，长尾便会自然发生。</p><p>那么地理和物理的限制不存在了吗？</p><p>限制仍旧存在，只不过技术发展、运输网络完善使这些限制的影响变的微不足道，特别是互联网的发展。试想一下，在一个没有货架空间限制(网上商城可以展示所有商品)和其他供应瓶颈的时代，任何产品都可以被方便的发现，面向特定小众群体的产品将和人们产品有同样的吸引力。</p><h2 id="长尾无处不在"><a class="header-anchor" href="#长尾无处不在"></a>长尾无处不在</h2><p>那么什么是长尾，长尾是相对于热门而言的，处于热门之外的产品种类。如果将长尾上的小批量多品种生意集合成一个生意，这个生意可以同大热门生意分享同样的利润。</p><p>这打破了传统经济中的80/20法则。例如亚马逊热门图书和长尾图书，在线音乐网站的热门音乐和长尾音乐。</p><p>长尾之所以无处不在，是因为</p><p>###生产工具的普及<br>业余爱好者利用先进的工具能做大以前只有专业人士才能做得事。这大大丰富了产品多样性。<br>###网络是最好的口碑放大器<br>产品再多，如果无人欣赏，一切便毫无意义。互联网的出现，大大降低了接触消费者的成本。消费者在网店上可以接触到应有尽有的商品市场。<br>###过滤让人们能找到任何东西<br>产品应有尽有，消费者如何快速找到想要的小众产品，离不开搜索引擎的帮助。</p><h2 id="利基市场"><a class="header-anchor" href="#利基市场"></a>利基市场</h2><blockquote><p>是指由已有市场绝对优势的企业所忽略的某些细分市场并且在此市场尚未有完善的供应服务。一般由较小的产品市场并具有持续发展的潜力中一些需要且尚未被满足的族群消费者所组成为了满足特定的市场需求，价格区间，产品质量，针对细分后的产品进入这个小型市场且有盈利的基础。经由专业化的经营将品牌意识灌输到该特定消费者族群中逐渐形成该族群的领导品牌。</p><footer><strong>利基市场</strong><cite><a href="http://zh.wikipedia.org/wiki/%E5%88%A9%E5%9F%BA%E5%B8%82%E5%9C%BA">维基百科</a></cite></footer></blockquote><p>利基市场，从维基百科定义来看，也即长尾经济，通过发掘或扩展已有市场的长尾市场，获取特定群体的青睐。</p><p>例如豆瓣，面向文艺青年的社区</p><p>例如途牛，在携程大旅游平台下发展在线旅游。</p><p>例如陌陌，在微信一统移动IM下在陌生人社交中独占一隅。</p><p>例如YY，在QQ雄霸IM市场下在团队语音市场越战越勇。</p><p>在你想做的领域，你想到了什么？</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;80-20法则&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#80-20法则&quot;&gt;&lt;/a&gt;80/20法则&lt;/h2&gt;
&lt;p&gt;传统经济中，经济行为通常满足80/20法则，例如20%的产品创造了80%的销售额。这20%也就是所谓的热门产品。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://book.douban.com/subject/3038761/&quot; title=&quot;《80/20法则》&quot;&gt;《80/20法则》&lt;/a&gt;认为，少量的原因、投入和付出将获得大量的结果、产出和回报。&lt;br&gt;
从该法则可以看出，在原因与结果、投入与产出、付出与回报之间存在着一种内在的失衡。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;more-热门经济学&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#more-热门经济学&quot;&gt;&lt;/a&gt;</summary>
    
    
    
    <category term="读书笔记" scheme="http://blog.cuicc.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="longtail" scheme="http://blog.cuicc.com/tags/longtail/"/>
    
    <category term="长尾理论" scheme="http://blog.cuicc.com/tags/%E9%95%BF%E5%B0%BE%E7%90%86%E8%AE%BA/"/>
    
    <category term="读书笔记" scheme="http://blog.cuicc.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>

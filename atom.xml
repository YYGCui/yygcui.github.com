<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YYGCui</title>
  <icon>https://www.gravatar.com/avatar/8623bca8bca8b2403fc46e7694f4b7f0</icon>
  <subtitle>思考自然的本性，抚摸上帝的脉搏</subtitle>
  <link href="http://blog.cuicc.com/atom.xml" rel="self"/>
  
  <link href="http://blog.cuicc.com/"/>
  <updated>2025-08-23T12:20:44.411Z</updated>
  <id>http://blog.cuicc.com/</id>
  
  <author>
    <name>YYGCui</name>
    <email>yygcui@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>智能驾驶 DevOps</title>
    <link href="http://blog.cuicc.com/blog/2025/08/03/devops-for-intelligent-driving/"/>
    <id>http://blog.cuicc.com/blog/2025/08/03/devops-for-intelligent-driving/</id>
    <published>2025-08-03T06:33:30.000Z</published>
    <updated>2025-08-23T12:20:44.411Z</updated>
    
    <content type="html"><![CDATA[<p>DevOps 这一开发理念在2009年被提出后，经过十几年的发展，已经非常成熟了，特别是在微服务架构被提出并流行开来，进一步推动 DevOps 实践深入发展。DevOps 既然已经这么成熟了，我们为啥还要写这个话题？笔者认为理念是成熟的，但应用的业务场景是日新月异的，怎么把这一成熟的理念应用到各种业务场景，还是有不少挑战的；再者这也是参与各种职位后做的经验，结合ChatGPT的解答，总结的笔记。由于没有涉猎所有的环节对应的职位，如有不当之处请指正。开篇之前，先对齐一下基本概念。</p><h2 id="DevOps-是什么"><a class="header-anchor" href="#DevOps-是什么"></a>DevOps 是什么</h2><blockquote><p>DevOps 是软件开发与信息技术运维的整合及自动化实践[a]。这一方法论涵盖了软件开发的关键环节，能有效缩短开发周期并优化全生命周期管理[1]。Neal Ford指出，DevOps（尤其是通过持续交付实现时）遵循&quot;痛点前置&quot;原则——通过尽早处理复杂任务、推动自动化建设及快速发现问题来提升效率[2]。软件工程师与架构师应当运用适应性函数（fitness functions）来确保系统健康度[3]。</p><p>尽管存在学术争议[b][c][d][e]，DevOps仍以三大核心原则为特征：责任共担、工作流自动化及快速反馈机制。来自澳大利亚联邦科学与工业研究组织（CSIRO）和软件工程研究所的三位计算机科学家Len Bass、Ingo Weber与Liming Zhu从学术角度提出定义：“DevOps是一套旨在保证高质量的前提下，显著缩短系统变更提交到正式生产环境所用时间的实践集合”[7]。不过该术语在实际应用中存在多重解读。最成功的DevOps实施往往需要特定实践、文化转型与工具链三者的有机结合[8]。</p><footer><strong>Wikipedia</strong><cite><a href="https://en.wikipedia.org/wiki/DevOps">DevOps</a></cite></footer></blockquote><div align="center"><img width="50%" alt="devops" src="/images/devops/devops-infinite-loop.png" /></div><h2 id="智能驾驶是什么"><a class="header-anchor" href="#智能驾驶是什么"></a>智能驾驶是什么</h2><blockquote><p>智能驾驶（Intelligent Driving） 是指利用人工智能、传感器技术、通信技术和自动控制技术，使车辆具备 感知环境、理解交通、做出决策并执行驾驶操作 的能力。它是自动驾驶、智能辅助驾驶（ADAS）等系统的统称。</p><p>通俗的讲，智能驾驶就是让“车自己能看、能想、能动”，像一个具备初级智慧的司机那样安全行驶。</p><p>国际汽车工程师学会发布的自动驾驶分级 L0 - L5，大家更为熟知，从人工驾驶到完全自动驾驶</p><footer><strong>Wikipedia</strong><cite><a href="https://zh.wikipedia.org/zh-cn/%E8%87%AA%E5%8B%95%E9%A7%95%E9%A7%9B%E6%B1%BD%E8%BB%8A">自动驾驶汽车</a></cite></footer></blockquote><div align="center"><img width="50%" alt="intelligent-driving" src="/images/devops/devops-human-vs-auto.png" /></div><h2 id="智能驾驶-DevOps-是什么"><a class="header-anchor" href="#智能驾驶-DevOps-是什么"></a>智能驾驶 DevOps 是什么</h2><p>智能驾驶 DevOps 是将 DevOps 理念和工具链应用于智能驾驶系统的开发、测试、部署和运营全过程，目标是：</p><ul><li>提高研发效率（CI/CD 自动化）</li><li>加速版本迭代（高频交付）</li><li>保证系统质量（自动测试、回归）</li><li>支撑多车型、多平台、大量数据的复杂工程体系</li></ul><p>数据是智能驾驶的基础、支撑、引擎和保障，贯穿了从模型训练、功能开发、仿真测试到问题定位的全生命周期，数据闭环是我们常听到的智能驾驶常提的一个概念，数据闭环的实现离不开智能驾驶 DevOps 的三驾马车。</p><ul><li>Cloud Service DevOps (云服务 DevOps): 数据平台是云服务 DevOps 的实践体现，以数据为中心构建的云服务平台，承载基础设施资源运维、数据管理、云服务以及工具链的开发运维；</li><li>Vehicle Soc DevOps (车端嵌入式系统 DevOps): 不同于云服务，嵌入式系统有另一套开发流程，依托于效能云服务，承载了车端版本规划、开发、构建、测试、发布的整个流程，同时量产车云服务承载了车端版本的运维、运营和监控；</li><li>AI Model DevOps (模型 DevOps): 数据采集上云、标注、模型训练、模型发布等AI服务则构建了模型 DevOps 的整体链路，同时通过车端版本测试和运营。</li></ul><div align="center"><img width="70%" alt="auto-devops" src="/images/devops/devops-intelligence-driving-3loops.png" /></div><p>前面 DevOps 概念提到，DevOps 是软件开发与信息技术运维的整合及自动化实践。自动化的前提是什么，是策略（或者说是规则），有策略才能实现自动化。这是很重要的一点，是我们整个实现的基石。在开始探讨DevOps的8个核心环节之前，我们先来探讨一下各个环节相关的策略。</p><h2 id="策略"><a class="header-anchor" href="#策略"></a>策略</h2><h3 id="配置策略"><a class="header-anchor" href="#配置策略"></a>配置策略</h3><p>配置管理的目标是确保系统配置的自动化、标准化和版本控制，确保环境的一致性和可重复性。核心原则如下：</p><table><thead><tr><th>原则</th><th>解释</th></tr></thead><tbody><tr><td>配置即代码（Configuration as Code）</td><td>配置应写入代码仓库、版本可控（如 YAML / JSON / HCL）</td></tr><tr><td>环境一致性</td><td>不同环境（开发、测试、生产，仿真、实车）配置同步，消除&quot;在我机器上能运行&quot;问题</td></tr><tr><td>环境解耦</td><td>不同环境（开发、测试、生产）配置分离，不嵌入代码</td></tr><tr><td>集中管理</td><td>配置统一管理，防止散乱分布，单一配置源，防止多份配置不归一</td></tr><tr><td>可审计</td><td>配置改动可追溯、有记录，有变更审查流程规范</td></tr><tr><td>安全隔离</td><td>敏感信息（如 Token、密钥）通过安全机制管理</td></tr></tbody></table><p>这些原则在智能驾驶的三个 DevOps 中都适用，针对不同的场景，有不同的工具可供选择。</p><ul><li>版本控制工具，根据操作类型可以选择Git、SVN，我们通常用Git管理代码，用SVN管理文档，代码管理用Git、Git LFS、repo以及相应的管理平台Gitlab、Gerrit等。模型训练数据、模型本身则通过自研的数据平台做版本控制。</li><li>环境基础设施，根据隔离强弱及性能效率可以选择KVM、Docker以及相关的管理平台OpenStack、Kubernetes等，我们通常选择用Docker保证环境的一致性、部署微服务，用KVM部署跨平台虚拟机。</li><li>配置管理工具，在云服务 DevOps 中，通常使用Ansible、Chef、Puppet等做系统层配置，用Kubernetes模板等做应用层配置；在车端Soc DevOps中，通常使用车辆配置参数和远程配置等；，在AI Model DevOps中，通常依赖训练平台的配置管理。</li><li>数据管理工具，通常采用大数据存储，如对象存储OBS等</li></ul><h3 id="代码管理策略"><a class="header-anchor" href="#代码管理策略"></a>代码管理策略</h3><p>根据团队规模、模块耦合度、权限管理等多方面综合考虑，对于Git来讲，主要是权限管理方面的需求，其他维度可以通过流程规范来约束，当然用工具更好。有两种代码管理策略。</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>多仓（每个模块一个仓）</td><td>每个模块独立 Git 仓库，每个模块设置独立的权限</td></tr><tr><td>单仓（一个仓多个目录）</td><td>所有模块在一个 Git 仓中，以目录区分模块，所有模块共享一个权限</td></tr></tbody></table><p>这两种方式各有利弊，从以下各个方面来对比分析。总体来讲单仓对于开发人员更友好，对于CI/CD更简单，但对架构和控制更不友好。在这里我们基于强权限管理的需求，使用多仓模式。</p><table><thead><tr><th>维度</th><th>多仓（每个模块一个仓）</th><th>单仓（一个仓多个目录）</th></tr></thead><tbody><tr><td>模块解耦</td><td>非常强，模块独立，便于复用</td><td>弱，模块间容易产生隐式依赖</td></tr><tr><td>版本控制</td><td>每个模块单独 tag/version</td><td>所有模块同一个版本</td></tr><tr><td>CI/CD 分布式</td><td>构建需关心依赖的接口仓、公共组件仓，模块可单独构建测试</td><td>构建需关心模块的划分，有相应的构建配置规则</td></tr><tr><td>开发效率</td><td>大团队开发、并行推进更方便</td><td>小团队集中开发更方便</td></tr><tr><td>权限控制</td><td>每个模块可设置不同权限</td><td>所有人对整个仓都有权限</td></tr><tr><td>子模块管理</td><td>需要用 Git Submodule / Repo / manifest 工具</td><td>无需多仓管理工具</td></tr><tr><td>适合场景</td><td>微服务架构 / 多团队 / DevOps 场景</td><td>单一团队 / 内部高耦合项目</td></tr></tbody></table><h3 id="分支策略"><a class="header-anchor" href="#分支策略"></a>分支策略</h3><p>分支的划分主要受模块耦合度、团队划分、集成方式、测试效率等方面的影响，集成方式和测试效率决定了分支的层级。</p><p>在云服务开发中，微服务通常是独立集成、独立部署、独立演进的，微服务的代码分支通常和环境相匹配。</p><table><thead><tr><th>环境</th><th>推荐 Git 分支名</th><th>说明</th></tr></thead><tbody><tr><td>开发环境</td><td><code>develop</code> / <code>feature/*</code></td><td>开发功能、单元测试、多人协作</td></tr><tr><td>测试/集成环境</td><td><code>release/*</code></td><td>联调测试，功能冻结，准备上线</td></tr><tr><td>预生产环境</td><td><code>pre-release</code> / <code>staging</code></td><td>灰度验证、稳定性测试，接近线上</td></tr><tr><td>生产环境</td><td><code>main</code> / <code>master</code></td><td>最终上线代码，只接受从 pre 分支 promote 的改动</td></tr></tbody></table><p><em>注：对于内部云服务来讲，可以适当减少分支来达成快速验证快速上线的目的，在质量和效率平衡下，尽量保证每个环境的可追溯性</em></p><p>智能驾驶软件系统是一个很庞大的系统，有MCU软件，也有SoC软件。</p><ul><li>MCU通常是基于AUTOSAR CP开发的一个单片机系统，通过工具建模和配置生成BSW和RTE模块， 实现业务应用SWC模块代码，SWC模块按领域划分，比如平台、规控等</li><li>SoC软件系统从下往上分为底软、平台、业务层，业务层按传统分层架构分为感知融合、构图定位、规控预测等，在端到端大模型下，这种功能分层的界线可能比较模糊、变成了模型的一部分。</li></ul><p>无论MCU和SoC，都涉及不同的团队、多个子系统或者模块，考虑到多团队、多子系统/模块的解耦、协作开发，我们更倾向于按子系统并行开发逐级集成的方式。分支设计如下：</p><table><thead><tr><th>系统层级</th><th>Git 分支</th><th>说明</th></tr></thead><tbody><tr><td>模块</td><td>个人分支</td><td>开发功能、单元测试、多人协作</td></tr><tr><td>子系统</td><td>子系统(项目团队)分支</td><td>子系统联调测试，功能冻结，准备对系统发布</td></tr><tr><td>系统</td><td>系统分支(SoC全量/MCU全量)</td><td>整系统联调,稳定性测试，准备对解决方案发布</td></tr><tr><td>解决方案</td><td>NA</td><td>全域集成，功能测试，最终对用户发布</td></tr></tbody></table><p>同样的，分支命名可以根据制定的规范来，举例如下：</p><table><thead><tr><th>类型</th><th>推荐 Git 分支名</th><th>说明</th></tr></thead><tbody><tr><td>个人分支</td><td><code>br_&lt;name&gt;*</code></td><td>用于开发人员开发特性、解决问题、优化等</td></tr><tr><td>子系统(项目团队)分支</td><td><code>br_develop*</code></td><td>用于子系统集成、子系统测试</td></tr><tr><td>系统分支</td><td><code>master</code> / <code>develop</code></td><td>用于系统级集成、系统级测试</td></tr><tr><td>特性分支</td><td><code>br_feature*</code></td><td>用于多模块特性开发联调</td></tr><tr><td>发布分支</td><td><code>br_release*</code> / <code>br_bugfix*</code></td><td>用于版本发布或者版本bugfix</td></tr></tbody></table><p>模型相关的代码有两部分，一部分是训练代码，跟随云服务的方式，一部分是车端部署及模型后处理，跟随智能驾驶软件。</p><h3 id="集成策略"><a class="header-anchor" href="#集成策略"></a>集成策略</h3><p>软件架构决定了集成策略，比如我们采用微服务软件架构和单体架构使用的集成策略是不同的。对于智能驾驶这样的庞大的系统，通常都是多种集成方式的组合策略。常见的集成方式如下：</p><table><thead><tr><th>集成方式</th><th>描述</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>源码集成</td><td>模块源码放到同一项目一起编译</td><td>跨模块调试方便，接口一致性强</td><td>耦合度高、编译慢、分支管理复杂</td><td>单团队开发、快速迭代</td></tr><tr><td>二进制集成</td><td>模块提供 .so/.dll/.a 等产物，通过 ABI 连接</td><td>保护 IP、编译快、跨平台交付</td><td>接口变化需要适配，排查问题难</td><td>第三方 SDK、供应商模型</td></tr><tr><td>协议集成</td><td>模块通过网络、IPC、消息中间件通信</td><td>分布式、松耦合、支持跨进程或多机</td><td>实时性差于本地调用，接口管理复杂</td><td>多 ECU、多进程、云边交互</td></tr><tr><td>服务化集成</td><td>模块封装为服务，用 REST/gRPC/RPC/Kafka 接入</td><td>独立部署、弹性伸缩、支持 DevOps 流水线</td><td>部署复杂、服务治理成本高</td><td>云端、微服务架构</td></tr><tr><td>容器化集成</td><td>模块打包到 Docker 等容器中运行</td><td>环境隔离、易部署、可结合 CI/CD</td><td>对硬件资源敏感、需要容器编排</td><td>跨环境部署、DevOps、云原生</td></tr><tr><td>插件化集成</td><td>模块打包成插件，主程序运行时动态加载</td><td>热插拔灵活、可选功能</td><td>接口兼容性难维护，出错时易崩溃</td><td>桌面软件、游戏引擎、IDE 等插件系统</td></tr></tbody></table><p>在云服务开发中，微服务模块通过源码集成，微服务间通过服务化集成(REST/gRPC/RPC/Kafka)，微服务通过容器化集成。</p><p>在车端系统中，在同一ECU内，模块内通过源码集成自研部分 + 通过二进制集成第三方交付；模块间通过接口协议集成(ROS2 DDS)；多ECU通过接口协议集成(比如底盘域通过CAN) + 服务化集成(比如地图服务)</p><p>常见的集成策略如下：</p><table><thead><tr><th>策略类型</th><th>描述</th><th>适用场景</th></tr></thead><tbody><tr><td>大爆炸集成</td><td>所有模块一起完成后一次性集成</td><td>模块依赖少、小项目</td></tr><tr><td>增量集成</td><td>每次集成部分模块，并对每次集成结果做验证</td><td>大型系统开发、敏捷交付</td></tr><tr><td>自顶向下</td><td>先搭建系统主干/框架，逐步集成底层子模块</td><td>系统架构不确定，需早期原型</td></tr><tr><td>自底向上</td><td>先将底层组件集成好，再逐步组合成高层功能</td><td>底层成熟度高、上层依赖底层</td></tr><tr><td>沙盒集成</td><td>各模块在独立环境（沙盒）先单独验证，再合入主分支/主系统</td><td>大团队并行开发，避免集成冲突</td></tr><tr><td>持续集成（CI）</td><td>通过自动化流水线在每次代码提交后自动拉起编译、单元测试和部分集成测试</td><td>敏捷开发、快速反馈</td></tr></tbody></table><p>在车端系统中，整体上我们采用自底向上的集成策略，底层软件、软件平台、上层应用逐级集成。各个子系统采用沙盒集成策略，在独立环境或者最新的发布版本环境中单独验证子系统，验证通过后再合入主分支集成。对于每个模块，通过持续集成的方式在每次代码合并前拉起编译、测试、静态检查等检查项。</p><h3 id="验证策略"><a class="header-anchor" href="#验证策略"></a>验证策略</h3><p>验证策略的目标是在各个阶段及早的发现并修正问题，确保功能符合需求预期，保证系统鲁棒性。同时能够支撑相关认证(如ISO 26262、ASIL、ASPICE)等。常见的策略如下：</p><table><thead><tr><th>验证环节</th><th>验证内容</th><th>适用阶段</th></tr></thead><tbody><tr><td>单元测试（Unit Test）</td><td>针对最小可测单元（函数/类）做验证</td><td>开发阶段</td></tr><tr><td>模块测试（Module Test）</td><td>验证单一模块功能、边界、接口符合预期</td><td>模块完成后</td></tr><tr><td>集成测试（Integration Test）</td><td>验证模块之间交互、接口兼容、数据传递正确</td><td>模块集成阶段</td></tr><tr><td>系统测试（System Test）</td><td>验证整个系统的功能、性能、稳定性、用户场景覆盖</td><td>系统集成后</td></tr><tr><td>回归测试（Regression Test）</td><td>每次修改后验证旧功能依然可用</td><td>持续集成/迭代交付中</td></tr><tr><td>静态分析（Static Analysis）</td><td>工具化扫描代码风格、内存安全、MISRA、CERT、复杂度等</td><td>开发/持续集成</td></tr><tr><td>动态分析（Dynamic Analysis）</td><td>运行时监测内存、CPU、线程、性能热点、死锁</td><td>调试/性能验证</td></tr><tr><td>模拟/仿真（Simulation）</td><td>用 HIL/SIL/MIL 等模拟环境验证系统在真实条件下的表现</td><td>嵌入式/车载开发</td></tr><tr><td>场景回放验证（Replay Test）</td><td>在感知/智能驾驶中用实车或数据集回放传感器、车辆轨迹验证算法</td><td>感知/决策/规划模块</td></tr><tr><td>实车验证（On-vehicle Test）</td><td>将系统部署到真实车辆进行道路环境下的综合验证</td><td>验证阶段末期</td></tr></tbody></table><p>对于模型来说，验证项差不多，验证内容变成模型相关的指标；</p><table><thead><tr><th>验证环节</th><th>验证内容</th><th>说明</th></tr></thead><tbody><tr><td>单元验证</td><td>训练、推理是否能正常完成</td><td>含边界值、异常值等</td></tr><tr><td>功能验证</td><td>模型是否符合任务目标</td><td>如检测召回率、分割 IoU、分类准确率</td></tr><tr><td>性能验证</td><td>速度、内存、延迟、吞吐量是否达标</td><td>特别是在目标硬件上如Orin、MCU</td></tr><tr><td>回归验证</td><td>新模型对比基线模型无性能退化</td><td>指标下降要阻止合入</td></tr><tr><td>场景验证</td><td>典型/极端场景中模型表现</td><td>智能驾驶中常用离线回放场景集</td></tr><tr><td>鲁棒性验证</td><td>输入噪声、分辨率变化、光照等干扰下表现</td><td>真实场景不可避免波动</td></tr><tr><td>泛化验证</td><td>新场景/未见环境数据上的泛化能力</td><td>避免过拟合</td></tr><tr><td>偏差验证</td><td>数据分布、预测结果中的潜在偏差</td><td>符合公平性、合规性需求</td></tr></tbody></table><p><em>注：每个验证阶段都应该定义相应的准入准出条件，这里暂做遗留，后续单独展开。</em></p><h3 id="版本策略"><a class="header-anchor" href="#版本策略"></a>版本策略</h3><p>版本策略的核心目标是保证软件版本的可追溯性和可管理性，支持并行开发、快速修复和稳定发布，明确版本计划和版本管理方式。</p><table><thead><tr><th>策略</th><th>说明</th><th>适用场景</th></tr></thead><tbody><tr><td>语义化版本（SemVer）</td><td>使用 MAJOR.MINOR.PATCH 表示破坏性、兼容性、新功能</td><td>公共 API、对外 SDK/软件包</td></tr><tr><td>时间戳版本</td><td>使用日期（2024.06.27）表示版本</td><td>内部快速迭代、敏捷开发</td></tr><tr><td>分支管理</td><td>master/dev + feature/hotfix 分支模型</td><td>团队规模化开发、版本并行维护</td></tr><tr><td>标签管理</td><td>每次集成成功后在主分支打 tag</td><td>交付节点、回溯调试</td></tr></tbody></table><p>基于以上策略，制定合适的版本号规范和版本流转流程，前面的各种策略按照版本管理流程制定可量化的规则条件并应用于版本管理中。</p><h2 id="核心环节"><a class="header-anchor" href="#核心环节"></a>核心环节</h2><p>DevOps 有 8 个核心环节：</p><table><thead><tr><th>阶段</th><th>英文术语</th><th>主要工作内容</th></tr></thead><tbody><tr><td>1️⃣ 规划</td><td>Plan</td><td>需求分析、任务规划、需求拆分（如 Jira、Confluence）</td></tr><tr><td>2️⃣ 开发</td><td>Develop</td><td>编码、代码提交、版本控制（如 Git、IDE）</td></tr><tr><td>3️⃣ 构建</td><td>Build</td><td>编译、构建镜像、依赖分析（如 Make, CMake, Docker）</td></tr><tr><td>4️⃣ 测试</td><td>Test</td><td>单元测试、集成测试、接口测试（如 gtest, pytest, sonar）</td></tr><tr><td>5️⃣ 发布</td><td>Release/Integrate</td><td>持续集成、代码合并、版本打包（如 GitLab CI, Jenkins）</td></tr><tr><td>6️⃣ 部署</td><td>Deploy</td><td>自动部署、灰度发布、回滚机制（如 K8s, Ansible, Helm）</td></tr><tr><td>7️⃣ 运营</td><td>Operate</td><td>系统运维、资源管理、容器调度（如 Prometheus, Kubernetes）</td></tr><tr><td>8️⃣ 监控</td><td>Monitor</td><td>性能指标、日志分析、告警系统（如 Grafana, ELK）</td></tr></tbody></table><p>各环节涉及的角色及职责：</p><table><thead><tr><th>阶段</th><th>主要角色</th><th>职责说明</th></tr></thead><tbody><tr><td>1️⃣ 规划</td><td>- 产品经理（PM）<br>- 系统架构师（SA）<br>- 项目经理/版本经理/EO（Engineering Owner）<br>- QA</td><td>- 定义系统目标与需求<br>- 规划功能拆解、技术路径<br>- 制定版本迭代节奏<br>- 评估规划和设计质量，回溯，流程优化</td></tr><tr><td>2️⃣ 开发</td><td>- 模型训练/部署工程师<br>- 算法/开发工程师<br>- 嵌入式工程师<br>- 仿真平台开发<br>- 测试开发工程师<br>- QA</td><td>- 编写训练框架、部署框架，模型训练、校准、部署<br>- 编写核心模块代码、实现算法功能<br>- 集成传感器 SDK、芯片 SDK<br>- 实现仿真功能<br>- 编写测试框架、测试用例<br>- 评估开发质量，回溯，流程优化</td></tr><tr><td>3️⃣ 构建</td><td>- CI/CD 工程师<br>- DevOps 工程师<br>- 基础平台工程师<br>- QA</td><td>- 配置 CMake 等构建系统<br>- 实现编译流水线（如 Jenkins + Docker）<br>- 管理依赖和构建缓存<br>- 评估构建质量</td></tr><tr><td>4️⃣ 测试</td><td>- 测试工程师（TE）<br>- 仿真测试工程师<br>- QA</td><td>- 单元测试/功能测试/回归测试<br>- 基于仿真平台仿真<br>- 评估测试质量（覆盖率、漏测率等），回溯，流程优化</td></tr><tr><td>5️⃣ 发布</td><td>- 版本管理员<br>- 集成工程师<br>- 配置管理工程师</td><td>- 打包发布软件版本<br>- 管理 OTA 策略<br>- 跟踪依赖变更、回滚机制</td></tr><tr><td>6️⃣ 部署</td><td>- 车端软件集成工程师<br>- 平台运维<br>- 验证工程师</td><td>- 将系统部署至 HIL/SIL/实车环境<br>- 管理版本升级与兼容性测试</td></tr><tr><td>7️⃣ 运营</td><td>- 运维工程师<br>- 数据平台工程师<br>- 市场运营<br>- QA</td><td>- 实时监控系统状态<br>- 数据采集/清洗/闭环回流<br>- 市场调研、市场反馈、产品推广、客户运营<br>- 评估产品质量，回溯，流程优化</td></tr><tr><td>8️⃣ 监控</td><td>- 监控平台开发<br>- 观测器（Observer）系统开发者<br>- 数据分析师</td><td>- 建立观测系统（Log/指标/异常追踪）<br>- 实现 KPI 报警、自动化 root cause 定位<br>- 监控模型漂移（Model Drift）</td></tr></tbody></table><h3 id="规划-Plan"><a class="header-anchor" href="#规划-Plan"></a>规划 - Plan</h3><p>Plan 阶段是 DevOps 生命周期的起点，其核心目标是收集并确认业务需求、技术需求，制定可执行的开发 &amp; 运维计划；定义交付里程碑、验收标准；规划资源：人力、硬件、预算；明确沟通、审批、变更管理流程。Plan 阶段做得好，后续的 DevOps 流程才能高效无阻。</p><p>Plan 阶段的关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>需求收集</td><td>与产品/客户确认功能、性能、合规等需求</td></tr><tr><td>优先级排序</td><td>确定 backlog，排定迭代计划</td></tr><tr><td>工作拆解</td><td>将需求拆分为智能驾驶、模型、云服务工具链三部分的可执行的任务、Story、Bug</td></tr><tr><td>制定时间表</td><td>明确交付周期、里程碑、关键节点</td></tr><tr><td>风险识别</td><td>识别潜在技术/资源/依赖风险并制定应对措施</td></tr><tr><td>资源分配</td><td>明确开发、测试、运维、DevOps 平台等所需资源</td></tr><tr><td>环境规划</td><td>设计开发、测试、台架、测试车、采集车等各环境的搭建和管理方案</td></tr><tr><td>验收标准制定</td><td>定义功能完成标准、回归指标、上线门槛</td></tr></tbody></table><p>Plan 阶段的核心产出：</p><ul><li>产品/功能需求文档，设计文档，编程规范等</li><li>迭代计划（Sprint Plan、Release Plan）</li><li>WBS（工作分解结构）</li><li>关键里程碑定义</li><li>风险清单及应对策略</li><li>版本计划与发布排期</li><li>环境和资源申请清单</li></ul><h3 id="开发-Develop"><a class="header-anchor" href="#开发-Develop"></a>开发 - Develop</h3><h4 id="软件代码"><a class="header-anchor" href="#软件代码"></a>软件代码</h4><p>Develop 阶段的核心目标是根据 Plan 阶段的需求，将功能、问题或改进转化为高质量、可维护的代码；通过代码审查和静态分析保障代码质量；保证开发过程中的版本一致性与可追溯性；为后续持续集成（CI）奠定基础。</p><p>Develop 阶段的关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>环境准备</td><td>确保开发环境与集成环境一致（依赖版本、操作系统、编译器等），如使用Docker镜像</td></tr><tr><td>代码编写</td><td>按照规范、需求编写可维护、可扩展的代码</td></tr><tr><td>单元测试开发</td><td>编写单元测试、mock，保证代码功能符合预期</td></tr><tr><td>静态代码分析</td><td>在本地或 CI 里集成 clang-tidy、cppcheck、SonarQube、coverity、blackduck 等工具</td></tr><tr><td>代码审查（Code Review）</td><td>使用 Gerrit、GitLab MR 等做评审，提高代码质量</td></tr><tr><td>版本管理</td><td>按照分支策略提交、合并，并关联到对应的需求、任务、Bug，保证可回溯</td></tr><tr><td>编码规范执行</td><td>使用 clang-format、pylint 及人工审查等做代码风格统一</td></tr><tr><td>本地验证</td><td>在本地运行构建、测试、lint，保证代码可通过基本检查</td></tr></tbody></table><p>Develop 阶段最佳实践：</p><ul><li>小步提交：每次提交都应具备可编译、可通过单测的质量</li><li>分支管理：遵循 Git Flow 或 trunk-based，避免长期分支积压</li><li>提交信息规范：使用语义化提交，概述提交的内容</li><li>测试驱动开发（TDD），或者至少同时写单测</li><li>自动化检查：在提交前 hook 或合并前执行 lint、格式化、单测</li></ul><p>Develop 阶段常见挑战：</p><ul><li>Q: 不同开发人员使用不同环境，可能导致“works on my machine”问题<ul><li>A: 使用 Docker 容器或 dev container 保证一致性</li></ul></li><li>Q: 代码合并时引入冲突或回归<ul><li>A: 频繁拉取主干、CI 自动回归测试</li></ul></li><li>Q: 代码质量参差不齐<ul><li>A: 强制代码审查、静态分析、统一风格检查</li></ul></li></ul><h4 id="模型"><a class="header-anchor" href="#模型"></a>模型</h4><p>模型 Develop 阶段核心目标是基于采集数据理解问题，完成模型设计；快速实现新模型架构或改进现有模型；在样本或小数据集上做初步训练和验证；反复调优模型结构、损失函数、后处理等；输出第一个能在仿真/离线评测中具备初步可用性的模型。</p><p>模型 Develop 阶段的关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>问题定义</td><td>确定模型任务（如目标检测、语义分割、轨迹预测等），明确输入输出</td></tr><tr><td>数据探索</td><td>对样本做可视化、统计分析、分布验证，发现样本问题或模型盲区</td></tr><tr><td>特征工程</td><td>设计输入特征、归一化方案、数据增强策略</td></tr><tr><td>模型设计</td><td>设计神经网络架构，如 YOLO/CenterPoint/Transformer 等</td></tr><tr><td>模型实现</td><td>基于 PyTorch、TensorFlow、MindSpore 等框架实现</td></tr><tr><td>训练流程</td><td>构建初步训练脚本，配置损失函数、优化器、学习率策略等</td></tr><tr><td>验证脚本</td><td>编写指标计算脚本，如准确率、mAP、IoU、RMSE 等</td></tr><tr><td>性能初步评估</td><td>在验证集或特定场景数据上测试模型的可行性</td></tr><tr><td>代码规范</td><td>遵循团队代码标准，并完成基础单元测试</td></tr></tbody></table><p>Develop 阶段最佳实践：</p><ul><li>设计输入输出接口对接感知/规划模块，提前考虑端到端部署可用性</li><li>使用小规模先行验证模型有效性，避免大规模训练资源浪费</li><li>模型初版实现也要写测试样例，防止 early bugs 进入后期集成</li><li>通过 Notebook + Dashboard 定期展示模型结果和场景样例，方便团队协作</li><li>保留模型 checkpoint，并配合元数据记录用于后续对比和追溯</li></ul><p>Develop 阶段常见问题：</p><ul><li>Q: 过拟合小场景，线上泛化差<ul><li>A: 数据增强、多场景样本混合训练、交叉验证</li></ul></li><li>Q: 模型指标看起来好，但特定场景失效<ul><li>A: 设计场景覆盖度评测脚本、分场景指标统计</li></ul></li><li>Q: 训练数据和线上环境不一致<ul><li>A: 使用仿真或插入端到端处理链做验证，确保一致性</li></ul></li></ul><h3 id="构建-Build"><a class="header-anchor" href="#构建-Build"></a>构建 - Build</h3><h4 id="软件代码-v2"><a class="header-anchor" href="#软件代码-v2"></a>软件代码</h4><p>Build 阶段核心目标是把源代码转换成可执行文件、库、镜像或其他交付物；生成可用于部署、测试的工件，并保证可重现性；及时发现编译错误、依赖冲突等问题；提供一致、自动化、标准化的构建流程。</p><p>Build 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>依赖管理</td><td>下载、验证依赖版本，防止不兼容</td></tr><tr><td>编译/打包</td><td>编译源代码，链接生成目标文件，打包为安装包、容器镜像等</td></tr><tr><td>构建缓存</td><td>利用缓存减少重复构建时间</td></tr><tr><td>版本信息注入</td><td>在构建产物中写入 commit ID、时间、分支等元信息</td></tr><tr><td>单元测试执行</td><td>构建后立即跑单测验证构建有效性</td></tr><tr><td>工件签名/哈希</td><td>保证交付物完整性、防止篡改</td></tr><tr><td>构建产物存储</td><td>上传到 Artifactory、Nexus、Harbor、OBS 等仓库统一管理</td></tr></tbody></table><p>Build 阶段最佳实践：</p><ul><li>自动化构建：通过 CI 平台在提交合并时触发自动构建</li><li>幂等性：同样输入（代码、配置、依赖）生成的工件要一致</li><li>隔离环境：构建过程应在干净环境中运行（如 CI runner 或 Docker），避免「我机器上能编译」的问题</li><li>版本元数据：在构建产物中注入 commit ID、分支、编译时间，如可执行文件输出：</li><li>构建缓存：加速 CI，避免每次全量下载代码，全量编译</li></ul><p>Build 阶段常见挑战：</p><ul><li>Q: 编译环境不一致，导致 CI 通过但生产环境失败<ul><li>A: 在 CI 里用 Docker 统一环境</li></ul></li><li>Q: 构建时间过长，降低迭代效率<ul><li>A: 使用分布式构建、增量构建</li></ul></li><li>Q: 工件缺乏管理，无法回滚<ul><li>A: 构建产物集中上传到工件仓库，并在版本管理系统里记录可追溯信息</li></ul></li><li>Q: 开发、测试、版本等不同人员对工件诉求不一样<ul><li>A: CI 工程师熟悉整个开发调测流程，提升流程各个环节的使用体验</li></ul></li></ul><p>Build 阶段产物：</p><ul><li>可执行文件、动态/静态库</li><li>容器镜像</li><li>软件包（.deb/.rpm/.zip）</li><li>文档、API 说明</li><li>元信息文件（含版本、编译环境等）</li><li>单元测试报告，静态扫描报告等</li><li>冒烟测试报告</li></ul><h4 id="模型-v2"><a class="header-anchor" href="#模型-v2"></a>模型</h4><p>Build 阶段核心目标是将模型转换为高效的部署格式（如 TensorRT、ONNX、TFLite、或自研二进制格式）；将前处理、模型、后处理链打包成一致的 pipeline；静态编译或交叉编译所需的 C++/CUDA 算子（跟随软件代码开发）；校验模型在目标硬件上的推理正确性与性能；为 OTA、工厂烧录、仿真环境提供标准化可部署模型产物。</p><p>Build 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>模型导出</td><td>将 PyTorch/TensorFlow 模型导出为 ONNX 或其他中间格式</td></tr><tr><td>模型优化</td><td>使用 TensorRT、ONNX Graph Optimization 等做量化、合并、融合算子</td></tr><tr><td>平台适配</td><td>针对 Orin/Thor 或其他 ECU 平台进行硬件兼容验证</td></tr><tr><td>算子编译</td><td>针对自定义 CUDA/C++ 算子进行交叉编译，确保车端可用</td></tr><tr><td>Pipeline 封装</td><td>前处理、主模型、后处理组成整体 pipeline，方便调用和集成</td></tr><tr><td>功能一致性验证</td><td>确保模型优化后在输出精度上与训练时基本一致</td></tr><tr><td>性能基准测试</td><td>在目标硬件上测试推理耗时、资源占用，并输出性能报告</td></tr><tr><td>产物打包</td><td>产出模型文件、版本元信息、必要脚本及依赖库清单</td></tr></tbody></table><p>Build 阶段最佳实践：</p><ul><li>在 CI 流水线中自动化完成模型转换、优化、打包、验证</li><li>模型输出在优化前后必须做 diff，确认数值精度在可接受范围</li><li>为每个模型产物生成唯一 hash 与元数据，方便后续追溯</li><li>在不同硬件环境（Orin/Thor/PC）上都要做基准性能验证</li><li>对可执行文件、库、模型产物进行签名，保证交付安全性</li></ul><p>Build 阶段常见挑战：</p><ul><li>Q: 优化后模型数值漂移<ul><li>A: 加入基线输出比对脚本，自动检测误差是否超标</li></ul></li><li>Q: 目标硬件兼容性问题<ul><li>A: 使用车端交叉编译环境+硬件 in the loop（HIL）测试</li></ul></li><li>Q: 算子不支持优化工具<ul><li>A: 开发自定义 Plugin，并集成到 TensorRT/ONNX Runtime</li></ul></li><li>Q: 模型推理延迟高<ul><li>A: 优化模型结构，选择合适的精度，使用高效的推理引擎，结合批处理和异步处理</li></ul></li></ul><h3 id="测试-Test"><a class="header-anchor" href="#测试-Test"></a>测试 - Test</h3><h4 id="软件"><a class="header-anchor" href="#软件"></a>软件</h4><p>Test 阶段核心目标是验证构建产物满足功能、性能和非功能性需求；及时发现并反馈问题，阻止缺陷进入生产；提供可量化、可追溯的测试结果；将测试自动化，提高覆盖率、降低回归成本。</p><p>Test 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>单元测试</td><td>验证每个函数/类在隔离环境下的正确性</td></tr><tr><td>集成测试</td><td>验证多个模块/组件组合后的接口和协作</td></tr><tr><td>功能测试</td><td>验证系统满足业务需求的功能完整性</td></tr><tr><td>回归测试</td><td>确保修改/新增功能不会破坏已有功能</td></tr><tr><td>性能测试</td><td>评估系统在负载下的响应时间、吞吐量</td></tr><tr><td>安全测试</td><td>检查常见漏洞（XSS、SQL注入、身份验证缺陷等）</td></tr><tr><td>UI/端到端测试</td><td>以用户视角验证整个流程的正确性</td></tr><tr><td>静态代码扫描</td><td>分析代码缺陷、潜在漏洞</td></tr></tbody></table><p><em>注：其中单元测试、静态代码扫描、部分集成测试一般在开发构建阶段实施。根据测试策略，构建阶段自动触发冒烟回归测试等。</em></p><p>Test 阶段最佳实践：</p><ul><li>左移测试：越早发现问题，修复成本越低；单元测试应在开发期间完成</li><li>测试自动化：让 CI 触发后能自动跑单元、集成、功能测试</li><li>覆盖率监控：量化单元测试覆盖率，如行覆盖 80%+ 为合入门槛</li><li>分层测试：优先覆盖核心逻辑的单元和集成测试，再补充端到端测试</li><li>测试数据管理：保证测试数据可控、可重复、脱敏（防泄漏）</li><li>并行化执行：用并行任务执行，加速测试过程</li><li>结果报告：CI 自动生成可读的测试报告，并能上传到平台供查阅</li></ul><p>Test 阶段常见挑战：</p><ul><li>Q: 单测覆盖率不足 → 遗漏回归问题<ul><li>A: 强制覆盖率检查，并纳入合并门槛</li></ul></li><li>Q: 测试执行太慢 → 拉低迭代效率<ul><li>A: 将测试拆分到并行任务执行</li></ul></li><li>Q: 依赖外部服务导致测试不稳定<ul><li>A: 使用 mock 或 stub 隔离外部依赖</li></ul></li><li>Q: 仅功能测试缺乏性能/安全保障<ul><li>A: 为每次发布集成性能测试和安全扫描</li></ul></li></ul><p>Test 阶段核心产物</p><ul><li>自动化测试报告（HTML/JUnit 格式）</li><li>测试覆盖率报告</li><li>性能测试结果</li><li>安全扫描结果</li><li>测试日志 &amp; 回归追踪记录</li></ul><h4 id="模型-v3"><a class="header-anchor" href="#模型-v3"></a>模型</h4><p>Test 阶段核心目标是验证模型是否在全量数据集和重点场景中表现稳定；验证模型在目标硬件（如 NVIDIA Orin/Thor）上性能是否达标；评估 Corner Case、长尾场景、失效场景中的表现；保证新版本与旧版本之间的性能一致性（回归测试）；支撑自动化 CI 流水线闭环，形成上线前“质量关卡”。</p><p>Test 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>功能测试</td><td>检查模型输出是否合理，是否符合输入输出协议、shape、值域等要求</td></tr><tr><td>精度评估</td><td>使用标注数据计算 mAP、IoU、RMSE、ADE/FDE 等指标</td></tr><tr><td>场景覆盖测试</td><td>分城市、天气、光照、道路类型等统计模型表现</td></tr><tr><td>失效检测</td><td>检查模型是否在特定异常输入下崩溃或输出异常（NaN、Inf、空）</td></tr><tr><td>性能测试</td><td>推理耗时、帧率、CPU/GPU 使用率、功耗测试等</td></tr><tr><td>资源一致性测试</td><td>验证内存泄露、线程数异常等运行时资源问题</td></tr><tr><td>回归测试</td><td>对比旧模型版本，验证新模型没有引入性能或功能退化</td></tr><tr><td>模拟测试</td><td>在仿真环境中运行模型，验证整体驾驶行为是否安全可控</td></tr></tbody></table><p>Test 阶段最佳实践：</p><ul><li>构建 CI 自动评测流水线：每次提交后跑全套验证流程</li><li>设计分场景评测报告：比如在“隧道”、“大雨”、“夜晚”等重点场景下单独出报表</li><li>与感知/规划/控制等模块联测：测试模型是否影响上下游模块的正确性和鲁棒性</li><li>添加安全回归用例：保证模型不会在 Corner Case 中反复失效</li><li>性能与精度共同评估：性能未达标即使精度高也不能上线</li></ul><p>Test 阶段常见挑战：</p><ul><li>Q: 模型指标提升但上线表现变差<ul><li>A: 需要加场景评估和联测闭环，不仅看数字</li></ul></li><li>Q: 模型对输入分布偏移敏感<ul><li>A: 加入数据增强和鲁棒性评测</li></ul></li><li>Q: 新模型部署性能下降<ul><li>A: 优化后处理、BatchSize、绑定CPU亲和性</li></ul></li></ul><h3 id="发布-Release"><a class="header-anchor" href="#发布-Release"></a>发布 - Release</h3><h4 id="云服务"><a class="header-anchor" href="#云服务"></a>云服务</h4><p>Release 阶段核心目标是确保经过验证的工件被安全、稳定、可控地发布到生产或目标环境；管理发布节奏，减少变更对生产的风险；提供回滚和补丁机制应对线上问题；沟通协调各角色（开发、测试、运维、产品）做好上线准备。</p><p>Release 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>版本归档</td><td>标记稳定版本（Tag）、记录元数据（commit ID、分支、时间等）</td></tr><tr><td>产物签名</td><td>对发布包、容器镜像等做哈希校验或数字签名</td></tr><tr><td>发布文档编写</td><td>包含变更记录、升级指南、已知问题、兼容性说明</td></tr><tr><td>发布批准</td><td>由研发/产品/运维等负责人共同审核并签字/审批</td></tr><tr><td>灰度/蓝绿发布</td><td>先向部分用户发布观察表现，再逐步全量上线</td></tr><tr><td>回滚方案准备</td><td>明确发布失败或回归问题时的撤销、回滚步骤</td></tr><tr><td>发布通知</td><td>向利益相关方同步版本变更、上线计划和状态</td></tr></tbody></table><p>Release 阶段最佳实践：</p><ul><li>自动化发布流程：Release 流程应尽可能在 CI/CD 中自动化，减少人工操作</li><li>稳定窗口发布：选择低峰时段或运维窗口发布，便于快速定位问题</li><li>小步快跑：避免大规模改动同时上线，控制每次变更范围</li><li>发布可追溯：每个发布记录需包含版本号、提交信息、执行人、时间等元数据</li><li>回滚机制：生产环境出现严重问题时可快速回滚到上一个稳定版本</li><li>多环境验证：在预生产环境完成和生产环境一致的验证，保证无环境差异</li></ul><p>Release 阶段常见挑战：</p><ul><li>Q: 生产环境不一致导致发布后表现异常<ul><li>A: 用基础设施即代码（IaC）保持各环境一致</li></ul></li><li>Q: 发布步骤复杂、手动操作易出错<ul><li>A: 用脚本或 CD 平台标准化并自动化发布过程</li></ul></li><li>Q: 无回滚方案或回滚困难<ul><li>A: 每次发布前都明确回滚步骤并在预生产环境验证</li></ul></li><li>Q: 变更对客户或依赖系统影响不可控<ul><li>A: 采用灰度、蓝绿等渐进式发布，并加强监控</li></ul></li></ul><p>Release 阶段核心产物：</p><ul><li>发布包（可执行文件、Docker 镜像、安装包等）</li><li>发布记录（Tag、Release Notes、审批记录）</li><li>回滚方案及验证记录</li><li>发布计划/排期表</li><li>已知问题 &amp; 解决方案</li></ul><h4 id="智驾系统"><a class="header-anchor" href="#智驾系统"></a>智驾系统</h4><p>Release 阶段核心目标是确认交付的软件/模型版本稳定且符合质量标准；完成版本封装与元数据管理，确保可追溯；通过安全、法规合规性审核；制定灰度发布、回滚和风险应对方案。</p><p>Release 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>版本冻结与打包</td><td>冻结版本代码、模型，制作产物包（包含元数据、文档）</td></tr><tr><td>版本管理</td><td>确保版本号唯一且有详细变更日志</td></tr><tr><td>合规审查</td><td>符合ISO 26262、ASPICE、安全合规及法规要求</td></tr><tr><td>发布计划制定</td><td>制定灰度策略、分批次上线、监控预案</td></tr><tr><td>测试验证复核</td><td>对照测试报告复核关键性能与安全指标</td></tr><tr><td>部署准备</td><td>OTA推送准备、工厂烧录流程确认</td></tr><tr><td>回滚预案</td><td>制定异常情况下的快速回退方案</td></tr></tbody></table><p>Release 阶段最佳实践：</p><ul><li>版本管理规范：版本号需严格遵循语义化，记录完整变更历史</li><li>多级审批流程：发布前必须经过技术、安全、法规多部门审批</li><li>灰度发布：先在小范围车队或特定区域部署，监控效果后再全量推广</li><li>应急回滚：版本上线前必须准备快速回滚方案，保证安全</li><li>数据追踪：上线后实时收集运行数据，监控异常和模型性能退化</li><li>文档齐备：包含详细的版本说明、安全风险提示、已知问题列表</li></ul><p>Release 阶段常见挑战：</p><ul><li>Q: 上线版本不稳定<ul><li>A: 制定严格的灰度和回滚机制</li></ul></li><li>Q: 合规审核不过关<ul><li>A: 提前介入法规专家参与，确保文档齐全</li></ul></li><li>Q: 版本管理混乱<ul><li>A: 强制使用自动化工具和流程，避免人工错误</li></ul></li><li>Q: 部署失败或不兼容<ul><li>A: 完善硬件兼容性测试，提前做全链路集成测试</li></ul></li></ul><h3 id="部署-Deploy"><a class="header-anchor" href="#部署-Deploy"></a>部署 - Deploy</h3><h4 id="云服务-v2"><a class="header-anchor" href="#云服务-v2"></a>云服务</h4><p>Deploy 阶段核心目标是将验证合格的版本平稳、安全地部署到生产或目标环境；保证部署过程可重复、自动化、可追溯；降低对用户的影响，并具备快速回滚能力；与监控、告警联动，及时发现上线问题。</p><p>Deploy 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>部署前准备</td><td>检查环境、依赖、配额、健康状态</td></tr><tr><td>自动化部署</td><td>脚本或 CD 平台自动化将工件部署到服务器或容器</td></tr><tr><td>配置管理</td><td>使用统一配置中心或环境变量管理不同环境下的参数</td></tr><tr><td>数据迁移</td><td>执行数据库 schema、数据填充等迁移操作</td></tr><tr><td>变更验证</td><td>部署完成后做 smoke test，确认核心功能可用</td></tr><tr><td>部署监控</td><td>启动后持续监控日志、资源使用、核心指标</td></tr><tr><td>回滚策略</td><td>明确部署失败时撤销的步骤</td></tr><tr><td>部署后通知</td><td>向研发、运维、产品等相关方同步上线状态</td></tr></tbody></table><p>Deploy 阶段最佳实践：</p><ul><li>部署自动化：避免人工操作，减少风险并提升效率</li><li>环境幂等性：重复部署同一个版本不应引入额外问题</li><li>渐进式部署：灰度发布、蓝绿部署或 canary，先验证小批流量，再扩大范围</li><li>配置分离：代码和配置分离，通过环境变量、配置中心切换环境</li><li>部署自检：部署完立即运行自动化 smoke test 验证基本功能</li><li>联动监控：部署后自动检测 CPU/内存/请求错误率等异常波动</li><li>回滚机制：部署流程应支持快速回退，并验证回退有效性</li></ul><p>Deploy 阶段常见挑战：</p><ul><li>Q: 部署时间过长，导致服务中断<ul><li>A: 使用容器或分布式架构，逐步替换实例减少影响</li></ul></li><li>Q: 配置错误导致部署完成后异常<ul><li>A: 在 CI/CD 中加入配置校验或 lint</li></ul></li><li>Q: 数据库 schema 变更不兼容<ul><li>A: 数据库迁移需要向后兼容或支持双写期</li></ul></li><li>Q: 环境不一致导致部署后问题<ul><li>A: 用 IaC（Terraform、Ansible）保持环境一致</li></ul></li></ul><p>Deploy 阶段核心产物：</p><ul><li>部署日志</li><li>成功/失败状态报告</li><li>配置变更记录</li><li>smoke test 结果</li><li>部署后的监控数据快照</li></ul><h4 id="智驾系统-v2"><a class="header-anchor" href="#智驾系统-v2"></a>智驾系统</h4><p>Deploy 阶段核心目标是将模型和软件安全、高效地部署到目标硬件（车载ECU、边缘设备、仿真平台）；保证部署过程自动化、标准化，降低人工干预和出错风险；配置必要的运行环境和依赖，确保软件稳定运行；支持远程部署（OTA）和本地刷写，满足不同场景需求；实施部署验证，确保模型正常加载、推理和响应。</p><p>Deploy 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>部署包下发</td><td>将Release产物推送到目标设备或刷写到存储介质</td></tr><tr><td>运行环境配置</td><td>配置操作系统、驱动、中间件、依赖库版本</td></tr><tr><td>OTA部署支持</td><td>实现空中下载更新，支持增量升级和安全回滚</td></tr><tr><td>部署自动化</td><td>编写自动化脚本/流水线，支持批量设备快速部署</td></tr><tr><td>启动验证</td><td>启动模型推理服务，检查初始化成功、无异常</td></tr><tr><td>资源监控</td><td>监控CPU、GPU使用率、内存占用及温度等指标</td></tr><tr><td>日志采集</td><td>配置日志上传和远程诊断接口，便于后续排查</td></tr><tr><td>部署文档</td><td>制定详细部署手册和应急恢复方案</td></tr></tbody></table><p>Deploy 阶段最佳实践：</p><ul><li>自动化部署流水线，减少手动错误，提升效率和一致性</li><li>多环境适配，针对不同硬件平台做差异化配置和验证</li><li>灰度发布与监控，逐步扩大部署范围，实时监控关键指标</li><li>安全保障，通过签名校验、防篡改和安全启动保证部署安全</li><li>日志与诊断，部署时即配置好日志采集，方便后续运维支持</li></ul><p>Deploy 阶段常见挑战：</p><ul><li>Q: 不同硬件兼容性<ul><li>A: 维护硬件配置清单，自动适配部署包</li></ul></li><li>Q: 部署失败难排查<ul><li>A: 详细日志，远程诊断能力，自动回滚机制</li></ul></li><li>Q: OTA升级失败风险<ul><li>A: 增量升级、校验机制、灰度发布策略</li></ul></li><li>Q: 环境依赖复杂<ul><li>A: 按车型统一解决方案，复杂环境依赖配套版本化</li></ul></li></ul><h3 id="运营-Operate"><a class="header-anchor" href="#运营-Operate"></a>运营 - Operate</h3><h4 id="云服务-v3"><a class="header-anchor" href="#云服务-v3"></a>云服务</h4><p>Operate 阶段核心目标是确保生产环境系统长期稳定、性能达标、高可用；主动监控系统健康状况，快速检测并修复故障；收集运行指标，为后续优化、扩容、回归分析提供依据；持续进行安全加固和资源管理，保障服务安全、成本可控。</p><p>Operate 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>系统监控</td><td>收集 CPU、内存、IO、QPS、延迟、错误率等指标</td></tr><tr><td>日志采集与分析</td><td>集中收集应用、系统、审计日志，支持问题排查</td></tr><tr><td>资源管理</td><td>动态管理 CPU、内存、带宽、存储等资源，避免资源瓶颈</td></tr><tr><td>异常检测与告警</td><td>配置阈值、告警规则，实现自动化告警</td></tr><tr><td>自动化运维脚本</td><td>常用任务（扩容、备份、修复）的脚本化，降低人工操作风险</td></tr><tr><td>安全管理</td><td>及时更新补丁、管理凭据、检测入侵</td></tr><tr><td>SLA/SLO 监控</td><td>监控并评估服务可用性和性能是否符合对用户承诺的 SLA/SLO</td></tr><tr><td>成本优化</td><td>根据指标分析，释放或调整资源，降低运营成本</td></tr></tbody></table><p>Operate 阶段最佳实践：</p><ul><li>可观测性建设：三大支柱：日志（Logging）、指标（Metrics）、追踪（Tracing）</li><li>自动化修复：故障自动恢复脚本，如 pod 宕机自动重启</li><li>最小权限原则：生产环境账号、API token 等权限最小化</li><li>灾备演练：定期在预生产环境做灾难恢复演练</li><li>SLA/SLO 持续监控：将业务指标转化为 SLO，并与告警系统联动</li><li>容量规划：根据趋势预估未来资源需求，提前扩容或优化架构</li></ul><p>Operate 阶段常见挑战：</p><ul><li>Q: 指标/日志收集不全 → 无法准确定位线上问题<ul><li>A: 完善可观测性体系，并定期验证覆盖率</li></ul></li><li>Q: 告警风暴 → 太多无效告警掩盖真正问题<ul><li>A: 优化告警规则、设置合理阈值、引入告警合并</li></ul></li><li>Q: 缺乏自动化 → 故障处理依赖人工，响应慢<ul><li>A: 用自动化运维脚本和自愈系统替代重复人工操作</li></ul></li><li>Q: 安全漏洞暴露 → 长期未更新依赖或系统补丁<ul><li>A: 定期扫描并自动化补丁更新</li></ul></li></ul><p>Operate 阶段核心产物：</p><ul><li>系统运行指标大盘（如 Grafana Dashboards）</li><li>日志归档与检索接口</li><li>告警记录与处理报告</li><li>安全审计日志</li><li>资源使用和成本分析报告</li></ul><h4 id="智驾软件"><a class="header-anchor" href="#智驾软件"></a>智驾软件</h4><p>Operate 阶段核心目标是保证智能驾驶功能在生产车辆上的长期稳定性、安全性、可靠性；实时监控车辆状态、模块健康、环境变化，及时发现并处理异常；持续收集数据，支持模型迭代和功能优化；通过 OTA（Over-The-Air）维护和更新软件。</p><p>Operate 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>车辆在线监控</td><td>实时上报各 ECU、传感器、智能驾驶域控（DCU）健康状态</td></tr><tr><td>关键指标采集</td><td>如感知延迟、规划频率、车辆控制误差、定位漂移等</td></tr><tr><td>安全状态管理</td><td>定时做自检，包括传感器自诊断、功能安全机制（ASIL）检测</td></tr><tr><td>OTA 管理</td><td>远程更新软件版本、参数配置，并记录更新状态</td></tr><tr><td>异常日志采集</td><td>发生故障时抓取系统快照（sensor dump、core dump）用于排查</td></tr><tr><td>数据回传</td><td>收集特定路况、Corner Case 等数据，用于模型再训练</td></tr><tr><td>远程协助和诊断</td><td>当出现疑难问题，可远程接管或辅助分析</td></tr><tr><td>安全保障机制</td><td>如 L3/L4 车辆在模块异常时平稳退出自动驾驶模式</td></tr></tbody></table><p>Operate 阶段最佳实践：</p><ul><li>多层监控体系：ECU 级、域控级、整车级，三级监控保证全链路健康</li><li>模块健康自检测：周期性对感知、定位、规划模块做自检</li><li>闭环数据流：从车辆到云端的数据自动回传、自动分析、自动触发改进</li><li>分级告警机制：严重告警（如感知失效）直接触发紧急停车，中低级告警通知后台</li><li>自动 OTA 回滚：OTA 更新失败时可自动回退到上一个稳定版本</li><li>法规合规性：保证符合 ISO 26262、ISO/PAS 21448（SOTIF）、UN-R155/156 等标准</li></ul><p>Operate 阶段常见挑战：</p><ul><li>Q: 大规模车队中车辆分布广，运维成本高<ul><li>A: 采用集中云管平台 + OTA + 远程诊断</li></ul></li><li>Q: Corner Case 触发概率低，难以主动发现<ul><li>A: 通过智能数据标注和云端聚类，识别潜在问题</li></ul></li><li>Q: 实车环境变化大（天气、光线、道路）导致系统不稳定<ul><li>A: 持续回传多样化数据，更新模型并灰度部署验证</li></ul></li></ul><h4 id="智驾模型"><a class="header-anchor" href="#智驾模型"></a>智驾模型</h4><p>Operate 阶段核心目标是部署在车端或边缘端后，需保持稳定、低延迟、资源占用受控；实时监控推理耗时、准确率变化、置信度分布、Corner Case 出现频率等；模型输出不合理（如大面积漏检）时触发告警并记录上下文数据；将失败样本、低置信样本、特定环境数据回传到云端用于持续迭代；模型支持 OTA、灰度发布，确保新模型上线不会带来大面积回归。</p><p>Operate 阶段核心活动：</p><table><thead><tr><th>类别</th><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>模型监控</td><td>模型推理耗时监控</td><td>CPU/GPU/DLA 端推理时间稳定性</td></tr><tr><td></td><td>模型结果监控</td><td>漏检率、误检率、置信度漂移，输出结果一致性</td></tr><tr><td></td><td>资源占用</td><td>推理进程内存占用、显存、温度等</td></tr><tr><td>异常处理</td><td>动态 Fallback</td><td>如感知模型失效可切入规则逻辑或简化模型</td></tr><tr><td></td><td>自动日志&amp;数据打包</td><td>出现异常结果时自动上传模型输入、输出、上下文</td></tr><tr><td>数据闭环</td><td>场景触发回传</td><td>特定天气/光照/路况等场景自动采集上传</td></tr><tr><td></td><td>标注与训练联动</td><td>标注团队对反馈数据快速处理并触发新一轮训练</td></tr><tr><td>OTA 支持</td><td>模型热更新</td><td>模型支持动态加载或重启加载（如 TensorRT、ONNX）</td></tr><tr><td></td><td>模型版本管理</td><td>支持 hash 校验、切换回滚、版本审计等能力</td></tr></tbody></table><p><em>注：模型OTA一般跟随智驾软件，整个智驾系统OTA，模型往往与前后处理代码强相关。</em></p><p>Operate 阶段最佳实践：</p><ul><li>边车模型观测器设计：在感知/预测模块旁部署轻量 agent，专门采集模型输出统计信息与推理指标</li><li>Corner Case 捕捉策略：比如检测空车道误识别为行人、红绿灯误判等，标记回传</li><li>灰度模型上线流程：基于 VIN 白名单/地图区域逐步部署，保障控制安全性</li><li>与 CI/CD 流水线联动：模型上线前后自动验证关键路径，确保无回归</li><li>场景标签化反馈数据：为采集回来的数据打上标签（如“夜间-雨天-遮挡”），方便下一轮训练精准选样</li></ul><h3 id="监控-Monitor"><a class="header-anchor" href="#监控-Monitor"></a>监控 - Monitor</h3><h4 id="云服务-v4"><a class="header-anchor" href="#云服务-v4"></a>云服务</h4><p>Monitor 阶段核心目标是实时、全面地观察系统和业务状态；及时发现性能、可用性、异常趋势；提供量化数据支持后续优化、容量规划、产品迭代；形成自动化告警体系，将问题第一时间推送到责任人。</p><p>Monitor 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>指标收集</td><td>采集系统和应用的 CPU、内存、IO、响应时间、QPS 等指标</td></tr><tr><td>日志收集</td><td>集中收集、存储并分析应用和系统日志</td></tr><tr><td>分布式追踪</td><td>记录请求在多系统间流转的过程，定位链路瓶颈</td></tr><tr><td>用户体验监测</td><td>检测页面加载速度、API 失败率、App 崩溃率等</td></tr><tr><td>SLA/SLO 监控</td><td>跟踪并验证服务可用性是否达成对客户承诺</td></tr><tr><td>告警系统集成</td><td>对超阈值或异常指标自动触发告警并通知相关人员</td></tr><tr><td>仪表盘与可视化</td><td>以图表、看板形式展示核心指标，便于持续关注和对比</td></tr></tbody></table><p>Monitor 阶段最佳实践：</p><ul><li>覆盖全栈监控：应用、数据库、中间件、网络、主机指标都应覆盖</li><li>三大可观测性支柱：指标（Metrics）、日志（Logs）、追踪（Tracing）统一分析</li><li>告警降噪：避免告警风暴，通过告警合并、静默期、优先级等减少误报</li><li>服务级别目标（SLO）：将可用性指标与业务目标挂钩，比如「99.9% 的 API 成功率」</li><li>与 CI/CD 联动：上线后持续观察核心指标，自动回滚有问题的版本</li><li>自动化容量预测：用监控数据驱动资源扩容或架构优化</li></ul><p>Monitor 阶段常见挑战：</p><ul><li>Q: 只监控系统层面，缺乏业务指标<ul><li>A: 在应用中埋点，采集关键业务流程指标</li></ul></li><li>Q: 指标不一致或标准混乱<ul><li>A: 制定统一的监控指标规范</li></ul></li><li>Q: 告警频繁误报，导致运维疲劳<ul><li>A: 优化阈值、采用自适应告警或基于机器学习的异常检测</li></ul></li><li>Q: 可观测性孤岛：指标、日志、追踪分散在不同系统<ul><li>A: 采用集中可观测性平台（如 Elastic Observability、Grafana Cloud、Datadog）</li></ul></li></ul><p>Monitor 阶段核心产物：</p><ul><li>监控仪表盘（Dashboard）</li><li>指标时序数据库（TSDB）</li><li>告警规则配置和记录</li><li>SLA/SLO 报表</li><li>追踪数据和链路拓扑</li><li>分析报告（周/月/季度健康度</li></ul><h4 id="智驾软件-v2"><a class="header-anchor" href="#智驾软件-v2"></a>智驾软件</h4><p>Monitor 阶段核心目标是持续收集并可视化整车和核心算法模块的运行状态；快速发现感知、定位、规划、控制等关键模块的性能异常；记录环境、驾驶行为、Corner Case 等情况，为模型迭代提供数据；支持异常自动告警，提前发现潜在风险并联动自动化处理。</p><p>Monitor 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>系统健康监控</td><td>监控域控（DCU）、各 ECU、电源、传感器硬件状态</td></tr><tr><td>模块性能监控</td><td>监测感知帧率、延迟、定位精度、规划频率、控制误差等指标</td></tr><tr><td>环境与驾驶状态监控</td><td>记录天气、光线、路面状况、驾驶员接管频率等</td></tr><tr><td>车队状态聚合</td><td>云端汇总每辆车上传的数据，形成全车队健康大盘</td></tr><tr><td>数据可视化</td><td>在云端仪表盘上实时展示车辆状态、核心指标、告警分布</td></tr><tr><td>异常告警</td><td>配置指标阈值，自动触发本地或云端告警</td></tr><tr><td>日志和数据归档</td><td>异常情况下保存快照用于排查，正常运行中做定期归档</td></tr></tbody></table><p>Monitor 阶段最佳实践：</p><ul><li>多级监控：车载本地实时监控 + 云端汇总监控</li><li>指标与事件结合：对连续异常（如定位漂移）和突发事件（传感器掉线）都要监测</li><li>指标阈值动态调整：环境差异大，可用 AI 或大数据统计实现自适应告警阈值</li><li>SLA/SLO 定义：例如「感知模块平均延迟 ≤ 50ms」，并监测是否达成</li><li>可视化一体化：整合车队状态、单车历史、告警记录、性能趋势到同一看板</li><li>数据合规：合规处理涉及地理位置、驾驶行为数据，满足数据安全和隐私法规</li></ul><p>Monitor 阶段常见挑战：</p><ul><li>Q: 数据量巨大、上传带宽受限<ul><li>A: 边缘计算 + 数据分级上报（只上传关键指标或异常时全量上传）+ 按需拉取</li></ul></li><li>Q: 不同车型、不同硬件平台的指标标准不一致<ul><li>A: 制定统一指标标准，或在云端做多车型兼容</li></ul></li><li>Q: 本地告警延迟高或丢失<ul><li>A: 采用本地缓存+断点续传+优先级上报</li></ul></li></ul><h4 id="智驾模型-v2"><a class="header-anchor" href="#智驾模型-v2"></a>智驾模型</h4><p>Monitor 阶段核心目标是实时掌握模型推理性能：延迟、频率、硬件资源占用；监测模型结果的准确性、稳定性和一致性；捕获模型失效或输出异常；统计场景分布、置信度分布等趋势指标；形成可视化分析与自动化告警闭环；为数据回流和模型迭代提供可靠依据。</p><p>Monitor 阶段关键活动：</p><table><thead><tr><th>活动</th><th>说明</th></tr></thead><tbody><tr><td>模型推理性能监控</td><td>跟踪每次推理的耗时、内存/显存占用、推理帧率，发现性能下降或波动</td></tr><tr><td>模型输出监控</td><td>分析模型输出的置信度分布、类别概率、连续帧一致性</td></tr><tr><td>结果合理性检测</td><td>例如检测目标突然消失/漂移，预测轨迹突变，规划意图异常等</td></tr><tr><td>Corner Case 采集</td><td>识别易错场景并记录环境、传感器输入、模型输出上下文</td></tr><tr><td>自动化告警</td><td>模型性能/结果出现阈值外异常时推送告警给运维/研发人员</td></tr><tr><td>场景统计</td><td>根据天气、光照、路况等标签统计模型表现，找出模型弱点</td></tr></tbody></table><p>Monitor 阶段最佳实践：</p><ul><li>指标实时采集 + 上报：不要只做日志记录，要能实时汇总到云端</li><li>端到端一致性检测：感知-预测-规划模型串联输出是否自洽</li><li>动态阈值告警：不同车型、不同工况可以有不同的告警阈值</li><li>与环境关联：结合 GPS、IMU、摄像头等数据，将模型表现和环境关联起来</li><li>可视化：对车队中各车型、不同区域的模型表现形成趋势图，方便快速定位问题</li></ul><p>Monitor 阶段常见挑战：</p><ul><li>Q: 数据量大，上传成本高<ul><li>A: 只在异常或弱场景中做关键数据回传</li></ul></li><li>Q: 不同版本模型混用，难以统一监控<ul><li>A: 强制上报模型版本号，并在云端对不同版本做分组对比</li></ul></li><li>Q: 现场问题难以重现<ul><li>A: 抓取模型输入、输出、环境元数据，并可在仿真环境中重放</li></ul></li></ul><p>上述各阶段中，有根据代码、模型维度分类，也有根据云服务、智驾软件、智驾模型维度分类，不同分类的目的，是为了更有针对性的展现该阶段的主要内容。虽然做了一定的划分，本质上区别不大，主要是关注的维度不同。</p><p>以上对 DevOps 无限循环图的 8 个环节做了概览性的描述，每一个环节都可以展开具体实践，期待后续的篇章。</p><h2 id="参考链接"><a class="header-anchor" href="#参考链接"></a>参考链接</h2><ul><li><a href="https://en.wikipedia.org/wiki/DevOps">DevOps - Wikipedia</a></li><li><a href="https://zh.wikipedia.org/zh-cn/%E8%87%AA%E5%8B%95%E9%A7%95%E9%A7%9B%E6%B1%BD%E8%BB%8A">自动驾驶汽车 - Wikipedia</a></li><li><a href="https://pagertree.com/learn/devops/what-is-devops">What is DevOps?</a></li><li><a href="https://chatgpt.com/">ChatGPT 各种相关 prompt 的回答</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;DevOps 这一开发理念在2009年被提出后，经过十几年的发展，已经非常成熟了，特别是在微服务架构被提出并流行开来，进一步推动 DevOps 实践深入发展。DevOps 既然已经这么成熟了，我们为啥还要写这个话题？笔者认为理念是成熟的，但应用的业务场景是日新月异的，怎么把</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="智能驾驶" scheme="http://blog.cuicc.com/tags/%E6%99%BA%E8%83%BD%E9%A9%BE%E9%A9%B6/"/>
    
    <category term="DevOps" scheme="http://blog.cuicc.com/tags/DevOps/"/>
    
    <category term="CI/CD" scheme="http://blog.cuicc.com/tags/CI-CD/"/>
    
  </entry>
  
  <entry>
    <title>使用C++模板的一些技巧</title>
    <link href="http://blog.cuicc.com/blog/2021/12/25/some-tips-for-cpp-template/"/>
    <id>http://blog.cuicc.com/blog/2021/12/25/some-tips-for-cpp-template/</id>
    <published>2021-12-25T13:45:06.000Z</published>
    <updated>2025-03-16T07:58:25.552Z</updated>
    
    <content type="html"><![CDATA[<h2 id="模板是什么"><a class="header-anchor" href="#模板是什么"></a>模板是什么</h2><blockquote><p>模板（Template）在C++ 程序设计语言中，是指函数模板与类模板[1]，是一种参数化类型机制。Java和C＃中的泛型与C++ 的模板大体对应，但也有一些功能上的显著差异（C++ 模板支持两者没有明确对应的模板模板参数和模板非类型参数，但不支持Java的通配符以及C#的泛型类型约束）。模板是C++ 的泛型编程中不可缺少的一部分。</p><footer><strong>https://zh.wikipedia.org/wiki/%E6%A8%A1%E6%9D%BF_(C%2B%2B)</strong></footer></blockquote><p>简单说，模板的基本用法是可以简化参数类型不同但逻辑相同的代码，特别是不同参数类型的重载函数。</p><h2 id="遇到的问题"><a class="header-anchor" href="#遇到的问题"></a>遇到的问题</h2><p>最近有一个特性遇到了一些问题，帮他们优化，顺便整理一下。这个特性由原来的单个action变成了多个action，这里遇到一个问题，就是有一个入参对象需要和对应的action做关联更新，只存一份这个对象无法满足需求，而对象又比较大，拷贝多份的话，浪费了大量内存。最后的方案是把会更新的部分单独拿出来做了多份，只读的部分还是共用原来这个对象，最后把更新的部分整合回去给下游用。简单用伪码表示如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 原对象结构</span><br><span class="line">struct Example1 &#123;</span><br><span class="line">    type var1; // 更新</span><br><span class="line">    type var2; // 更新</span><br><span class="line">    ...</span><br><span class="line">    type varn; // 只读</span><br><span class="line">&#125;;</span><br><span class="line"># 多份对象结构</span><br><span class="line">struct NewExample1 &#123;</span><br><span class="line">    type var1;</span><br><span class="line">    type var2;</span><br><span class="line">    ...</span><br><span class="line">    Example1* e1; // 只读</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>为了不影响原有的功能，特性算法开发直接把相关函数拷贝出来一份，使用新对象作为参数，拷贝一份是因为类型不一样了，且读取数据的方式也不同。这样带来一个问题，每次特性分支同步主干时，这部分拷贝出来的代码都不会被更新，需要人工和原函数校对修改，同时大量的重复代码也给维护代码带来了很大的成本。</p><p>实际上，这两种类型的处理逻辑是一样的，只是类型不同且访问的数据源形式不太一样，比如使用<code>NewExample1</code>类型时，其数据源有本身可能更新的<code>var1</code>, 也有不变的部分比如<code>e1-&gt;varn</code>。这正是泛型编程可以发挥的场景，使用模板可以去掉大量的重复逻辑。</p><h2 id="泛型编程"><a class="header-anchor" href="#泛型编程"></a>泛型编程</h2><p>泛型编程是指使用一种独立于任何具体类型的方式进行编码，模板是泛型编程的基础。使用模板前需要搞清楚的是，模板的推导是编译期完成的，编译完成后就生成了对应类型的特化实现，并不是运行期动态特化。</p><p>所以模板函数实现一般放在头文件中，编译器在类型检查时，只有看到函数实现才能特化出具体类型的函数。如果模板函数声明和实现分开，会导致链接时找不到函数实现。</p><p>从上面的特性开发得知，特性分支需要同步主干代码，那么如果在特性分支上把模板函数实现都移入头文件，也会给同步造成很大的问题，也需要人工校对头文件的模板函数和cpp里的函数，最好的方式就是就地(cpp中)模板化。</p><h3 id="在cpp中模板化"><a class="header-anchor" href="#在cpp中模板化"></a>在cpp中模板化</h3><p>如何实现模板声明和实现的分离，在cpp文件中实现函数。检索通过<code>stackoverflow</code>找个了方案：在cpp中实现时，需要声明要特化的类型，这样在编译时就能根据特化声明来特化函数实现。当然这样就不是广义的泛型了，只支持声明特化的几种类型，详细内容看<code>stackoverflow</code>及其最佳答案里的链接。在这个特性中，这种方式满足当前的使用。示例如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># .h</span><br><span class="line"># 模板类</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">class Example &#123;</span><br><span class="line">    void Func1(T&amp; t);</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"># 模板函数</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">void ExampleFunc(T&amp; t);</span><br><span class="line"></span><br><span class="line"># .cpp</span><br><span class="line"># 模板类实现</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">void Example&lt;T&gt;::Func1(T&amp; t) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## 明确类特化</span><br><span class="line">template class Example&lt;Example1&gt;;</span><br><span class="line">template class Example&lt;NewExample1&gt;;</span><br><span class="line"></span><br><span class="line"># 模板函数实现</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">void ExampleFunc(T&amp; t) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 明确函数特化</span><br><span class="line">template void ExampleFunc&lt;Example1&gt;(T&amp; t);</span><br><span class="line">template void ExampleFunc&lt;NewExample1&gt;(T&amp; t);</span><br></pre></td></tr></table></figure><p>结合上述类型，我们特化了<code>Example1</code>和<code>NewExample1</code>两种实现，满足我们当前的使用需求。这样能消除大部分的重复逻辑，仅仅增加了两种特化声明。</p><h3 id="类型差异处理"><a class="header-anchor" href="#类型差异处理"></a>类型差异处理</h3><p>前文提到，因为我们两种类型仅仅是为了避免大量冗余只读的部分，我们有些逻辑获取数据源是和类型强关联的，直接上例子更直观：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Example1类型处理</span><br><span class="line">void Example::Func1(Example1&amp; t) &#123;</span><br><span class="line">    return t.var1 + t.varn;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># NewExample1类型处理, 只读部分通过指针访问Example1</span><br><span class="line">void Example::Func1(NewExample1&amp; t) &#123;</span><br><span class="line">    return t.var1 + t.e1-&gt;varn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，对于读写部分，两种类型的读取代码一摸一样，对于只读部分，就出现了差异。在不考虑复杂模板的情况下，想到的一种折中方法如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 模板函数实现</span><br><span class="line">template &lt;class T&gt;</span><br><span class="line">void Example&lt;T&gt;::Func1(const Example1&amp; t1, T&amp; t2) &#123;</span><br><span class="line">    return t2.var1 + t1.varn;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 全特化两种类型的实现，封装具体差异部分</span><br><span class="line">template &lt;&gt;</span><br><span class="line">void Example&lt;Example1&gt;::Func1(Example1&amp; t) &#123;</span><br><span class="line">    return Func1(t, t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">template &lt;&gt;</span><br><span class="line">void Example&lt;NewExample1&gt;::Func1(NewExample1&amp; t) &#123;</span><br><span class="line">    return Func1(*t.e1, t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只增加了函数调用的封装，屏蔽类型引起的差异。在消除重复代码的情况下，增加了一点函数封装的代码，当前也还可以接受。当然，这种方法，只适用于明确知道几种类型的情况下，如果泛化的类型比较多，就不是一种很好的方法了。</p><h3 id="更好的方法？"><a class="header-anchor" href="#更好的方法？"></a>更好的方法？</h3><p>那么，有没有更好的方法，可以直接在模板中处理类型带来的逻辑差异呢。是不是只能通过模板元编程来解决呢？还在研究中。。。</p><h2 id="参考链接"><a class="header-anchor" href="#参考链接"></a>参考链接</h2><p><a href="https://en.cppreference.com/w/cpp/language/templates">Templates - cppreference.com</a></p><p><a href="https://stackoverflow.com/questions/115703/storing-c-template-function-definitions-in-a-cpp-file">Storing C++ template function definitions in a .CPP file</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;模板是什么&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#模板是什么&quot;&gt;&lt;/a&gt;模板是什么&lt;/h2&gt;
&lt;blockquote&gt;&lt;p&gt;模板（Template）在C++ 程序设计语言中，是指函数模板与类模板[1]，是一种参数化类型机制。Java和C</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="C/C++" scheme="http://blog.cuicc.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>记一次内存泄漏定位</title>
    <link href="http://blog.cuicc.com/blog/2021/12/10/checking-for-mem-leaks/"/>
    <id>http://blog.cuicc.com/blog/2021/12/10/checking-for-mem-leaks/</id>
    <published>2021-12-10T14:21:44.000Z</published>
    <updated>2025-03-16T07:58:25.536Z</updated>
    
    <content type="html"><![CDATA[<p>最近测试时发现，运行相对较长一段时间后进程因内存使用超过配额上限而被杀掉，这应该是内存缓慢增长导致的，也就是说出现了内存泄漏。这个进程代码是用C++实现的，且基本没有使用<code>malloc/free</code>, <code>new/delete</code>等显式的内存申请释放，但代码中大量使用了标准库的容器类。这种因为业务逻辑导致容器没有清除导致的内存泄露，之前一直没有找到很好的定位手段，已知的工具<code>valgrind</code>貌似不能用来定位这种方式的泄露。</p><p>通过内外网搜索，找到了一些基于内存采样的分析工具，如<code>google-perftools</code>里的<code>tcmalloc</code>，及<code>bytehound</code>，本文主要记录下使用<code>tcmalloc</code>定位内存泄漏的方法。</p><h2 id="google-perftools"><a class="header-anchor" href="#google-perftools"></a>google-perftools</h2><p><a href="https://github.com/gperftools/gperftools">google-perftools</a>是Google开源的一个高性能的多线程的<code>malloc</code>实现集，号称当前最快的<code>malloc</code>，使用它可以提高内存访问性能，在我们的测试中，有大约单核10%的CPU性能提升。同时，它还集成了<code>heap-checker</code>，<code>heap-profiler</code>，<code>cpu-profiler</code>等内存和cpu检查<a href="https://github.com/gperftools/gperftools/wiki">分析工具</a>。这里主要使用<code>heap-profiler</code>来定位内存泄漏问题。</p><h3 id="tcmalloc库"><a class="header-anchor" href="#tcmalloc库"></a>tcmalloc库</h3><p>ubuntu上可以直接通过<code>apt</code>安装</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install -y google-perftools</span><br><span class="line"></span><br><span class="line"># 相关路径如下</span><br><span class="line"># /usr/bin/google-pprof</span><br><span class="line"># /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4</span><br></pre></td></tr></table></figure><p>有两种方式来使用tcmalloc库，一种是在编译时链接，然后运行时通过环境变量启用不同的工具，官方wiki看起来是推荐这种方式的。命令如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc [...] -o myprogram -ltcmalloc</span><br><span class="line"># HEAPPROFILE设置输出分析文件的前缀</span><br><span class="line">HEAPPROFILE=/tmp/myprogram ./myprogram</span><br></pre></td></tr></table></figure><p>另一种方式是通过<code>PRELOAD</code>的方式优先加载该动态链接库，好处是它不用重新编译代码，且可以覆盖该程序及其他在此之后链接库里的相同函数实现，实现全局使用的目的。命令如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">env LD_PRELOAD=&quot;/usr/lib/libtcmalloc.so&quot; HEAPPROFILE=/tmp/myprogram ./myprogram</span><br></pre></td></tr></table></figure><h3 id="内存分析"><a class="header-anchor" href="#内存分析"></a>内存分析</h3><p>通过上述启动程序后，每隔10s钟会在指定的输出路径输出内存采样文件，如<code>/tmp/myprogram.0001.heap</code>。通过一个简单的示例程序看下其过程。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># test.cpp</span><br><span class="line">#include &lt;vector&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;cstdlib&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">void test() &#123;</span><br><span class="line">    vector&lt;int&gt; testv;</span><br><span class="line">    for (int i = 0; i &lt; 10000; i++) &#123;</span><br><span class="line">        testv.push_back(i);</span><br><span class="line">    &#125;</span><br><span class="line">    # 退出不释放内存</span><br><span class="line">    exit(1);</span><br><span class="line">&#125;</span><br><span class="line">int main(void) &#123;</span><br><span class="line">    test();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该示例通过<code>vector</code>申请了<code>10000*sizeof(int)</code>大小左右的内存，然后没有释放。编译并预加载<code>tcmalloc</code>执行。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ test.cpp -o test</span><br><span class="line">env LD_PRELOAD=&quot;/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4&quot; HEAPPROFILE=/tmp/test ./test</span><br><span class="line"># 执行完成后看到以下文件</span><br><span class="line">/tmp/test.0001.heap</span><br></pre></td></tr></table></figure><p>使用<code>google-pprof</code>查看可以该文件，通过不同的参数可以指定显示方式，甚至web显示也可以。比如用<code>--test</code>参数显示成文本，用<code>--gv</code>或者<code>--pdf</code>可以图形化显示，如这里存到pdf文件中。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ google-pprof --pdf test /tmp/test.0001.heap &gt; test.0001.heap.pdf</span><br></pre></td></tr></table></figure><p>通过下图可以直观的看到<code>test</code>函数<code>alloc</code>了内存，没有<code>dealloc</code>过。</p><p><img src="/images/test-0001-heap-pdf.png" alt=""></p><h3 id="内存泄漏定位"><a class="header-anchor" href="#内存泄漏定位"></a>内存泄漏定位</h3><p>那么，在复杂的程序中，既有申请又有释放，内存一直缓慢增长该怎么取分析定位呢？如果直接查看单个文件，并无法说明内存只有申请没有释放。这里会用到<code>pprof</code>比较两个heap文件查看差异的方法。比如运行相对较长时间程序，获得了<code>myprogram.0001.heap ... myprogram.0234.heap</code> 这些采样数据，同时通过观察进程内存在这段时间内明显增长。可以通过以下命令对比两个文件：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ google-pprof --pdf --base /tmp/test.0010.heap test /tmp/test.0234.heap &gt; test.compare.pdf</span><br></pre></td></tr></table></figure><p>生成的pdf和上图类似，不同点在于该pdf中显示的相对值，就是0234申请的内存减去0010申请的值。可以直观的看到哪些函数相对申请了占比大的内存，大大缩小了排查范围，然后通过阅读这些函数就可以找到具体哪些容器存在未清除的问题，比如没有<code>clear</code>或<code>erase</code>。</p><p>这里取第0010个heap文件是因为程序前期初始化等申请一些内存，这部分先排除在外，避免大量定位。这里可以灵活运用，比如可以先看单个文件哪些申请了大量内存再做比较。</p><h2 id="bytehound"><a class="header-anchor" href="#bytehound"></a>bytehound</h2><p><a href="https://github.com/koute/bytehound">bytehound</a>是一款<code>Linux</code>平台的内存分析工具，具有丰富的前端界面，可以看趋势图、火焰图、内存申请调用栈等等。与上面不同的是它通过续写的方式生成一个<code>.dat</code>文件。</p><p>它的缺点是生成的文件非常大，从笔者的测试看，该文件一分钟增加2G左右，对于缓慢增长来说，运行几个小时文件大小吃不消。再者，虽然火焰图比较直观可以看出内存热点(类似cpu性能热点分析)，但是没有内存申请比较，不太容易缩小排查范围。</p><p>因为生成文件太大的问题，没有详细使用该工具，如有兴趣，可以参考他的<a href="https://koute.github.io/bytehound/">详细文档</a></p><h2 id="扩展资料"><a class="header-anchor" href="#扩展资料"></a>扩展资料</h2><ol><li><a href="https://github.com/gperftools/gperftools/wiki">google-perftools官方wiki</a> - 官方wiki对该工具各方面都有详尽的说明，想了解其他功能细节可以参看</li><li><a href="https://segmentfault.com/a/1190000040982400">内存泄漏的定位与排查：Heap Profiling 原理解析</a> - 该文章详细介绍了<code>heap profile</code>的原理，主流工具<code>profile</code>的实现细节等，该文中还提到了<code> gprof, Valgrind and gperftools</code>等工具评估链接，对于想了解原理的同学建议阅读。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近测试时发现，运行相对较长一段时间后进程因内存使用超过配额上限而被杀掉，这应该是内存缓慢增长导致的，也就是说出现了内存泄漏。这个进程代码是用C++实现的，且基本没有使用&lt;code&gt;malloc/free&lt;/code&gt;, &lt;code&gt;new/delete&lt;/code&gt;等显式</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="C/C++" scheme="http://blog.cuicc.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>线程池并行化重构</title>
    <link href="http://blog.cuicc.com/blog/2021/12/03/refactor-in-parallel-with-multi-threads/"/>
    <id>http://blog.cuicc.com/blog/2021/12/03/refactor-in-parallel-with-multi-threads/</id>
    <published>2021-12-03T14:24:56.000Z</published>
    <updated>2025-03-16T07:58:25.536Z</updated>
    
    <content type="html"><![CDATA[<p>最近业务新特性开发，由原来的单个action变成了多个action，最后取一个最优action。由于action变多，运行时间也相应多了几倍，action之间是相互独立，互不影响的，那么就想通过并行化的方法提升下性能，这个时候自然而然就想到了线程池。本文记录一下此次并行化重构业务代码时遇到的一些有意思的点。</p><h2 id="线程池"><a class="header-anchor" href="#线程池"></a>线程池</h2><p>模块中本来就包含线程框架，可以适当修改支持线程池，这里没啥大问题。业务代码action处理函数的改造主要在于函数输出，由原来的串行执行使用的成员变量改为变量数组，对应于线程池的个数。原有的依次比较改成最后遍历数组比较取最优。这块重构问题主要是内存问题，有些输出变量是对输入变量的局部更新，但是该变量是很大的数据结构，直接变成数组，造成内存使用增加很多，当前通过增加输出数据结构解决，这里的坑和多线程无关，另外单独介绍。</p><h2 id="单例"><a class="header-anchor" href="#单例"></a>单例</h2><p>这块业务代码有一个特色，就是单例使用特别多，且单例不仅仅是状态资源管理类，同时还是业务功能类。这里单例使用的是否合理，软件架构设计的是否合理不做深入讨论。当前只讨论怎么重构支持多线程。</p><h3 id="重构为类成员变量"><a class="header-anchor" href="#重构为类成员变量"></a>重构为类成员变量</h3><p>首先想到的方法是，既然不是全局的状态资源管理类，那么改成类成员比较合理，这样多线程处理时可以像上面的函数输出，改成数组就能满足需求。但通过阅读代码发现单例互相调用，随处调用等等，这种方法难以实现。</p><h3 id="重构为多单例"><a class="header-anchor" href="#重构为多单例"></a>重构为多单例</h3><p>这种方法比较省事，把原来的静态实例变成静态实例数组，获取单例接口通过增加参数来区分获取的是哪一个实例，从而和线程对应起来。代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static const MyClass&amp; GetInstance(uint8_t threadIndex) &#123;</span><br><span class="line">    static MyClass instance[THREAD_POOL_SIZE];</span><br><span class="line">    return instance[threadIndex];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多线程处理没有问题了，现在的问题变成如何获取<code>threadIndex</code>。</p><p>一个方法是给线程池的各线程命名，建立线程名称与<code>threadIndex</code>的map关系，这样在线程内可以通过系统接口获取线程名称，再通过map得到<code>threadIndex</code>。这种方法使用起来比较方便，但是有一个问题，单例特别多且高频调用，频繁调用系统接口比较影响性能。</p><p>另一种方法是通过参数传递进去，根据业务代码特点，每个类都有一个初始化配置接口<code>InitConfig</code>，这个接口在系统启动时执行一次。那么可以给每个类增加一个成员变量<code>threadIndex_</code>，在线程入口函数类的初始化时，遍历入口多单例并把<code>index</code>传入。在把action处理函数提交给线程池处理时，增加<code>index</code>参数，这样每个类在调用单例时都是通过传入的<code>index</code>调用的。代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MyClass::InitConfig(uint8_t index) &#123;</span><br><span class="line">    threadIndex_ = index;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 入口初始化时对多单例的初始化</span><br><span class="line">for (uint8_t i = 0; i &lt; THREAD_POOL_SIZE) &#123;</span><br><span class="line">    MyClass::GetInstance(i).InitConfig(i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># MyClass类中调用其他单例时</span><br><span class="line">OtherClass::GetInstance(threadIndex_).HandleFunc(...)</span><br></pre></td></tr></table></figure><p>这种方法相对比较可行，就是修改非常多，每一个调用单例且会更新的类都要修改。</p><p>单例修改完成后，使用线程池调式时发现还是会coredump，不用想肯定是多线程同时读写同一份数据造成的。通过调用栈看到的函数调用关系，看不出来具体问题点在哪里，虽然每次调用栈都不太一样，但是出问题的类及函数是相同的，且看到是同一个结构里的容器拷贝出了问题。通过增加打印及阅读代码，发现了另一个坑…</p><h2 id="static变量"><a class="header-anchor" href="#static变量"></a>static变量</h2><p>某些类成员函数中，局部变量定义时使用了static，但是没有使用历史值，猜测是想为了避免频繁构造析构该变量。但是C++中类中出现的static变量，不管是类成员变量还是函数局部变量，是独立于类实例的，所有该类的实例共享一份static变量。这就很清楚了，多线程调用时，这些线程共享了这一个变量，同时读写时出现踩内存问题。</p><p>回到局部变量使用static上，在面向过程实现中，staitc局部变量可以保证该变量的作用域只在函数内，避免使用全局变量造成全局可见，起到很好的封装作用。但是在面向对象实现中，这种隐藏在层层逻辑下的static局部变量是有很大的隐患的，因为它不是类的成员变量，却又所有实例共享一份。定义成普通类成员变量一样可以避免频繁构造析构，且重用该变量的值。</p><p>通过以上修改，终于调通了并行化~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近业务新特性开发，由原来的单个action变成了多个action，最后取一个最优action。由于action变多，运行时间也相应多了几倍，action之间是相互独立，互不影响的，那么就想通过并行化的方法提升下性能，这个时候自然而然就想到了线程池。本文记录一下此次并行化重</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="C/C++" scheme="http://blog.cuicc.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>恢复Hexo博客环境</title>
    <link href="http://blog.cuicc.com/blog/2021/11/30/recover-environment-for-writing/"/>
    <id>http://blog.cuicc.com/blog/2021/11/30/recover-environment-for-writing/</id>
    <published>2021-11-30T12:31:47.000Z</published>
    <updated>2025-03-16T07:58:25.520Z</updated>
    
    <content type="html"><![CDATA[<p>博客荒废了好些年了，这段时间觉得没有大的、好的主题可以写，就一直处于断更状态。最近发现就当笔记记录一些东西备查也是挺好，如果再次过程中还能对他人有一点帮助，那就更好了。是时候捡起来继续了，首先要恢复出本地的写作及部署环境，这里记录一下以备下次使用…</p><h2 id="WSL环境"><a class="header-anchor" href="#WSL环境"></a>WSL环境</h2><p>如果直接使用Windows或Mac等原生系统，可以跳过此步。从Windows支持Linux环境后，个人习惯用<code>WSL</code>，即保留Windows桌面的便捷性，又能兼顾Linux高效的命令操作。<br>安装步骤如下：</p><ol><li>打开“启用或关闭Windows功能”，勾选“适用于Linux的Windows子系统”。</li><li>从Microsoft Store中搜索你喜欢的Linux版本，比如Ubuntu，然后安装。</li></ol><p>安装完成后，安装powerline字体，参考<a href="https://github.com/powerline/fonts">官方指南</a>，需要注意的是因为使用的terminal是Windows的，所以要在Windows中安装，然后在terminal的字体设置中选择powerline相关字体。</p><p>个人比较喜欢用<code>oh-my-zsh</code>，安装完成后修改主题为<code>ZSH_THEME=&quot;agnoster&quot;</code>。enjoy it~</p><h2 id="Hexo环境"><a class="header-anchor" href="#Hexo环境"></a>Hexo环境</h2><p>这一步没什么花头，直接参照<a href="https://hexo.io/zh-cn/docs/">官方指南</a>安装Node.js和Git，然后通过npm安装Hexo即可。</p><h2 id="配置Hexo工程"><a class="header-anchor" href="#配置Hexo工程"></a>配置Hexo工程</h2><p>如果本地没有存储Source备份，需要从Github端clone一份</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b &lt;Source分支名&gt; https://github.com/&lt;用户名&gt;/&lt;Git库名&gt;.git</span><br></pre></td></tr></table></figure><p>其下操作步骤一样，进入Git仓库目录，执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure><p>由于之前的package.json比较老，执行install之后报了一堆npm的错误，形如</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">found XXX vulnerabilities (XXX low, XXX moderate, XXX high)</span><br><span class="line">run `npm audit fix` to fix them</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>在执行<code>npm audit fix</code>或<code>npm audit fix --force</code>后依然无法解决这个报错。这是因为该工程配置的依赖包版本太老了，npm检查后认为这些包存在安全隐患。最简单的方式就是升级到最新版本。</p><h3 id="Hexo升级"><a class="header-anchor" href="#Hexo升级"></a>Hexo升级</h3><p>由于package.json里配置了默认版本，所以首先要检查是否有新版本，然后更新json，命令如下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装npm-check用来检查是否需要升级插件</span></span><br><span class="line"><span class="built_in">sudo</span> npm install -g npm-check</span><br><span class="line">npm-check</span><br><span class="line"><span class="comment"># 安装npm-upgrade用来更新json</span></span><br><span class="line"><span class="built_in">sudo</span> npm install -g npm-upgrade</span><br><span class="line">npm-upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新全局插件</span></span><br><span class="line"><span class="built_in">sudo</span> npm update -g</span><br><span class="line"><span class="comment"># 更新本工程插件</span></span><br><span class="line">npm update --save</span><br></pre></td></tr></table></figure><p>更新完成后，可以用<code>hexo version</code>查看hexo及其依赖插件版本。</p><h3 id="其他告警"><a class="header-anchor" href="#其他告警"></a>其他告警</h3><ol><li>安装到最新版后，发现有报config参数deprecated，可以直接搜索相关参数看官方文档解决。<br>如安装5.0后遇到<code>external_link</code>参数问题</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INFO  Validating config</span><br><span class="line">WARN  Deprecated config detected: &quot;external_link&quot; with a Boolean value is deprecated. ...</span><br><span class="line"></span><br><span class="line"># 新格式如下</span><br><span class="line">external_link:</span><br><span class="line">    enable: true|false</span><br></pre></td></tr></table></figure><ol start="2"><li>执行<code>hexo s</code>后，有报循环依赖的告警，如下</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency</span><br><span class="line">(Use `node --trace-warnings ...` to show where the warning was created)</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;lineno&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;column&#x27; of module exports inside circular dependency</span><br><span class="line">(node:9508) Warning: Accessing non-existent property &#x27;filename&#x27; of module exports inside circular dependency</span><br></pre></td></tr></table></figure><p>搜索发现是依赖的某个插件导致，不解决也不影响使用，暂时没管。相关<a href="https://www.haoyizebo.com/posts/710984d0/">解决链接</a></p><p>接下来，就可以<code>hexo new</code>继续写作之旅了~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;博客荒废了好些年了，这段时间觉得没有大的、好的主题可以写，就一直处于断更状态。最近发现就当笔记记录一些东西备查也是挺好，如果再次过程中还能对他人有一点帮助，那就更好了。是时候捡起来继续了，首先要恢复出本地的写作及部署环境，这里记录一下以备下次使用…&lt;/p&gt;
&lt;h2 id=&quot;</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="hexo" scheme="http://blog.cuicc.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>我的2017个人总结</title>
    <link href="http://blog.cuicc.com/blog/2017/12/31/my-personal-review-2017/"/>
    <id>http://blog.cuicc.com/blog/2017/12/31/my-personal-review-2017/</id>
    <published>2017-12-31T07:19:25.000Z</published>
    <updated>2025-08-23T12:03:15.604Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>燕子去了，有再來的時候；楊柳枯了，有再青的時候；桃花謝了，有再開的時候。但是，聰明的，你告訴我，我們的日子為什麼一去不復返呢？──是有人偷了他們罷：那是誰？又藏在何處呢？是他們自己逃走了罷：現在又到了那裡呢？</p><footer><strong>朱自清</strong><cite><a href="https://zh.wikisource.org/wiki/%E5%8C%86%E5%8C%86">匆匆</a></cite></footer></blockquote><p>每年这个时候总结一下，看看<a href="/blog/2017/01/02/my-personal-review-2016/" title="我的2016个人总结">去年的目标</a>实现的怎么样，今年有哪些计划。</p><p>2017年最大的收获是小女的降临，带给我们太多的惊喜，太多的欢乐，更惊叹生命的神奇。从一事无知的小婴儿，到第一次发音（哭声之外），第一次抓头发，第一次吐泡泡，第一次抬头，第一次翻身，第一次爬，长出第一颗牙，认识爸爸妈妈，听懂爸爸妈妈说话，慢慢学走路… 太多的惊奇。2018年让我们探索更多的惊奇。</p><p>2017年最大的变化是由二人世界变成了三口之家。以前的随性而为，现在的三思而不行，在小宝宝身上以及家庭琐事上倾注了几乎所有的时间与精力。2018年希望能找到一定的平衡，对宝宝有高质量的陪伴，同时也有自己的时间，二人世界的时间。</p><p>2017年最大的欠缺是没有学好养娃这门学问。养娃远没有喂饱，穿暖，逗乐这么简单。以宝宝宝宝睡眠为例，为什么晚上易醒，醒来易哭，是饿了吗，是不困吗，什么是睡眠训练，怎么训练等等。2018年希望能在读书计划里加入育儿类书籍，打好理论基础，懂得宝宝各阶段的心理状态，应对方法。</p><p>2017年最大的无奈是工作被变动。由原来的接触各种新技术，广而不深的技术开发到技术单一，深而不广的产品开发。无奈的地方在于无休止的加班，越做越窄的工作内容而又暂时无法逃离。2018年希望在做不完的工作中能扩充自己的技能，继续保持对行业、科技、产品、趋势、模式的好奇心。</p><p>2017年最大的坚持是健身与读书。从家里徒手加哑铃，到公司健身房器械，虽然一直耿耿于怀的体重没有上去，但身体更好了，精神状态更好了。上半年读了不少书，有管理、有散文、有小说、有历史、有传记，下半年因为工作太累的原因，几乎没读。2018年希望继续坚持锻炼身体，以增肌为目标；希望继续坚持读书，利用好上下班的通勤时间，增加专业书籍的阅读量。</p><p>2018年的目标：</p><ol><li>有空多陪伴宝宝，解放宝妈，让宝妈有更多的时间做自己的事情；育儿理论基础增强，从各种育儿书，心理学等开始。</li><li>‎身体与灵魂，继续在路上。坚持健身，目标增肌增重。坚持读书，各种有趣的书，能写写读书笔记。</li><li>‎探索工作的多种可能，坚持各种博客杂文的积累下，多读几本技术专业书籍，提高综合知识面。</li><li>‎能规划一次长途旅行，去看看风景，看看人文，看看世界。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;&lt;p&gt;燕子去了，有再來的時候；楊柳枯了，有再青的時候；桃花謝了，有再開的時候。但是，聰明的，你告訴我，我們的日子為什麼一去不復返呢？──是有人偷了他們罷：那是誰？又藏在何處呢？是他們自己逃走了罷：現在又到了那裡呢？&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之多网络策略</title>
    <link href="http://blog.cuicc.com/blog/2017/09/10/kubernetes-network-policy/"/>
    <id>http://blog.cuicc.com/blog/2017/09/10/kubernetes-network-policy/</id>
    <published>2017-09-10T04:28:33.000Z</published>
    <updated>2025-03-16T07:58:25.515Z</updated>
    
    <content type="html"><![CDATA[<p>网络策略(<code>Network Policy</code>)是<code>Kubernetes</code>提供的一种规范，它描述了一组<code>Pod</code>是如何被允许相互通信的，以及和其他端点是如何通信的。<code>Kubernetes</code>只提供了这样的机制，具体功能由网络插件(<code>Network Plugins</code>)实现，流行的网络插件有很多，但并不是所有的网络插件都提供了网络策略功能，如<code>flannel</code>就没有提供这样的功能，目前已知的支持网络策略的有<code>Calico</code>, <code>Cilium</code>, <code>Kube-router</code>, <code>Romana</code>, <code>Weave Net</code>, <code>Canal</code>。</p><p>网络策略的应用和<code>Kubernetes</code>中很多操作类似，是通过<code>labels</code>来选取一组<code>Pods</code>的，然后再配置具体的规则(目前的实现都是通过配置<code>iptables rule</code>)来控制什么流量被允许发送到这组选取的<code>Pods</code>。</p><p><em>注:</em> 笔者使用的<strong>Kubernetes 1.6</strong>版本中网络策略还处于<code>beta</code>状态，其配置和<strong>Kubernetes 1.7</strong>中网络策略正式版略有差异。这里略作批注。</p><h2 id="网络策略"><a class="header-anchor" href="#网络策略"></a>网络策略</h2><p>使用网络策略的一般步骤如下(以<code>Calico</code>为例):</p><h3 id="配置网络策略"><a class="header-anchor" href="#配置网络策略"></a>配置网络策略</h3><ol><li>修改<code>kube-apiserver</code>的配置文件，添加配置项<code>--runtime-config=extensions/v1beta1/networkpolicies=true</code>，表示启用网络策略(<strong>Kubernetes 1.6</strong>版本中)</li><li>修改<code>kubelet</code>的配置文件，添加配置项<code>--network-plugin=cni</code>，表示使用CNI网络插件</li><li>根据<code>calico</code>相应版本的<a href="https://docs.projectcalico.org/v2.5/getting-started/kubernetes/installation/">安装文档</a>，安装<code>calico</code>插件，<strong>Calico Kubernetes Hosted Install</strong>方式比较简单。</li></ol><h3 id="使用网络策略"><a class="header-anchor" href="#使用网络策略"></a>使用网络策略</h3><p><code>kubernetes</code>官方文档有<a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">详细的说明</a>，这里简要列一下几个关键配置。</p><ol><li><p>默认配置下，<code>Pods</code>是不做隔离的，即集群内所有<code>Pod</code>之间都是互通的。<br>a. <strong>Kubernetes 1.6</strong>版本中在使用网络策略之前，需要先配置<code>namespace</code>为默认隔离，配置如下：</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;mynamespace&quot;,</span><br><span class="line">        &quot;labels&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;mynamespace&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">            &quot;net.beta.kubernetes.io/network-policy&quot;: &quot;&#123;\&quot;ingress\&quot;: &#123;\&quot;isolation\&quot;: \&quot;DefaultDeny\&quot;&#125;&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时，该<code>namespace</code>下的所有<code>Pod</code>都是隔离状态的，不接收任何来源的流量。</p><p>b. <strong>Kubernetes 1.7</strong>版本中直接通过网络策略配置，即配置网络策略的应用网络策略规则，未配置网络策略的还是未隔离状态。</p></li><li><p>使用标签选择器配置一组<code>Pod</code>的网路策略，即接收哪些来源的流量， 示例如下(<strong>Kubernetes 1.6</strong>版本<code>apiVersion</code>不同)，该配置表示：</p><ul><li>在名为<code>default</code>的命名空间中隔离所有标签为<code>role=db</code>的<code>Pod</code>， 如果没有隔离的话(<strong>Kubernetes 1.7</strong>版本)。</li><li>允许标签为<code>project=myproject</code>的命名空间中的所有<code>Pod</code>通过<code>TCP</code>连接该<code>default</code>命令空间里的标签为<code>role=db</code>的<code>Pod</code>的<code>6379</code>端口。</li><li>允许标签为<code>role=frontend</code>的<code>defult</code>命名空间中的所有<code>Pod</code>通过<code>TCP</code>连接该<code>default</code>命令空间里的标签为<code>role=db</code>的<code>Pod</code>的<code>6379</code>端口。</li></ul> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">&quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">&quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;test-network-policy&quot;,</span><br><span class="line">    &quot;namespace&quot;: &quot;default&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;spec&quot;: &#123;</span><br><span class="line">    &quot;podSelector&quot;: &#123;</span><br><span class="line">    &quot;matchLabels&quot;: &#123;</span><br><span class="line">        &quot;role&quot;: &quot;db&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;ingress&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;from&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;namespaceSelector&quot;: &#123;</span><br><span class="line">            &quot;matchLabels&quot;: &#123;</span><br><span class="line">                &quot;project&quot;: &quot;myproject&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;podSelector&quot;: &#123;</span><br><span class="line">            &quot;matchLabels&quot;: &#123;</span><br><span class="line">                &quot;role&quot;: &quot;frontend&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;ports&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;protocol&quot;: &quot;TCP&quot;,</span><br><span class="line">            &quot;port&quot;: 6379</span><br><span class="line">        &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>同样的，<strong>Kubernetes 1.7</strong>版本中，也提供了默认策略<br>a. 默认全隔离策略，类似于<strong>Kubernetes 1.6</strong>版本对<code>namespace</code>的配置，作用的命名空间下所有<code>Pod</code>在未应用其他网络策略的情况下是隔离状态。</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;default-deny&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;podSelector&quot;: null</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>b. 全通策略，作用的命名空间下所有<code>Pod</code>可接收任何流量，无视其上配置的其他网络策略。</p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;apiVersion&quot;: &quot;networking.k8s.io/v1&quot;,</span><br><span class="line">    &quot;kind&quot;: &quot;NetworkPolicy&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;allow-all&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;podSelector&quot;: null,</span><br><span class="line">        &quot;ingress&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="多网络策略"><a class="header-anchor" href="#多网络策略"></a>多网络策略</h2><p>在文章[kubernetes之多网络支持]中，以<code>flannel</code>为例讲述了多网络的配置方法。由于<code>flannel</code>不支持网络策略，这里使用<a href="https://github.com/Huawei-PaaS/CNI-Genie">Huawei-PaaS/CNI-Genie</a>插件为例，<code>CNI-Genie</code>也是集成引导插件，本身不做具体功能，由引用的插件完成网络功能，其支持<code>Calico</code>, <code>Weave Net</code>, <code>Canal</code>, <code>Romana</code>等。</p><h3 id="配置多插件"><a class="header-anchor" href="#配置多插件"></a>配置多插件</h3><p>在前述配置网络策略的基础上，再安装<code>CNI-Genie</code>, <code>Weave Net</code>, <code>Canal</code>, <code>Romana</code>等插件，以上插件官方都有<code>Kubernetes Hosted Install</code>的安装脚本，直接下载应用即可。这里<code>CNI-Genie</code>的配置文件是<code>00-**.conf</code>，而其他插件的配置文件是<code>10-**.conf</code>，所以按优先级默认加载的插件是<code>CNI-Genie</code>。</p><h3 id="使用多网络"><a class="header-anchor" href="#使用多网络"></a>使用多网络</h3><p><code>CNI-Genie</code>使用动态选择插件的策略，即每次部署都可以指定不同的插件，通过<code>Kubernetes</code>的<code>annotations</code>实现，示例如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: mytest</span><br><span class="line">  namespace: mynamespace</span><br><span class="line">  labels:</span><br><span class="line">    name: mytest</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: mytest</span><br><span class="line">      namespace: mynamespace</span><br><span class="line">      labels:</span><br><span class="line">        name: mytest</span><br><span class="line">      annotations:</span><br><span class="line">        cni: &quot;calico,weave&quot;</span><br><span class="line">        multi-ip-preferences: |</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;multi_entry&quot;: 0,</span><br><span class="line">            &quot;ips&quot;: &#123;</span><br><span class="line">              &quot;&quot;: &#123;</span><br><span class="line">                &quot;ip&quot;: &quot;&quot;,</span><br><span class="line">                &quot;interface&quot;: &quot;&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: mytest</span><br><span class="line">          image: mytest:latest</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 21234</span><br></pre></td></tr></table></figure><p>这里<code>annotations</code>添加了两个字段，<code>cni</code>表示该部署使用的网络插件，如这里使用的是<code>Calico</code>和<code>Weave Net</code>。<code>multi-ip-preferences</code>字段用于反填网络插件配置的ip地址和网络编号，以<code>ip1</code>, <code>ip2</code>, … 命名。</p><p><em>注</em>: <code>Calico</code>由于本身实现的问题，笔者在验证时不能作为非第一网络使用，具体参看<a href="https://github.com/projectcalico/cni-plugin/issues/352">github issue</a></p><h3 id="多网络策略-v2"><a class="header-anchor" href="#多网络策略-v2"></a>多网络策略</h3><p>网络策略的实现都是以<code>Kubernetes</code>里的<code>PodIP</code>为入参施加网络规则的，但在多网络配置下只有第一网络的ip被上报给<code>Kubernetes</code>，作为<code>PodIP</code>。也就是说我们无法通过<code>Kubernetes</code>存储的数据获取到多网络地址。这里我们可以利用<code>multi-ip-preferences</code>字段的值来满足定制化需求。</p><p>以<code>Weave Net</code>为例，需要定制其<code>npc</code>实现，所有获取<code>PodIP</code>的地方替换成如下方式获取的ip(获取第二网络地址，这里示例不具有灵活性，可考虑在<code>multi-ip-preferences</code>添加一个字段表示该ip属于哪个插件)。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">func getIPFromAnnotation(pod *coreapi.Pod) string &#123;</span><br><span class="line">var podIP2 string = &quot;&quot;</span><br><span class="line">var mip MultiIPPreferences</span><br><span class="line"></span><br><span class="line">mipJSON, found := pod.ObjectMeta.Annotations[&quot;multi-ip-preferences&quot;]</span><br><span class="line">if found &#123;</span><br><span class="line">if err := json.Unmarshal([]byte(mipJSON), &amp;mip); err == nil &#123;</span><br><span class="line">if value, ok := mip.Ips[&quot;ip2&quot;]; ok &#123;</span><br><span class="line">podIP2 = value</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return podIP2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，我们的多网络配置下，可以使网络策略作用于所有配置网络。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;网络策略(&lt;code&gt;Network Policy&lt;/code&gt;)是&lt;code&gt;Kubernetes&lt;/code&gt;提供的一种规范，它描述了一组&lt;code&gt;Pod&lt;/code&gt;是如何被允许相互通信的，以及和其他端点是如何通信的。&lt;code&gt;Kubernetes&lt;/code&gt;只</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之探针</title>
    <link href="http://blog.cuicc.com/blog/2017/07/23/kubernetes-probe/"/>
    <id>http://blog.cuicc.com/blog/2017/07/23/kubernetes-probe/</id>
    <published>2017-07-23T06:58:58.000Z</published>
    <updated>2025-03-16T07:58:25.515Z</updated>
    
    <content type="html"><![CDATA[<p>探针是<code>kubelet</code>用于周期性诊断容器的一种方式。目前<code>kubenertes</code>提供两种探针，通过调用容器提供的句柄(<code>handler</code>)来实现监测诊断。</p><h2 id="两种探针"><a class="header-anchor" href="#两种探针"></a>两种探针</h2><ul><li><strong>livenessProbe</strong>: 用于探测容器是否处于<code>Running</code>状态，如果该探针返回失败，<code>kubelet</code>将会杀掉容器，并根据<code>restart policy</code>来决定是否重新创建该容器。如果没有配置该探针，默认返回成功的状态，只有容器<code>crash</code>，才会触发失败状态返回。</li><li><strong>readinessProbe</strong>: 用于探测容器是否可以处理服务请求，如果该探针失败，端点控制器将会把该<code>Pod</code>的IP从关联的<code>Service</code>中删除掉。如果没有配置该探针，默认返回成功的状态。</li></ul><h2 id="三种操作"><a class="header-anchor" href="#三种操作"></a>三种操作</h2><ul><li><strong>ExecAction</strong>: 在容器中执行命令行，如果命令的退出状态是0，则认为探针的状态是成功。</li><li><strong>TCPSocketAction</strong>: 向容器指定端口上发送TCP请求，如果该端口已被监听，则认为探针的状态是成功。</li><li><strong>HTTPGetAction</strong>: 向容器指定端口和路径发送HTTP GET请求，如果返回状态码处于200到400之间，则认为探针的状态是成功。</li></ul><h2 id="四种场景"><a class="header-anchor" href="#四种场景"></a>四种场景</h2><ul><li><strong>Default</strong>: 不配置探针时，容器处于不健康的状态(如<code>crash</code>)时，<code>kubelet</code>也会杀掉容器；容器正常初始化后，就认为是可以提供服务的状态。</li><li><strong>Custom</strong>: 在某种情况下，进程无法正常提供功能，但容器依然处于健康状态，则可以通过配置<code>liveness</code>探针实现杀掉容器； 进程初始化事件比较长，则可以通过配置<code>readiness</code>探针实现服务可用。</li><li><strong>Reset</strong>: 某些进程处于中间过程状态，但又希望从初始状态开始时，可以通过配置<code>liveness</code>探针实现，同时提供复位接口，如请求复位接口，则探针返回失败状态，从而实现复位操作。默认返回成功状态。</li><li><strong>OutOfService</strong>: 在进行服务升级时，需要将服务临时下线，可以通过配置<code>readiness</code>探针实现，同时提供服务下线接口，如请求下线接口，则探针返回失败状态，从而实现下线操作。默认返回成功状态。</li></ul><p><em>参考:</em></p><ul><li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes"><em>Pod Lifecycle - Container probes</em></a></li><li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/"><em>Configure Liveness and Readiness Probes</em></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;探针是&lt;code&gt;kubelet&lt;/code&gt;用于周期性诊断容器的一种方式。目前&lt;code&gt;kubenertes&lt;/code&gt;提供两种探针，通过调用容器提供的句柄(&lt;code&gt;handler&lt;/code&gt;)来实现监测诊断。&lt;/p&gt;
&lt;h2 id=&quot;两种探针&quot;&gt;&lt;a clas</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之多网络支持</title>
    <link href="http://blog.cuicc.com/blog/2017/05/14/kubernetes-multi-networks/"/>
    <id>http://blog.cuicc.com/blog/2017/05/14/kubernetes-multi-networks/</id>
    <published>2017-05-14T03:30:55.000Z</published>
    <updated>2025-03-16T07:58:25.515Z</updated>
    
    <content type="html"><![CDATA[<p>某些场景下，我们需要多网络的支持，如<code>eth0</code>用于业务功能，<code>eth1</code>用于配置管理功能，那么<code>kubernetes</code>下该如何实现呢？</p><a href="/blog/2017/04/30/kubernetes-network/" title="kubernetes之网络分析">上一篇</a> 我们着重分析了各层级之间网络通信的方式，以及内外网之间的网络通信，这些通信方式的探讨都是基于单一网络的。<p><code>kubernetes</code>网络默认只支持单一网络，使用<code>noop</code>网络插件。<code>kubernetes</code>网络是以<code>Plugin</code>的方式实现的，它支持符合<code>CNI</code>规范的插件，通过<code>--network-plugin=</code>来指定，这就意味着我们可以定制网络方案。</p><p>关于<code>kubernets</code>网络插件，<a href="https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/">官方文档</a>有详细的描述，这里简单介绍一下:</p><p>网络插件还处于<code>alpha</code>阶段，其内容会经常发生变化。目前支持两种网络插件</p><ul><li>CNI plugin: 符合<code>CNI</code>规范的插件，其规范请参看<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md">官方文档</a>。</li><li>kubenet plugin：这个可看作是<code>kubernentes</code>官方提供的符合CNI规范的插件，基于<code>cbr0</code>，使用<code>CNI</code>的<code>bridge</code>和<code>local-host</code>插件。</li></ul><p>那么，要实现定制化的网络，只需按<code>CNI</code>规范实现<code>Add</code>和<code>Remove</code>接口即可。<code>kubernetes</code>多网络方案就是以<code>CNI</code>插件的方式实现的。以下操作基于<code>Ubuntu 14.04</code>，除<code>etcd</code>操作外，其他操作所有节点都要执行。</p><h2 id="准备工作"><a class="header-anchor" href="#准备工作"></a>准备工作</h2><ul><li>已部署多节点<code>kubernetes</code>集群，<code>overlay</code>网络使用<code>flannel</code></li><li>已安装<code>golang</code>编译环境</li><li>部署节点上已安装<code>bridge-utils</code>, <code>conntrack</code>和<code>nsenter</code></li><li>从<code>github</code>上下载<a href="https://github.com/Intel-Corp/multus-cni">multus-cni</a>，该插件实现多网络功能，具体网络功能由以下插件实现</li><li>[可选]从<code>github</code>上下载<a href="https://github.com/Intel-Corp/sriov-cni">sriov-cni</a>，该插件实现SR-IOV功能</li><li>从<code>github</code>上下载<a href="https://github.com/containernetworking/cni">cni</a>，基础插件库，包含<code>bridge</code>, <code>flannel</code>, <code>ipam</code>等</li></ul><h2 id="CNI插件"><a class="header-anchor" href="#CNI插件"></a>CNI插件</h2><p>将<code>multus-cni</code>, <code>sriov-cni</code>, <code>cni</code>放在<code>go</code>编译目录下，如<code>~/go/src/</code>下，分别编译三个插件，在各自目录下执行<code>./build.sh</code>。编译成功后，生成的二进制文件位于<code>./bin</code>下。</p><p>创建目录<code>/opt/cni/bin</code>，将编译好的二进制文件拷贝到该目录下。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/cni/bin</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/multus-cni/ &amp;&amp; ./build.sh</span><br><span class="line"><span class="built_in">cp</span> ./bin/* /opt/cni/bin/</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/sriov-cni/ &amp;&amp; ./build.sh</span><br><span class="line"><span class="built_in">cp</span> ./bin/* /opt/cni/bin/</span><br><span class="line"><span class="built_in">cd</span> ~/go/src/cni/ &amp;&amp; ./build.sh</span><br><span class="line"><span class="built_in">cp</span> ./bin/* /opt/cni/bin/</span><br></pre></td></tr></table></figure><h2 id="配置flannel网络"><a class="header-anchor" href="#配置flannel网络"></a>配置flannel网络</h2><p>以下操作除步骤4只需要在<code>master</code>节点操作外，其他步骤各节点都需要执行。</p><ol><li>创建该<code>flannel</code>网络使用的网桥，如<code>kbr1</code></li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brctl addbr kbr1</span><br></pre></td></tr></table></figure><ol start="2"><li>创建存放flannel网络配置的目录</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /run/flannel/networks</span><br></pre></td></tr></table></figure><ol start="3"><li>仿照<code>/run/flannel/subnets.env</code>文件，在<code>/run/flannel/networks</code>下创建配置文件，如<code>subnets2.env</code>，使用不同的网络段，如</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> /run/flannel/subnets.env /run/flannel/networks/subnets2.<span class="built_in">env</span></span><br><span class="line">vim /run/flannel/networks/subnets2.<span class="built_in">env</span></span><br><span class="line"><span class="comment">#modify as follows</span></span><br><span class="line">FLANNEL_NETWORK=173.17.0.0/16</span><br><span class="line">FLANNEL_SUBNET=173.17.76.1/24</span><br><span class="line">FLANNEL_MTU=1400</span><br><span class="line">FLANNEL_IPMASQ=<span class="literal">true</span></span><br></pre></td></tr></table></figure><ol start="4"><li>将该网络段注册到<code>etcd</code>，注意使用不同的前缀，如原网络使用的是<code>/coreos.com/network/</code>，这里使用<code>/k8s/network2/</code>。再者默认的<code>vlan index</code>是1，所以这里<code>VNI</code>为2</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/opt/bin/etcdctl <span class="built_in">set</span> /k8s/network2/config <span class="string">&#x27;&#123; &quot;Network&quot;: &quot;173.17.0.0/16&quot;, &quot;Backend&quot;: &#123; &quot;Type&quot;: &quot;vxlan&quot;, &quot;VNI&quot;: 2 &#125; &#125;&#x27;</span></span><br></pre></td></tr></table></figure><ol start="5"><li>使用上述配置启动新的<code>flannel daemon</code>，<a href="https://github.com/coreos/flannel/blob/master/Documentation/running.md#multiple-networks">参考文档</a>，其中<code>--etcd-endpoints=http://127.0.0.1:4001 --ip-masq --iface=172.16.1.171</code>来自于<code>/etc/default/flannel</code>文件</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/opt/bin/flanneld -subnet-file /run/flannel/networks/subnets2.env -etcd-prefix=/k8s/network2 --etcd-endpoints=http://127.0.0.1:4001 --ip-masq --iface=172.16.1.171 &amp;</span><br></pre></td></tr></table></figure><ol start="6"><li>创建<code>flannel</code>数据存储目录，存储<code>subnets2.env</code>网络相关的数据</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /var/lib/cni/flannel/2</span><br></pre></td></tr></table></figure><h2 id="配置multus-cni"><a class="header-anchor" href="#配置multus-cni"></a>配置multus-cni</h2><p>在<code>cni-conf-dir</code>(默认为<code>/etc/cni/net.d/</code>)下创建配置文件<code>test.conf</code>，其内容如下</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;multus-demo-network&quot;</span>,</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;multus&quot;</span>,</span><br><span class="line">    <span class="string">&quot;delegates&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;flannel.2&quot;</span>,</span><br><span class="line">                <span class="string">&quot;subnetFile&quot;</span>: <span class="string">&quot;/run/flannel/networks/subnets2.env&quot;</span>,</span><br><span class="line">                <span class="string">&quot;dataDir&quot;</span>: <span class="string">&quot;/var/lib/cni/flannel/2&quot;</span>,</span><br><span class="line">                <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;bridge&quot;</span>: <span class="string">&quot;kbr1&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;flannel.1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;subnetFile&quot;</span>: <span class="string">&quot;/run/flannel/subnet.env&quot;</span>,</span><br><span class="line">                <span class="string">&quot;dataDir&quot;</span>: <span class="string">&quot;/var/lib/cni/flannel&quot;</span>,</span><br><span class="line">                <span class="string">&quot;masterplugin&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;bridge&quot;</span>: <span class="string">&quot;docker0&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;isDefaultGateway&quot;</span>: <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该文件的作用是，配置两个<code>flannel</code>网络，指定了各自的<code>subnet</code>配置文件，数据存储位置<code>dataDir</code>，使用的网桥。其中<code>flannel.1</code>有<code>masterplugin</code>属性，其意为该网络会上报给<code>kubelet</code>。</p><h2 id="配置kubelet"><a class="header-anchor" href="#配置kubelet"></a>配置kubelet</h2><p><code>kubelet</code>的配置文件为<code>/etc/default/kubelet</code>, 在其行尾加上<code>--network-plugin=cni</code>。 如果上述的<code>cni bin</code>和<code>cni conf</code>不想放在默认目录下，这里可以使用<code>--cni-bin-dir</code>和<code>--cni-conf-dir</code>指定目录。</p><p>然后重启<code>kubelet</code>进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">service kubelet restart</span><br><span class="line">service kubelet status</span><br></pre></td></tr></table></figure><h2 id="Enjoy-it"><a class="header-anchor" href="#Enjoy-it"></a>Enjoy it</h2><p>现在，启动的<code>pod</code>都具有两个网络<code>eth0</code>和<code>net0</code>(<code>multus-cni</code>多网络是以<code>net0</code>, <code>net1</code> … <code>netn</code>命名的)。每个网络使用不同的<code>flannel</code>网络，网络间是隔离的，<code>vlan index</code>不同。如果需要更多的网络，只需增加配置即可。</p><p>该方案的缺点是配置是固定的，不能动态增删，需要重启<code>kubelet</code>。对每个<code>pod</code>而言，网络个数不能动态配置，依赖于整体方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;某些场景下，我们需要多网络的支持，如&lt;code&gt;eth0&lt;/code&gt;用于业务功能，&lt;code&gt;eth1&lt;/code&gt;用于配置管理功能，那么&lt;code&gt;kubernetes&lt;/code&gt;下该如何实现呢？&lt;/p&gt;
&lt;a href=&quot;/blog/2017/04/30/kuber</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
    <category term="flannel" scheme="http://blog.cuicc.com/tags/flannel/"/>
    
    <category term="multi-networks" scheme="http://blog.cuicc.com/tags/multi-networks/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之网络分析</title>
    <link href="http://blog.cuicc.com/blog/2017/04/30/kubernetes-network/"/>
    <id>http://blog.cuicc.com/blog/2017/04/30/kubernetes-network/</id>
    <published>2017-04-30T12:50:45.000Z</published>
    <updated>2025-08-23T12:14:09.391Z</updated>
    
    <content type="html"><![CDATA[<p><code>Kubernetes</code>是一个开源的容器集群管理平台，可用来自动化部署、扩展和运维应用容器。关于这个平台本身的各组件及具体功能不在本文讨论范围，本文主要关注<code>kubernetes</code>的网络方案。在讨论网络之前有必要先了解下相关概念，这些概念和网络息息相关。</p><h2 id="基本概念"><a class="header-anchor" href="#基本概念"></a>基本概念</h2><p><code>Containers</code>是最小的资源单位，用于轻松地打包应用程序及相关配置。但在<code>kubernetes</code>中，容器不是操作的最小单位，甚至容器本身对<code>kubernetes</code>是不可见的，而是通过包装在外面的<code>Pod</code>进行资源的管理。</p><p><code>Pods</code>是最小的部署单位，是部署在<code>kubernetes</code>中的应用的一个实例。可包含一组相关容器，<code>Pod</code>内共享的存储资源，一个唯一的网络IP以及一些选项配置容器该怎样运行。<code>Pod</code>中的所有容器共享一个网络IP，容器间可直接用<code>localhost</code>访问。</p><p><code>Replica sets</code>是<code>ReplicationController</code>的下一代实现，它和后者基本上是一样的，除了对选择器<code>Selector</code>的支持不一样。该控制器用来保证始终都有一定数量的<code>Pod</code>副本在运行，它会自动替换故障/被删除/被终止的副本。也就是说，少于设定的固定数量时，会自动创建到达该数量；多于该数量时，会自动删除到该数量。官方不建议直接使用该控制器，可用更高层的<code>Deployment</code>来管理。</p><p><code>Deployment</code>为<code>Pods</code>和<code>Replica sets</code>提供了声明更新，也就是说该控制器用来保证达到你描述的期望状态。使用该控制器可以方便的更新<code>Pods</code>(滚动升级)，如更新了容器镜像；可以方面的回滚到之前的部署版本；可以随时暂停和启动部署。</p><p><code>Service</code>有时也被称为微服务，是一个抽象的概念，它定义了一组<code>Pods</code>以及访问它们的策略。<code>Pods</code>是通过标签选择器<code>Label Selector</code>被集合在一起的。该抽象层屏蔽了后端的<code>Pods</code>副本，对外呈现一个访问入口。这样即使后端被替换，对外也是不感知的。所以，不管是对内还是对外提供的功能，都以<code>Service</code>作为服务入口是合理的做法。</p><p><code>Service</code>和<code>Deployment</code>可以看作是同一级的概念，<code>Service</code>用于<code>Pods</code>对外提供服务的管理，<code>Deployment</code>用于<code>Pods</code>本身的管理。以上各个概念之间的关系如下图：</p><img src="/images/k8s/k8s-concepts.png" class="" title="Kubernetes概念关系图"><p><code>Nodes</code>是指<code>kubernetes</code>集群的节点，提供能力的机器，如虚拟机等，这里列举一下便于下面的网络讨论。</p><h2 id="网络方案"><a class="header-anchor" href="#网络方案"></a>网络方案</h2><p>基于以上的概念，可以看到涉及到的网络通信有容器间的通信，<code>Pod</code>间的通信，服务间的通信，跨节点的通信，以及延伸一下跨集群的通信。那么这些网络通信在<code>kubernetes</code>里都是如何实施的呢？<code>kubernetes</code>官方给出了一个使用<code>OpenVSwitch</code>的<a href="https://kubernetes.io/docs/admin/ovs-networking/">网络方案</a>。这里基于这个网络方案图扩展一下，试图涵盖所有的网络连接类型。如下图所示，针对每种网络连接类型，后面会详细讨论。</p><img src="/images/k8s/k8s-network.png" class="" title="Kubernetes网络方案图"><h3 id="Container-to-Container"><a class="header-anchor" href="#Container-to-Container"></a>Container-to-Container</h3><p>上面我们已经提到，<code>kubernetes</code>不会直接操作容器本身，对外呈现的最小操作单位是<code>Pod</code>，这里容器之间的通信是指一个<code>Pod</code>内的容器之间如何通信。我们观察一个<code>Pod</code>里的资源时，会发现有一个自己启动的<code>pause</code>容器，这个容器的作用是为<code>Pod</code>提供网络，所有其他的容器(也就是我们通过模板启动的容器)，都是共享<code>pause</code>容器网络的。在实现上，如<code>Docker</code>提供了<code>--net=container:ID</code>这样的选项。</p><p>每个<code>pod</code>对外呈现一个唯一的IP，<code>Pod</code>内的各容器共享这个IP，也就是说各容器处于同一网络空间中，可直接使用<code>localhost</code>互相访问，需要注意的是各容器使用的端口不能冲突，可以认为<code>IP:Port</code>能够唯一确定一个容器。类比一个系统内的多个网络进程。</p><h3 id="Pod-to-Pod"><a class="header-anchor" href="#Pod-to-Pod"></a>Pod-to-Pod</h3><p><code>kubernetes</code>网络实现基于以下三个原则：</p><ul><li>所有容器和其他容器的通信不需要NAT</li><li>所有<code>node</code>和容器间的通信不需要NAT</li><li>容器自己看到的IP就是对外呈现的IP</li></ul><p>那么，这是如何做到的呢？在同一<code>node</code>时，是通过容器网桥实现的，如<code>Docker</code>默认使用的网桥<code>Docker0</code>；在跨<code>node</code>通信时，是通过<code>node</code>间的<code>overlay network</code>实现互联的，如<code>flannel</code>, <code>OpenVSwitch</code>提供的<code>VxLAN tunnel</code>。官方列举了更多的<code>overlay network</code>实现，<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">参考链接</a>。</p><h3 id="Pod-to-Service"><a class="header-anchor" href="#Pod-to-Service"></a>Pod-to-Service</h3><p>作为前端的<code>Service</code>与作为后端的<code>Pods</code>之间是通过<code>kubernetes</code>的组件<code>kube-proxy</code>实现通信的。<code>kube-proxy</code>为<code>Service</code>实现了虚拟IP的形式，即<code>ClusterIP</code>。有两种代理模式，<code>userspace</code>和<code>iptables</code>。</p><ul><li><code>userspace</code>模式下，需要在本<code>node</code>上分配<code>proxy port</code>，该port被代理到后端的<code>Pods</code>，这样来自<code>ClusterIP:Port</code>的信息被重定向到<code>proxy port</code>，然后代理到后端的<code>Pods</code>。</li><li><code>iptables</code>模式下，<code>kube-proxy</code>通过直接增删<code>iptables</code>规则实现重定向转发。它比<code>userspace</code>模式更快更可靠，缺点是当前<code>Pod</code>无响应时，它无法自动重试其他<code>Pod</code>，需要借助<code>readiness probes</code>实现。</li></ul><p>关于两种模式更详细的描述参考<a href="https://kubernetes.io/docs/concepts/services-networking/service/">官网文档</a></p><h3 id="Service-to-External"><a class="header-anchor" href="#Service-to-External"></a>Service-to-External</h3><p><code>Service</code>是以<code>ClusterIP</code>的形式对外提供服务的，但<code>ClusterIP</code>是集群内的虚拟IP网络。那么和集群外是如何通信的呢？可以通过以下方式实现：</p><ul><li><p><code>NodePort</code>: <code>kubernetes</code>从配置的端口范围(默认配置30000-32767)内分配一个端口，每个节点都会把该端口上的信息转发到<code>Service</code>中。这种方式可以通过集群内的任一节点<code>NodeIP:NodePort</code>访问到<code>Service</code>。这意味着整个集群最多只支持6万多个这种类型的服务。该类型的服务同样会分配一个内部的<code>ClusterIP</code>。</p></li><li><p><code>LoadBalancer</code>: 依赖于外部云提供商提供的服务均衡器，这同样需要<code>kubernetes</code>有相应的插件支持，具体的服务均衡策略由外部均衡器负责，信息将被定向到后端的<code>Pods</code>。这种类型的服务下，某些云提供商支持配置<code>LoadBalancerIP</code>，除此之外，上述的<code>ClusterIP</code>和<code>NodePort</code>也同样会分配以便正确的路由到<code>Service</code>。</p></li><li><p><code>ExternalName</code>: 该类型和上述几种不一样，它不需要代理或转发，它是通过<code>kube-dns</code>解析<code>CNAME</code>记录的方式重定向url实现的。</p></li></ul><p>从上面可以看出，<code>ClusterIP</code>, <code>NodePort</code>, <code>LoadBalancer</code>这三种类型是层层嵌套实现的。但对云提供商没有严格要求这样做，只是目前的API是这样的。</p><p>除了这几种服务类型之外，还可以使用<code>ExternalIPs</code>实现集群内外的互通，所谓的<code>ExternalIP</code>是指能够被路由到<code>kubernetes</code>节点的IP的，在公有云上，也就是我们所说的公网IP。<code>ExternelIPs</code>可以和任一类型的<code>Service</code>一起使用。</p><p>具体配置模板可参考<a href="https://kubernetes.io/docs/concepts/services-networking/service/">官网文档</a></p><h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2><p>至此，已涵盖网络方案图里的所有通信类型。在使用上做几点总结：</p><ul><li><p><code>Pod</code>(应用)的各<code>Container</code>(进程)通信可以看作是<code>VM</code>上各进程间的通信，<code>Pod</code>类似<code>VM</code>。</p></li><li><p><code>Pod</code>作为功能提供方时，以<code>Service</code>方式提供，屏蔽后端的具体实现，不直接对外暴露<code>Pod</code>。</p></li><li><p>集群<code>node</code>间的<code>overlay</code>网络不要和大网互通，保持集群的私密性。需要和外部交互时，通过<code>Service</code>。</p></li><li><p>集群内外通信，大网IP充足时，使用<code>ExternalIPs</code>，不拘泥于<code>Service</code>类型，否则使用<code>NodePort</code>，私有集群下基本够用。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Kubernetes&lt;/code&gt;是一个开源的容器集群管理平台，可用来自动化部署、扩展和运维应用容器。关于这个平台本身的各组件及具体功能不在本文讨论范围，本文主要关注&lt;code&gt;kubernetes&lt;/code&gt;的网络方案。在讨论网络之前有必要先了解下相关概念，</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="kubernetes" scheme="http://blog.cuicc.com/tags/kubernetes/"/>
    
    <category term="docker" scheme="http://blog.cuicc.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Sails:Node.js的MVC框架</title>
    <link href="http://blog.cuicc.com/blog/2017/04/09/Sails-MVC-framework-for-Node-js/"/>
    <id>http://blog.cuicc.com/blog/2017/04/09/Sails-MVC-framework-for-Node-js/</id>
    <published>2017-04-09T08:57:09.000Z</published>
    <updated>2025-03-16T07:58:25.515Z</updated>
    
    <content type="html"><![CDATA[<p><code>Sails</code>是<code>Node.js</code>上最流行的<code>MVC</code>架构模式的web框架，在设计上参考了<code>Ruby on Rails</code>的MVC框架模式，它是基于<code>Node.js</code>上最火爆的web框架<code>Express</code>开发的。 和其他的MVC框架不同的是，Sails的<code>MC</code>在服务端，而<code>V</code>在客户端，提供可扩展的、面向服务的数据驱动API。在使用上和其他知名的MVC框架类似，如PHP的<code>CodeIgnite</code>。</p><h2 id="基本用法"><a class="header-anchor" href="#基本用法"></a>基本用法</h2><p><code>Sails</code>在使用上提供了极大的便利性，创建一个项目使用命令<code>sails new &lt;project name&gt;</code>，运行则在项目目录下执行<code>sails lift</code>，然后可以通过<code>ip:1337</code>访问，如<code>localhost:1337</code>。</p><p>在开发上可使用命令<code>sails generate api cats</code>来生成<code>controller</code>和<code>model</code>，分别是<code>api/controllers/CatsController.js</code>和<code>api/models/Cats.js</code>。<code>view</code>则放在<code>views</code>目录下，支持多种模板语言，如<code>ejs</code>, <code>swig</code>等。</p><p>这里不深入探讨基本用法，主要侧重在<code>Sails</code>比较具有代表性的两个功能上，<code>Blueprints</code>和<code>Waterline</code>。</p><h2 id="Blueprints"><a class="header-anchor" href="#Blueprints"></a>Blueprints</h2><p><code>Blueprints</code>旨在减少代码数量及节约时间，它提供了一种快速生成API <code>routes</code>和<code>actions</code>(actions是指controller里定义的方法)的方法。<code>blueprint API</code>由两部分组成：<code>blueprint routes</code>和<code>blueprint actions</code>。</p><h3 id="Blueprint-Actions"><a class="header-anchor" href="#Blueprint-Actions"></a>Blueprint Actions</h3><p><code>Blueprint actions</code>是指一些通用方法，它们作用于任何<code>controller</code>来操作它的同名<code>model</code>，例如<code>CatsController.js</code>需要有<code>Cats.js</code>。这些方法是内置方法，即使<code>controller</code>是空的情况下也可以使用。方法如下：<code>find</code>, <code>findOne</code>, <code>create</code>, <code>update</code>, <code>destroy</code>, <code>populate</code>, <code>add</code>, <code>remove</code>，这些方法也就是下面的数据模型操作的<code>Waterline</code>所提供的方法。</p><h3 id="Blueprint-routes"><a class="header-anchor" href="#Blueprint-routes"></a>Blueprint routes</h3><p><code>Blueprint routes</code>是在执行<code>sails lift</code>时根据<code>controller</code>, <code>model</code>, <code>config</code>自动生成的路由。默认情况下，一个route指向一个action。有以下三种路由配置，配置文件位于<code>config/blueprints.js</code>。</p><ul><li><p><strong>RESTful routes</strong> 可通过RESTful接口直接对model进行CRUD操作。如<code>GET /user</code>将获取user列表，对应于<code>user.find()</code>; <code>POST /user</code>将增加一个user，对应于<code>user.create()</code>。RESTful路由最好使用<code>policies</code>进行保护以免未授权的用户访问。</p></li><li><p><strong>Shortcut routes</strong> 和<code>RESTful routes</code>类似，不同的是可直接把<code>action</code>编码在url中，如<code>/user/create?name=joe</code>可实现上面的<code>POST</code>方法的功能。而在这里都是<code>GET</code>操作。该路由适合在开发调试阶段使用，产品环境最好关闭。</p></li><li><p><strong>Action routes</strong> 当你在<code>controller</code>中实现了一些自定义的方法时，该功能可自动生成对应的路由，如<code>CatsController.js</code>中有方法<code>meow</code>，那么可通过<code>/cats/meow</code>接口访问。这里和其他<code>MVC</code>自动生成<code>controller</code>的路由一样的用法。和上面不同的是，自定义方法时同名<code>model</code>不是必须的。</p></li></ul><h2 id="Waterline"><a class="header-anchor" href="#Waterline"></a>Waterline</h2><p><code>Waterline</code>是数据无关的一个抽象适配层，让你在操作数据时无需关心底层数据库类型，不用写某种数据库专用的操作代码。其底层支持<code>SQL</code>型和<code>NoSQL</code>型数据库, 如<code>MySQL</code>, <code>MongoDB</code>等。对接某一具体数据库时，你所需要做的就是在<code>config/connections.js</code>里配置适配器，在<code>config/models.js</code>配置<code>models</code>默认连接的具体适配器，当然也可以在某一具体<code>model</code>里指定连接的适配器。这样，需要切换数据库时，只需修改连接的适配器即可，不需要修改一行代码。</p><p><code>model</code>中的数据模型结构如下，虽然某些字段看起来时<code>SQL</code>型数据库专用的，但定义了这些字段并不影响<code>NoSQL</code>型数据库使用。这里该<code>model</code>中的<code>connection</code>定义会覆盖掉<code>config/models.js</code>里的定义。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Model example</span></span><br><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">  <span class="attr">connection</span>: <span class="string">&#x27;MySQLDB&#x27;</span>,</span><br><span class="line">  <span class="attr">tableName</span>: <span class="string">&#x27;users&#x27;</span>,</span><br><span class="line">  <span class="attr">attributes</span>: &#123;</span><br><span class="line">    <span class="attr">id</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;integer&#x27;</span>,</span><br><span class="line">      <span class="attr">unique</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">primaryKey</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">columnName</span>: <span class="string">&#x27;the_primary_key&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">name</span>: &#123;</span><br><span class="line">      <span class="attr">type</span>: <span class="string">&#x27;string&#x27;</span>,</span><br><span class="line">      <span class="attr">columnName</span>: <span class="string">&#x27;full_name&#x27;</span></span><br><span class="line">    &#125;，</span><br><span class="line"></span><br><span class="line">    <span class="attr">getFullName</span>: <span class="keyword">function</span>(<span class="params"></span>)&#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">   <span class="attr">enroll</span>: <span class="keyword">function</span> (<span class="params">options, cb</span>) &#123;</span><br><span class="line">       ...</span><br><span class="line">       <span class="title function_">cb</span>(err, data);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的<code>model</code>示例可以看到，除了属性字段定义外，还有一些函数定义。这里看到的是我们自定义的函数，<code>Sails</code>还提供了一些内置函数。我们还发现函数可以在属性内，也可以在属性外，下面详细介绍一下。</p><h3 id="Model-Method"><a class="header-anchor" href="#Model-Method"></a>Model Method</h3><p>模型方法也称为静态方法或者类方法，放在面向对象里很好理解，就是该类提供的静态方法，不需要实例化可直接使用的方法。上面放在<code>attributes</code>外定义的方法就是模型方法。<code>Sails</code>提供的内置模型方法涵盖了增删改查，具体方法列表看<a href="http://sailsjs.com/documentation/reference/waterline-orm/models">官方文档</a>。除了这些方法外，还支持动态查找功能，以上面的<code>model</code>为例，该<code>model</code>有属性<code>id</code>和<code>name</code>，那么就有动态查找方法<code>findById</code>和<code>findByName</code>。</p><p>需要注意的是，模型静态方法都是异步方法，方法有两个参数，第一个是输入值，第二个是回调函数。输入值最好是一个完整记录或者时主键。自定义模型静态方法的好处是你可以把数据操作方法放在<code>controller</code>之外，放在<code>model</code>里，这样你在其他<code>controller</code>中也可以重用，当然前提是与<code>req</code>和<code>res</code>无关的操作。</p><h3 id="Attribute-Method"><a class="header-anchor" href="#Attribute-Method"></a>Attribute Method</h3><p>属性方法也称为记录方法或者实例方法，顾名思义，它是作用于某一实例或某一记录的方法。放在<code>attributes</code>内定义的方法就是自定义属性方法，当然<code>Sails</code>也提供了一些内置的属性方法，包括<code>.toJSON()</code>, <code>.save()</code>, <code>.toObject()</code>，详细介绍看<a href="http://sailsjs.com/documentation/reference/waterline-orm/records">官方文档</a>。</p><p>除了内置方法<code>.save()</code>外，属性方法都应当是同步的方法。因为自定义异步属性方法时，很难保证不出现意外结果。在命名属性方法时，最好加上前缀<code>is</code>，<code>get</code>等以区分其他属性，并对方法提供一定的自解释。</p><h3 id="more…"><a class="header-anchor" href="#more…"></a>more…</h3><p>这里只是管中窥豹，只介绍了最表面的冰山一角，以说明Waterline的功能强大，其他还有<code>Associations</code>, <code>Validations</code>等等，如有兴趣，强烈建议看一下<a href="http://sailsjs.com/documentation/concepts/models-and-orm">官方文档</a>。</p><h2 id="官方文档"><a class="header-anchor" href="#官方文档"></a>官方文档</h2><ul><li><p>工程结构请参考<a href="http://sailsjs.com/documentation/anatomy">APP Structure</a></p></li><li><p>基本概念请参考<a href="http://sailsjs.com/documentation/concepts">Concepts</a></p></li><li><p>接口使用请参考<a href="http://sailsjs.com/documentation/reference">API Reference</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;code&gt;Sails&lt;/code&gt;是&lt;code&gt;Node.js&lt;/code&gt;上最流行的&lt;code&gt;MVC&lt;/code&gt;架构模式的web框架，在设计上参考了&lt;code&gt;Ruby on Rails&lt;/code&gt;的MVC框架模式，它是基于&lt;code&gt;Node.js&lt;/code&gt;</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="Node.js" scheme="http://blog.cuicc.com/tags/Node-js/"/>
    
    <category term="Sails" scheme="http://blog.cuicc.com/tags/Sails/"/>
    
    <category term="MVC" scheme="http://blog.cuicc.com/tags/MVC/"/>
    
  </entry>
  
  <entry>
    <title>Node.js抛异常ECONNRESET退出</title>
    <link href="http://blog.cuicc.com/blog/2017/03/26/nodejs-ECONNRESET/"/>
    <id>http://blog.cuicc.com/blog/2017/03/26/nodejs-ECONNRESET/</id>
    <published>2017-03-26T06:15:53.000Z</published>
    <updated>2025-03-16T07:58:25.515Z</updated>
    
    <content type="html"><![CDATA[<p>项目中需要对接公司域账户对其他模块提供鉴权服务。为方便实现Restful接口，以及学习一门没用过的技术，于是决定使用Node.js开发实现。</p><h2 id="LDAP鉴权服务接口"><a class="header-anchor" href="#LDAP鉴权服务接口"></a>LDAP鉴权服务接口</h2><p>该服务实现两个功能，一个是和LDAP服务器对接鉴权域登录，一个是对外以Restful API的方式提供服务。Node.js的库<a href="http://ldapjs.org/">ldapjs</a>和<a href="https://expressjs.com/">Express</a>可以很简单的完成这两个功能。实现大体框架如下</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> ldap = <span class="built_in">require</span>(<span class="string">&#x27;ldapjs&#x27;</span>);</span><br><span class="line">...</span><br><span class="line"><span class="keyword">var</span> app = <span class="title function_">express</span>();</span><br><span class="line"></span><br><span class="line">app.<span class="title function_">post</span>(</span><br><span class="line">    <span class="string">&#x27;auth&#x27;</span>,</span><br><span class="line">    <span class="keyword">function</span>(<span class="params">req, res</span>)&#123;</span><br><span class="line">        <span class="keyword">var</span> user = &#123;</span><br><span class="line">            <span class="attr">username</span>: req.<span class="property">body</span>.<span class="property">username</span>,</span><br><span class="line">            <span class="attr">password</span>: req.<span class="property">body</span>.<span class="property">password</span>,</span><br><span class="line">            dn      : <span class="string">&#x27;&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">var</span> adminClient = ldap.<span class="title function_">creatClient</span>(&#123;<span class="attr">url</span>:url&#125;);</span><br><span class="line">        adminClient.<span class="title function_">bind</span>(admin.<span class="property">dn</span>, admin.<span class="property">password</span>, <span class="keyword">function</span>(<span class="params">err</span>)&#123;</span><br><span class="line">            assert.<span class="title function_">ifError</span>(err);</span><br><span class="line"></span><br><span class="line">            adminClient.<span class="title function_">search</span>(base, opts, <span class="keyword">function</span>(<span class="params">err, search</span>)&#123;</span><br><span class="line">                search.<span class="title function_">on</span>(<span class="string">&#x27;searchEntry&#x27;</span>, <span class="keyword">function</span>(<span class="params">entry</span>)&#123;</span><br><span class="line">                    user.<span class="property">dn</span> = entry.<span class="property">dn</span>; </span><br><span class="line">                    <span class="keyword">var</span> userClient = ldap.<span class="title function_">createClient</span>(&#123;<span class="attr">url</span>:url&#125;);</span><br><span class="line">                    userClient.<span class="title function_">bind</span>(user.<span class="property">dn</span>, user.<span class="property">password</span>, <span class="keyword">function</span>(<span class="params">err</span>)&#123;</span><br><span class="line">                        <span class="keyword">if</span>(err)&#123;</span><br><span class="line">                            res.<span class="title function_">json</span>(&#123;<span class="string">&#x27;status&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;message&#x27;</span>:<span class="string">&#x27;invalid password&#x27;</span>&#125;);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        res.<span class="title function_">json</span>(&#123;<span class="string">&#x27;status&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;message&#x27;</span>:<span class="string">&#x27;auth ok&#x27;</span>&#125;);</span><br><span class="line">                    &#125;);</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">                search.<span class="title function_">on</span>(<span class="string">&#x27;end&#x27;</span>, <span class="keyword">function</span>(<span class="params">err</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(user.<span class="property">dn</span> === <span class="string">&#x27;&#x27;</span>)&#123;</span><br><span class="line">                        res.<span class="title function_">json</span>(&#123;<span class="string">&#x27;status&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;invalid user&#x27;</span>&#125;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">app.<span class="title function_">listen</span>(<span class="number">8080</span>, <span class="keyword">function</span>(<span class="params"></span>)&#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;listening on port 8080&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>完成后，使用postman测试了下，功能没有问题。但程序会在十几分钟后抛出异常，退出执行。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">events.<span class="property">js</span>:<span class="number">72</span></span><br><span class="line">        <span class="keyword">throw</span> er; </span><br><span class="line">              ^</span><br><span class="line"><span class="title class_">Error</span>: read <span class="variable constant_">ECONNRESET</span></span><br><span class="line">    at <span class="title function_">errnoException</span> (net.<span class="property">js</span>:<span class="number">900</span>:<span class="number">11</span>)</span><br><span class="line">    at <span class="variable constant_">TCP</span>.<span class="property">onread</span> (net.<span class="property">js</span>:<span class="number">555</span>:<span class="number">19</span>)</span><br></pre></td></tr></table></figure><p>遂Google了一下Nodejs ECONNRESET。</p><h2 id="Node-js-ECONNRESET"><a class="header-anchor" href="#Node-js-ECONNRESET"></a>Node.js ECONNRESET</h2><p>stackoverflow上有一个问答专门探讨这个<a href="http://stackoverflow.com/questions/17245881/node-js-econnreset">问题</a>，简单摘录一下回答</p><blockquote><p>“ECONNRESET” means the other side of the TCP conversation abruptly closed its end of the connection. This is most probably due to one or more application protocol errors. You could look at the API server logs to see if it complains about something.</p><footer><strong>e-sushi</strong><cite><a href="http://stackoverflow.com/a/17637900">ECONNRESET</a></cite></footer></blockquote><p>ECONNRESET表示TCP会话的另一端突然断开了连接。很大可能性是由应用的协议出错造成的。这里我有两个连接，一个是Restful接口的连接，一个是ldap的连接。</p><blockquote><p>I had a similar problem where apps started erroring out after an upgrade of Node. I believe this can be traced back to Node release v0.9.10 this item:</p><p>net: don’t suppress ECONNRESET (Ben Noordhuis)</p><p>Previous versions wouldn’t error out on interruptions from the client. A break in the connection from the client throws the error ECONNRESET in Node. I believe this is intended functionality for Node, so the fix (at least for me) was to handle the error, which I believe you did in unCaught exceptions. Although I handle it in the net.socket handler.</p><footer><strong>John Williams</strong><cite><a href="http://stackoverflow.com/a/17798353">ECONNRESET</a></cite></footer></blockquote><p>从Node v0.9.10开始不再压制ECONNRESET，之前的版本从客户端中断时不会报错。现在从客户端中断会抛出ECONNRESET错误，这是Node的预期功能。解决方法是处理这个错误，因为这是一个未捕获的异常。</p><h2 id="原因分析"><a class="header-anchor" href="#原因分析"></a>原因分析</h2><p>综上可总结该问题的原因：</p><ol><li>Node退出是因为出现未捕获的异常，异常为<code>read ECONNRESET</code>错误。</li><li><code>ECONNRESET</code>是因为TCP连接的对端(通常是server)突然断开了连接。server一般都设置了<code>keepalive</code>，对于不活动的连接会超时断开。</li><li>客户端请求完成后没有主动断开连接。</li></ol><h2 id="解决方法"><a class="header-anchor" href="#解决方法"></a>解决方法</h2><p>简单的解决方法就是捕获这个异常，如果无法定位出具体出这个异常的地方，可以在进程级捕获进行分析。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">process.<span class="title function_">on</span>(<span class="string">&#x27;uncaughtException&#x27;</span>, <span class="keyword">function</span>(<span class="params">err</span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(err.<span class="property">stack</span>);</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;NOT exit...&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>而在本例中，作为客户端请求的是ldap，ldap服务器断开了不活动的连接，应该由ldap来捕获异常，但<a href="http://ldapjs.org/client.html">官方文档</a>并没有相关说明。在github该库的<a href="https://github.com/mcavage/node-ldapjs/issues/318">issue</a>中找到了捕获方法。client有监听error事件功能，以及可以设置client自动重连，官方文档未更新。基本用法如下：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> client = ldap.<span class="title function_">creatClient</span>(&#123;<span class="attr">url</span>:url, <span class="attr">reconnect</span>: <span class="literal">true</span>&#125;);</span><br><span class="line">...</span><br><span class="line">client.<span class="title function_">on</span>(<span class="string">&#x27;error&#x27;</span>, <span class="keyword">function</span>(<span class="params">err</span>)&#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(err);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>对于小的应用请求而言，client主动断开连接是比较优雅的做法，根据该issue，client具有<code>destroy</code>方法，可以主动销毁创建的client对象。基本用法如下：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">client.<span class="title function_">unbind</span>();</span><br><span class="line">client.<span class="title function_">destroy</span>();</span><br></pre></td></tr></table></figure><p>但测试了一下并没有起作用。这里采用client捕获异常防止进程退出的方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;项目中需要对接公司域账户对其他模块提供鉴权服务。为方便实现Restful接口，以及学习一门没用过的技术，于是决定使用Node.js开发实现。&lt;/p&gt;
&lt;h2 id=&quot;LDAP鉴权服务接口&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#LDAP鉴权服务接口</summary>
      
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="Node.js" scheme="http://blog.cuicc.com/tags/Node-js/"/>
    
  </entry>
  
  <entry>
    <title>心智是否成熟</title>
    <link href="http://blog.cuicc.com/blog/2017/03/12/grow-up/"/>
    <id>http://blog.cuicc.com/blog/2017/03/12/grow-up/</id>
    <published>2017-03-12T12:05:40.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>职场中，我们经常听到招聘要找一个心智成熟的人；生活中，我们经常听到说一个人很幼稚，不成熟，即使年龄已经不小。那么，到底什么是心智？心智成熟的表现是什么？或者说怎么去做一个心智成熟的人呢？学习摘抄了一下，与君共勉。</p><h2 id="什么是心智"><a class="header-anchor" href="#什么是心智"></a>什么是心智</h2><p>心智的定义，我看了下<a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E7%81%B5">维基百科</a>和<a href="http://baike.baidu.com/item/%E5%BF%83%E6%99%BA">百度百科</a>。相比较而言，我更喜欢百度百科的描述，相对更容易理解一点。</p><blockquote><p>心智是人们的心理与智能的表现。</p><p>心智定义：即是指人们对已知事物的沉淀和储存，通过生物反应而实现动因的一种能力总和。它涵盖了“哲学”对已知事物的积累和储存，结合了“生物学”的大脑信息处理，即“生物反应”，运用了为实现某种欲需（动因）而从事的“心理”活动，从而达到为实现动因结果而必须产生的智能力和“潜能”力。</p><p>一个人的“心智”指的是他各项思维能力的总和，用以感受、观察、理解、判断、选择、记忆、想像、假设、推理，而后根据指导其行为。</p><footer><strong>百度百科</strong><cite><a href="http://baike.baidu.com/item/%E5%BF%83%E6%99%BA">心智</a></cite></footer></blockquote><p>心智也可以简化为两个关键词：思维和智力。<br>那么如果去判断一个人心智是否成熟/怎么去做一个心智成熟的人呢，也主要从这两个方面来看。</p><h2 id="成熟的心智"><a class="header-anchor" href="#成熟的心智"></a>成熟的心智</h2><p>Google了一下心智成熟，发现有两个描述比较好，一个比较详尽且有对比，但不知道出处。另一个比较精炼，出自于《King, Warrior, Magician, Lover 》。这两个描述基本主旨是相似的。这既可以用来判断，也可以查找不足，努力成长。</p><h3 id="详尽的描述"><a class="header-anchor" href="#详尽的描述"></a>详尽的描述</h3><blockquote><p>1.心智成熟的人， 在日常的生活工作中，为人处世，行事判断有主见，有原则，不以别人的喜恶行为来左右自己的行事处世标准。</p><p>2.心智成熟的人， 承认人性中有光明的一面，有黑暗的一面，有慈善的一面，有阴暗的一面，有优点又有缺点，并有容忍和谅解的胸襟。</p><p>3.心智成熟的人， 能够坦然地接受对方的一切优点和缺点，懂得学会与别人如何相处之道。</p><p>4.心智成熟的人， 会从很多不同的视角看问题，而孩子气的人， 通常只从自己的角度看问题！</p><p>5.心智成熟的人， 明白良好的动机未必带来良好的效果，艰苦的付出未必收到丰硕的成果，了解手段与目的之不可分割。</p><p>6.“不以人废言”，懂得“以事论事”而“不以人论事”的道理。承认真理的绝对性，不看人的地位的高低而断言论是非。</p><p>7.面对批评， 成熟的人， 会心平气和， 想想道理， 努力改进 ；不成熟的人，则会垂头丧气， 或暴怒不已。</p><p>8.出状况时，成熟的人习惯反省，并乐意致歉；不成熟的人，只会指责他人，从不道歉。</p><p>9.心智成熟的人，因充满自信而心有余力，总是善意解读他人之言行，并且有礼回应；不成熟的人，缺乏自信而敏感多疑，认为别人的言行总是另有目的，忍不住会语带挑衅地回应。</p><p>10.遇到心情低谷时，成熟的人，会为自己的心情负责，想的是：“我该做些什么，可以让事情好转？”；不成熟的人，则是要他人为自己情绪负责，想的是：“ TA该做什么，才能让我的心情好转？” 。</p><p>11.成熟的人，会利用幽默感调整心情，自我解嘲时，能用旁观者视角，读出其中有趣，而轻松化解情绪；不成熟的人，则是用幽默来仓皇掩盖心中情绪，自我解嘲后，心情往往更难堪而低迷。</p><p>12.在人际关系中，成熟的人常说：“我愿意……”，主动付出爱；不成熟的人总是说：“我需要……”，只会提要求。</p><p>13.明白“人比人气死人”的道理，不拿自己跟别人滥加比较。不要勉强自己去做天才明星。百万富翁屈指可数，平凡人总是大多数。明白富人有富人的烦恼，凡人有凡人乐趣。</p><p>14.了解人与人之间的沟通乃是世上最难最难也是最有意义的一件事情，而封闭自傲的心灵正是沟通的最大敌人。</p><p>15.能够独立思考或作正确的决定。做事不会反复无常，对重要的决定事项，无须依赖别人而能够独立判断。</p><footer><strong>豆瓣</strong><cite><a href="https://www.douban.com/group/topic/29621603/">如何看一个人心智是否成熟</a></cite></footer></blockquote><h3 id="精炼的描述"><a class="header-anchor" href="#精炼的描述"></a>精炼的描述</h3><blockquote><p>• 他们沉稳，处事不惊。能够在危险中保持镇定。<br>• 他们不容易被冒犯，却很容易能给人带来安全和可靠感。<br>• 他们从不寻求关注和爱护。他们生活的趋势是给于他人认同，给于爱。<br>• 他们习惯于慷慨的给于他人帮助。他们深知，助人强者无不自强。<br>• 他们的生活有确定的使命，行动和思维从不混乱。<br>• 他们能够忍耐痛苦，但依旧敞开心活着。他们不怕被骗，被看不起。<br>• 他们从来不为自己辩解，因为他们知道自己是谁。</p><footer><strong>Robert Moore / Douglas Gillette </strong><cite>King Warrior Magician Lover</cite></footer></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;职场中，我们经常听到招聘要找一个心智成熟的人；生活中，我们经常听到说一个人很幼稚，不成熟，即使年龄已经不小。那么，到底什么是心智？心智成熟的表现是什么？或者说怎么去做一个心智成熟的人呢？学习摘抄了一下，与君共勉。&lt;/p&gt;
&lt;h2 id=&quot;什么是心智&quot;&gt;&lt;a class=&quot;h</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="心智" scheme="http://blog.cuicc.com/tags/%E5%BF%83%E6%99%BA/"/>
    
  </entry>
  
  <entry>
    <title>我的2016个人总结</title>
    <link href="http://blog.cuicc.com/blog/2017/01/02/my-personal-review-2016/"/>
    <id>http://blog.cuicc.com/blog/2017/01/02/my-personal-review-2016/</id>
    <published>2017-01-02T04:34:46.000Z</published>
    <updated>2025-08-23T12:03:02.530Z</updated>
    
    <content type="html"><![CDATA[<p>时间过得很快，转眼又是一年过去了。我还记得年初给老大们分享外企与私企工作异同时，有这样一个观点：所谓人傻钱多活少，并不是一个良好的状态，上班整天无所事事，下班一样也无所事事，看似有大把的时间，在这样的状态下，有再多的时间还是啥也不想干。</p><p>这一年，不是产品合作开发，就是支援产品开发。尤其是下半年，充分感受了产品开发的忙、累，比所谓的996更变态。同样地在这样一种身心疲惫的工作状态下，对很多事情都是有心无力。</p><p>这两种状态从侧面印证了我的论断：保持一定的忙碌状态，这样所有的爱好与习惯都是有条不紊的坚持下去。</p><p>还记得2015年，坚持了一年的身体锻炼，读了数十本不同种类的书。基于这美好的过去一年，曾写下2016年的目标。回首过去这一年，锻炼身体懈怠了，书读的少了，新东西学的半途而废了，没有一个坚持下来的。客观原因是上下班路程远，花的时间多；支援产品太忙太累。主观原因是心理上懈怠了，忘了坚持的意义。虽然如此，过去这一年还是有些需要总结的地方。</p><p>这一年，实现了每年一次长途旅行的目标。仍然没有走出亚洲，希望能有机会去欧洲、美洲走一遭。这一次去的是台湾，完全没有语言障碍的地方。台湾给我印象最深的是人文，礼貌、素质、秩序、友好，体现得淋漓尽致；故宫博物院的文物藏品玲琅满目，手艺与想象的集大成者，更不用说其历史价值了。</p><p>这一年，在休养了半年后，终于成功研发了2.1版 — 小咕咚，马上就要发布了，嗯。这是这一年最大的事，最欣慰的事，最期待的事。每天讲故事时的胎动，想想就开心。</p><p>这一年，又一次换了住处，方便老婆上下班，方便照顾即将迎来的小生命。</p><p>这一年，倾其所有，负债累累，搞了一个户口本。算是给自己一个交代，给老婆一个交代，给孩子一个交代。</p><p>这一年，去支援产品开发，在忙死、累死的背后，看到更多的是无谓的加班加点，是管理混乱导致，更深层还是制度使然。制度对人的塑造程度达到惊人的可怕地步。</p><p>这一年，原有的坚持慢慢被消磨殆尽，就连周末都难以再拾起运动，拿起书本。纵使记得“身体与灵魂必须有一个在修bug”，身心俱疲之下难以做到身体力行。</p><p>2017年，首要的任务是多赚钱，多赚钱，多赚钱。</p><p>2017年，我希望锻炼强大的内心，纵使心累，仍不忘坚持初心。</p><p>2017年，我仍希望坚持锻炼，保证健康的体魄。</p><p>2017年，我仍希望坚持读书，保证知识的宽度。</p><p>2017年，我仍希望坚持学习，保证技术的深度。</p><p>2017年，带着孩子，一起欣赏花花草草，虫鱼鸟兽，世间万物，锦绣繁华。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;时间过得很快，转眼又是一年过去了。我还记得年初给老大们分享外企与私企工作异同时，有这样一个观点：所谓人傻钱多活少，并不是一个良好的状态，上班整天无所事事，下班一样也无所事事，看似有大把的时间，在这样的状态下，有再多的时间还是啥也不想干。&lt;/p&gt;
&lt;p&gt;这一年，不是产品合作开</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>从免费抽奖到一元众筹</title>
    <link href="http://blog.cuicc.com/blog/2016/03/27/free-lottery-vs-one-cny-crowdfunding/"/>
    <id>http://blog.cuicc.com/blog/2016/03/27/free-lottery-vs-one-cny-crowdfunding/</id>
    <published>2016-03-27T06:28:22.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现一个很有意思的转变，互联网平台或商家开始搞“一元众筹”推广模式，各商家的叫法不一，但玩法是一样的：一块钱参与抽奖，每到一定人数(通常是商品的售价)，抽取一人获奖得到该商品。那么相对于原来的免费抽奖，除了一块钱还有什么不一样呢？我尝试从以下几个方面对比一下:</p><span id="more"></span><h3 id="免费抽奖"><a class="header-anchor" href="#免费抽奖"></a>免费抽奖</h3><ul><li>推广模式：商家或平台提供奖品，参与抽奖获得一个抽奖号，分享到微博微信等社交平台额外获取多个抽奖号。</li><li>推广成本：从长期来看这是一笔不小的广告费。</li><li>用户心态：对用户来说，通常毫不犹豫地点击按钮参与抽奖，并且参与人数众多，热门奖品通常数十万人，抽到的概率很小。因为免费，用户可能对商家或平台几乎没有啥关注，仅仅为了抽奖而已。</li><li>推广收益：可以快速提高注册用户量。可能初期推广效果比较好。利于融资？</li></ul><h3 id="一元众筹"><a class="header-anchor" href="#一元众筹"></a>一元众筹</h3><ul><li>推广模式：用户一块钱买一个抽奖号，每到一定人数(通常是商品的售价)，众筹成功，从中抽取一人获得奖品。同时每次参与可获取一定的优惠券(比如5元优惠券)。</li><li>推广成本：充分利用众筹这一概念，不用付出成本。</li><li>用户心态：用户肯付出一元的成本，通常会考虑是否有在该商家或平台消费的可能性，优惠券的作用。</li><li>推广收益：筛选用户，增加目标用户转化率和用户粘性。</li></ul><h3 id="一元众筹平台"><a class="header-anchor" href="#一元众筹平台"></a>一元众筹平台</h3><p>在写这篇文章的时候，google了一下，发现有好多专门做低额众筹的平台。玩法和上述基本一样，不同的是只是纯众筹而已，没有优惠券返还，众筹份额不一定是一元。<br>好奇这些平台如何盈利呢？简单对比了几个商品，这些平台上奖品众筹价比实际售价高出不少，只要卖出去就可以稳赚不赔。这应该是这类平台的盈利模式吧。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近发现一个很有意思的转变，互联网平台或商家开始搞“一元众筹”推广模式，各商家的叫法不一，但玩法是一样的：一块钱参与抽奖，每到一定人数(通常是商品的售价)，抽取一人获奖得到该商品。那么相对于原来的免费抽奖，除了一块钱还有什么不一样呢？我尝试从以下几个方面对比一下:&lt;/p&gt;</summary>
    
    
    
    <category term="业界追踪" scheme="http://blog.cuicc.com/categories/%E4%B8%9A%E7%95%8C%E8%BF%BD%E8%B8%AA/"/>
    
    
    <category term="众筹" scheme="http://blog.cuicc.com/tags/%E4%BC%97%E7%AD%B9/"/>
    
    <category term="营销" scheme="http://blog.cuicc.com/tags/%E8%90%A5%E9%94%80/"/>
    
  </entry>
  
  <entry>
    <title>我的2015个人总结</title>
    <link href="http://blog.cuicc.com/blog/2016/01/02/my-personal-review-2015/"/>
    <id>http://blog.cuicc.com/blog/2016/01/02/my-personal-review-2015/</id>
    <published>2016-01-02T13:28:52.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>2015年对我来讲，是不太顺利的一年，经历了各种不好的事。人未三十而立，却已尝尽人生百态的感觉。</p><p>年初制定的计划，完成的并不好，甚至已经看不懂当初的简写是啥了，惭愧惭愧。这也和当初的目标太笼统有关。</p><p>这一年，坚持读书，时有断续，也看了好些本书，一些晦涩的书或者英文原版书看了看了开头挖了坑，一直没有填上。有小说，有科幻，有经济，有科普。</p><p>这一年，最欣慰的是坚持锻炼身体，唯一坚持到现在的一件事。无论是从P4P的level 1到疯狂level 2，还是转战到keep，一直打卡保持到现在。无论锻炼些什么，总之身体状态感觉还不错。希望能一直坚持下去。</p><p>这一年，经过一年的漫长等待，老婆的肺部阴影终于消失不见。差点喜极而泣！一年的原因不明，一年的担忧忐忑，终于在最后这一刻都放下。</p><p>这一年，也曾动摇过换个看似比较有前途的职业，不管是没有相关工作经验，还是开价太高，结果还是没有走出去。想开了也好，新兴也好，传统也好，都是为了生活，努力做好每一份工作吧。</p><p>这一年，前前后后经历过很多项目，总结了一些思考，但总感觉有点单薄，无法形成自己的方法论。虽不能左右大环境，希望可以形成自己的方法论，不求指导别人，但求指导自己。</p><p>这一年，还是无法平静自己的内心，每当夜深人静，还时常想起过去的一些事。一直耿耿于怀，多想再多几年时光可以陪在家人身旁。</p><p>2016年，我希望能够坚持运动，健康生活从每一天开始。</p><p>2016年，我希望能像坚持运动一样坚持读几本有意思的书。</p><p>2016年，我希望能够每段时间学习一样新东西，领域不限，先从感兴趣的开始。</p><p>2016年，我希望能安定下来，能够基于2.0版本开发出2.1版本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;2015年对我来讲，是不太顺利的一年，经历了各种不好的事。人未三十而立，却已尝尽人生百态的感觉。&lt;/p&gt;
&lt;p&gt;年初制定的计划，完成的并不好，甚至已经看不懂当初的简写是啥了，惭愧惭愧。这也和当初的目标太笼统有关。&lt;/p&gt;
&lt;p&gt;这一年，坚持读书，时有断续，也看了好些本书，一</summary>
      
    
    
    
    <category term="生活记录" scheme="http://blog.cuicc.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="总结" scheme="http://blog.cuicc.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>技术开发的一些思考</title>
    <link href="http://blog.cuicc.com/blog/2015/12/06/thinking-about-technoloy-development/"/>
    <id>http://blog.cuicc.com/blog/2015/12/06/thinking-about-technoloy-development/</id>
    <published>2015-12-06T08:52:35.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<h3 id="技术开发是什么"><a class="header-anchor" href="#技术开发是什么"></a>技术开发是什么</h3><p>维基百科上没有相关词条，百度百科解释如下：</p><blockquote><p>技术开发（Technical Development）是把研究所得到的发现或一般科学知识应用于产品和工艺上的技术活动。 工业企业技术开发的对象主要有：产品的开发、设备与工具的开发、生产工艺的开发、能源与原材料的开发、改善环境的技术开发等。不同的企业可根据不同的情况选择技术开发的重点。</p><footer><strong>技术开发</strong><cite><a href="http://baike.baidu.com/view/1273954.htm">百度百科</a></cite></footer></blockquote><p>归纳总结一下，现在的技术开发无外乎以下两点：</p><ol><li>发明创造新技术解决(潜在)问题</li><li>组合现有前沿技术解决(潜在)问题</li></ol><p>对大多数企业来说，大多数时候都是在用第2点。能够做到第1点的少之又少。</p><span id="more"></span><h3 id="技术开发做什么"><a class="header-anchor" href="#技术开发做什么"></a>技术开发做什么</h3><p>我所理解的技术开发要快速做出产品原型，验证是否可用于正式产品中。基于这个理解，技术开发需要做以下两点：</p><ol><li>可行性验证，验证该技术方案是否可行，能否达到需求的目标</li><li>可用性实施，在可行性基础上，该技术方案能否易于实施，达到可用易用的程度。</li></ol><p><em>对产品实践来说，真正的技术积累来自于可用性，可行性无法识别问题点</em></p><h3 id="技术开发问题点"><a class="header-anchor" href="#技术开发问题点"></a>技术开发问题点</h3><p>通常我们的开发方式，我们的架构演进方式是：</p><ol><li>先实现，先达到需求的目标</li><li>再优化，优化设计不好的地方</li><li>服务化，服务化改造</li><li>合适化，选择合适的技术实现</li></ol><h4 id="我们遇到的问题"><a class="header-anchor" href="#我们遇到的问题"></a>我们遇到的问题</h4><ol><li>只有大饼，没有实施目标</li><li>大饼的概念，大饼的概念图，怎么做饼？</li><li>SE/项目经理职责不明确<ol><li>目标具体化及分解</li><li>软件架构设计</li></ol></li><li>项目经理太弱势<ol><li>项目实施决策</li><li>技术背景权威</li><li>迭代划分实施</li><li>责任划分跟踪</li><li>迭代目标评估</li></ol></li><li>不思求变<ol><li>历史包袱太重，如何平衡兼容与创新</li><li>拥抱先进生产力工具，提高效率</li></ol></li></ol><h4 id="结果如何"><a class="header-anchor" href="#结果如何"></a>结果如何</h4><ol><li>原型基本就是过家家</li><li>假装能以及解决了问题</li><li>自以为做的很高大上</li><li>盲目追求/包装新概念</li></ol><h3 id="技术开发怎么做"><a class="header-anchor" href="#技术开发怎么做"></a>技术开发怎么做</h3><p>回到最初的看法，把技术开发团队想象成是一家创业公司，应该怎么做。</p><p>从想法/需求到快速实现原型，到投入市场验证，到不断迭代优化，到用户体验良好的产品。</p><p>对于我们来说，看起来是这样的：</p><ol><li>需求分析出明确目标，目标分解，架构设计，迭代划分</li><li>从原型最小集出发，每个迭代都是可用的(可投入“市场”验证)</li><li>根据市场反馈，迭代优化，再次循环</li></ol><p>从具体开发来说：</p><ol><li>每次迭代目标对齐，做什么</li><li>每次迭代需求与设计明确</li><li>每次迭代各模块自我充分的分析与设计</li><li>每次迭代完成系统是可以用的，保证这个基本点</li></ol><p><em>暂时想到这么多</em></p><p><em>仅从个人角度看，感觉有点片面，从高层看是否如此呢</em></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;技术开发是什么&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#技术开发是什么&quot;&gt;&lt;/a&gt;技术开发是什么&lt;/h3&gt;
&lt;p&gt;维基百科上没有相关词条，百度百科解释如下：&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;技术开发（Technical Development）是把研究所得到的发现或一般科学知识应用于产品和工艺上的技术活动。 工业企业技术开发的对象主要有：产品的开发、设备与工具的开发、生产工艺的开发、能源与原材料的开发、改善环境的技术开发等。不同的企业可根据不同的情况选择技术开发的重点。&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;技术开发&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;http://baike.baidu.com/view/1273954.htm&quot;&gt;百度百科&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;归纳总结一下，现在的技术开发无外乎以下两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;发明创造新技术解决(潜在)问题&lt;/li&gt;
&lt;li&gt;组合现有前沿技术解决(潜在)问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对大多数企业来说，大多数时候都是在用第2点。能够做到第1点的少之又少。&lt;/p&gt;</summary>
    
    
    
    <category term="职场感悟" scheme="http://blog.cuicc.com/categories/%E8%81%8C%E5%9C%BA%E6%84%9F%E6%82%9F/"/>
    
    
    <category term="technology" scheme="http://blog.cuicc.com/tags/technology/"/>
    
  </entry>
  
  <entry>
    <title>tips for git submodule</title>
    <link href="http://blog.cuicc.com/blog/2015/10/25/tips-for-git-submodule/"/>
    <id>http://blog.cuicc.com/blog/2015/10/25/tips-for-git-submodule/</id>
    <published>2015-10-25T06:41:56.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>近来使用<code>git submodule</code>来管理项目，趟过一些坑，整理记录一下。</p><p>##为啥使用submodule</p><p>Git官网如是说，简单的说，就是在引入第三方库时，或者一些公共模块的管理时，可以使用submodule，既单独管理更新，又能很方便的引入使用。</p><blockquote><p>A submodule allows you to keep another Git repository in a subdirectory of your repository. The other repository has its own history, which does not interfere with the history of the current repository. This can be used to have external dependencies such as third party libraries for example.</p><footer><strong>Git</strong><cite><a href="https://git-scm.com/docs/git-submodule">git-submodule Document</a></cite></footer></blockquote><span id="more"></span><p>##Add submodule</p><p>在一个repo中加入submodule的命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] add [-b &lt;branch&gt;] [-f|--force] [--name &lt;name&gt;]</span><br><span class="line">              [--reference &lt;repository&gt;] [--depth &lt;depth&gt;] [--] &lt;repository&gt; [&lt;path&gt;]</span><br></pre></td></tr></table></figure><p>在add一个submodule之后，在当前repo下便会生成一个<code>.gitmodules</code>文件，该文件记录submodule的相关信息，其内容如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[submodule &quot;submodule-name&quot;]</span><br><span class="line">        path = path name</span><br><span class="line">        url = https://github.com/submodule-name.git</span><br></pre></td></tr></table></figure><p>##update submodule</p><p>clone一个repo后，其submodule只会显示一个目录，其内容是空的，这时需要update各个submodule，其命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] init [--] [&lt;path&gt;…​]</span><br><span class="line">git submodule [--quiet] update [--init] [--remote] [-N|--no-fetch]</span><br><span class="line">              [-f|--force] [--rebase|--merge] [--reference &lt;repository&gt;]</span><br><span class="line">              [--depth &lt;depth&gt;] [--recursive] [--] [&lt;path&gt;…​]</span><br></pre></td></tr></table></figure><p>更新操作需要先init以下，然后再update。该两个操作也可以合并为一个命令完成，就是在update时加入<code>--init</code>参数。</p><p>如果需要从远程repo中update submodule，需要在update时加入<code>--remote</code>参数，这样会pull下来server上的最新版。</p><p>##modify submodule repo</p><p>更改submodule的repo地址，没有直接的命令可以完成，需要修改前面提到的<code>.gitmodules</code>文件，将<code>url</code>改成要更改成的repo地址。然后执行如下命令</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule [--quiet] sync [--recursive] [--] [&lt;path&gt;…​]</span><br></pre></td></tr></table></figure><p>##remove submodule</p><p>删除submodule的命令的过程比较繁多，需要多个命令才能完成，其命令如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mv asubmodule asubmodule_tmp</span><br><span class="line">git submodule [--quiet] deinit [-f|--force] [--] &lt;path&gt;…​   </span><br><span class="line">git rm asubmodule</span><br><span class="line"># if you want to leave it in your working tree</span><br><span class="line">git rm --cached asubmodule</span><br><span class="line">mv asubmodule_tmp asubmodule</span><br><span class="line">rm -rf .git/modules/asubmodule</span><br></pre></td></tr></table></figure><p>##modify submodule content</p><p>update之后的submodule是不属于任何一个branch的，也就是无branch的。submodule的HEAD是处于<code>detached HEAD</code>状态的。这样，如果要更改submodule的内容，需要首先切换到要更新的branch，然后按正常的git流程add/commit/pull/push等操作。</p><p>如果直接修改了submodule的内容，然后commit了该修改，那么在push时会出现up-to-update的情况。这时可以用如下命令挽救</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yygcui@ubuntu$ git checkout master</span><br><span class="line">Warning: you are leaving 1 commit behind, not connected to</span><br><span class="line">any of your branches:</span><br><span class="line"></span><br><span class="line">  &lt;commit id&gt; forget to check out master</span><br><span class="line"></span><br><span class="line">If you want to keep them by creating a new branch, this may be a good time</span><br><span class="line">to do so with:</span><br><span class="line"></span><br><span class="line"> git branch new_branch_name &lt;commit id&gt;</span><br><span class="line"></span><br><span class="line">Switched to branch &#x27;master&#x27;</span><br><span class="line">yygcui@ubuntu$ git cherry-pick &lt;commit id&gt;</span><br><span class="line">yygcui@ubuntu$ git push</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;近来使用&lt;code&gt;git submodule&lt;/code&gt;来管理项目，趟过一些坑，整理记录一下。&lt;/p&gt;
&lt;p&gt;##为啥使用submodule&lt;/p&gt;
&lt;p&gt;Git官网如是说，简单的说，就是在引入第三方库时，或者一些公共模块的管理时，可以使用submodule，既单独管理更新，又能很方便的引入使用。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;A submodule allows you to keep another Git repository in a subdirectory of your repository. The other repository has its own history, which does not interfere with the history of the current repository. This can be used to have external dependencies such as third party libraries for example.&lt;/p&gt;
&lt;footer&gt;&lt;strong&gt;Git&lt;/strong&gt;&lt;cite&gt;&lt;a href=&quot;https://git-scm.com/docs/git-submodule&quot;&gt;git-submodule Document&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="git" scheme="http://blog.cuicc.com/tags/git/"/>
    
    <category term="submodule" scheme="http://blog.cuicc.com/tags/submodule/"/>
    
  </entry>
  
  <entry>
    <title>mysql掉电后无法启动 InnoDB: is in the future!</title>
    <link href="http://blog.cuicc.com/blog/2015/10/12/mysql-can-not-startup-after-loss-power/"/>
    <id>http://blog.cuicc.com/blog/2015/10/12/mysql-can-not-startup-after-loss-power/</id>
    <published>2015-10-12T13:59:26.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>公司在节假日会断电，十一忘记了关掉服务器，openstack在系统非正常关机后，无法启动。看了下日志，发现是其使用的mysql起不来。该数据库存储了所有的虚拟机相关信息，若是修复不好，损失惨重啊(别问我为什么没备份，我也不知道…)</p><p>分析mysql启动失败的原因，只能从log入手了，打开log发现最后的日志是</p><span id="more"></span><figure class="highlight bash"><figcaption><span>mysql.log</span></figcaption><table><tr><td class="code"><pre><span class="line">error: <span class="string">&#x27;Can&#x27;</span>t connect to <span class="built_in">local</span> MySQL server through socket <span class="string">&#x27;/var/run/mysqld/mysqld.sock&#x27;</span> (2)<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check that mysqld is running and that the socket: &#x27;</span>/var/run/mysqld/mysqld.sock<span class="string">&#x27; exists!</span></span><br></pre></td></tr></table></figure><p>根据log查看了下，mysqld.sock是存在。google了下这个error，根据一些文档试了下，发现根本没有什么作用，也就是说这可能不是出错的原因。只好继续向前翻log，发现每次试图启动mysql时，都有大量如下日志，我怀疑是因为突然掉电，导致有些log没有写入系统，所以出现了序列号不一致情况。</p><figure class="highlight bash"><figcaption><span>mysql.log</span></figcaption><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">InnoDB: Error: page 570 <span class="built_in">log</span> sequence number 7289495</span><br><span class="line">InnoDB: is <span class="keyword">in</span> the future! Current system <span class="built_in">log</span> sequence number 5574939.</span><br><span class="line">InnoDB: Your database may be corrupt or you may have copied the InnoDB</span><br><span class="line">InnoDB: tablespace but not the InnoDB <span class="built_in">log</span> files. See</span><br><span class="line">InnoDB: http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html</span><br><span class="line">InnoDB: <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure><p>再次google这个error，发现了这样的一篇博文<a href="https://boknowsit.wordpress.com/2012/12/22/mysql-log-is-in-the-future/">MySQL log is in the future!</a>，这篇博文的方法简单易懂，但是首要问题是我的mysql无法启动，无法启动就不能备份数据。同时也看了下log中提到的<a href="http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html">Forcing InnoDB Recovery</a>。</p><p>Forcing InnoDB Recovery提供了6个等级的修复模式，需要注意的是值大于3的时候，会对数据文件造成永久的破坏，不可恢复。六个等级的介绍摘抄如下：</p><figure class="highlight plaintext"><figcaption><span>Forcing InnoDB Recovery</span></figcaption><table><tr><td class="code"><pre><span class="line">1 (SRV_FORCE_IGNORE_CORRUPT)</span><br><span class="line"></span><br><span class="line">Lets the server run even if it detects a corrupt page. Tries to make SELECT * FROM tbl_name jump over corrupt index records and pages, which helps in dumping tables.</span><br><span class="line"></span><br><span class="line">2 (SRV_FORCE_NO_BACKGROUND)</span><br><span class="line"></span><br><span class="line">Prevents the master thread and any purge threads from running. If a crash would occur during the purge operation, this recovery value prevents it.</span><br><span class="line"></span><br><span class="line">3 (SRV_FORCE_NO_TRX_UNDO)</span><br><span class="line"></span><br><span class="line">Does not run transaction rollbacks after crash recovery.</span><br><span class="line"></span><br><span class="line">4 (SRV_FORCE_NO_IBUF_MERGE)</span><br><span class="line"></span><br><span class="line">Prevents insert buffer merge operations. If they would cause a crash, does not do them. Does not calculate table statistics. This value can permanently corrupt data files. After using this value, be prepared to drop and recreate all secondary indexes.</span><br><span class="line"></span><br><span class="line">5 (SRV_FORCE_NO_UNDO_LOG_SCAN)</span><br><span class="line"></span><br><span class="line">Does not look at undo logs when starting the database: InnoDB treats even incomplete transactions as committed. This value can permanently corrupt data files.</span><br><span class="line"></span><br><span class="line">6 (SRV_FORCE_NO_LOG_REDO)</span><br><span class="line"></span><br><span class="line">Does not do the redo log roll-forward in connection with recovery. This value can permanently corrupt data files. Leaves database pages in an obsolete state, which in turn may introduce more corruption into B-trees and other database structures.</span><br></pre></td></tr></table></figure><p>使用方法如下，在mysql配置文件中，添加或修改以下配置的值</p><figure class="highlight bash"><figcaption><span>my.cnf</span></figcaption><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_force_recovery = 1</span><br></pre></td></tr></table></figure><p>根据查到的博文提到的方法，我的修复步骤如下：</p><ul><li>因为我无法启动mysql，所以首先要想办法启动mysql，然后dump数据。从innodb_force_recovery的值1开始尝试，看mysql能否在该修复模式下启动，不到万不得已，不要尝试值为4及以上。</li><li>在我这里，mysql在值为2时可以启动，这是stop掉数据库，然后备份数据</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> service mysql stop</span><br><span class="line">mysqldump -u root -p --all-databases &gt; all-databases.sql</span><br></pre></td></tr></table></figure> <ul><li>删除掉出错的数据文件</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> ib_logfile0 ib_logfile0.bak</span><br><span class="line"><span class="built_in">mv</span> ib_logfile1 ib_logfile1.bak</span><br><span class="line"><span class="built_in">mv</span> ibdata1 ibdata1.bak</span><br></pre></td></tr></table></figure><ul><li>启动mysql，然后从备份文件恢复数据</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> service mysql start</span><br><span class="line">mysql -u root -p &lt; all-databases.sql</span><br></pre></td></tr></table></figure><ul><li>因为在修复模式下，在插入数据时报错，也就是说此时是不能写入数据的。所以就关闭掉了修复模式</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">innodb_force_recovery = 0</span><br></pre></td></tr></table></figure><p>restart mysql后，再次恢复数据</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> service mysql restart</span><br><span class="line">mysql -u root -p &lt; all-databases.sql</span><br></pre></td></tr></table></figure><ul><li>再次重启下mysql，现在mysql可以正常启动了，并且数据也回复成功。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;公司在节假日会断电，十一忘记了关掉服务器，openstack在系统非正常关机后，无法启动。看了下日志，发现是其使用的mysql起不来。该数据库存储了所有的虚拟机相关信息，若是修复不好，损失惨重啊(别问我为什么没备份，我也不知道…)&lt;/p&gt;
&lt;p&gt;分析mysql启动失败的原因，只能从log入手了，打开log发现最后的日志是&lt;/p&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="mysql" scheme="http://blog.cuicc.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>容器化编译和部署</title>
    <link href="http://blog.cuicc.com/blog/2015/09/20/compile-and-deploy-using-docker/"/>
    <id>http://blog.cuicc.com/blog/2015/09/20/compile-and-deploy-using-docker/</id>
    <published>2015-09-20T08:12:48.000Z</published>
    <updated>2025-03-16T07:58:25.510Z</updated>
    
    <content type="html"><![CDATA[<p>容器不是一个新技术，lxc已经存在了很长时间，但Docker却使它更加方便易用。Docker火了之后，我一直没有明白它为啥这么火，除了它宣称的轻量化之外，还有什么。它能做的事情，虚拟机都可以做，并且虚拟机有更好的隔离性。</p><p>在使用场景上，貌似布道的更多的是环境一致性，即开发、测试、部署环境都能很好的保持一致。而至于在生产环境中使用它有什么好处，除了DevOps所倡导的自动化，简化运维，我就没有其他概念了。</p><p>最近在研究微服务的东西，那么微服务必然需要DevOps，必然也就需要高度自动化。Docker，或者说容器，很好的迎合了这一契机。可以说Docker极大的简化了自动化部署的难度。本文就从最近的实践看一看以前没发现的好处。</p><span id="more"></span><h2 id="用源码直接编译部署"><a class="header-anchor" href="#用源码直接编译部署"></a>用源码直接编译部署</h2><p>这种方式直接从VCS仓库下载源码，安装相关依赖库，然后编译安装，生成Docker镜像。其Dockerfile可能是这样的，以构建运行ubuntu的镜像为例。关于Dockerfile语法等可以参考<a href="https://docs.docker.com/reference/builder/">Dockerfile reference</a></p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    build-essential \</span><br><span class="line">    automake \</span><br><span class="line">    libtool \</span><br><span class="line">    git \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home/ &amp;&amp; git clone http://github.com/yygcui/myapp.git</span><br><span class="line"></span><br><span class="line"># compile and install</span><br><span class="line">RUN cd /home/myapp \</span><br><span class="line">    &amp;&amp; ./configure \</span><br><span class="line">    &amp;&amp; make \</span><br><span class="line">    &amp;&amp; make install \</span><br><span class="line"></span><br><span class="line"># clean source code and some tools </span><br><span class="line">RUN rm -rf /home/myapp \</span><br><span class="line">    &amp;&amp; apt-get remove --purge -y git build-essential automake libtool</span><br><span class="line"></span><br><span class="line"># set run cmd</span><br><span class="line">ENTRYPOINT [&quot;myapp.bin&quot;]</span><br><span class="line">CMD [&quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><p>从Dockerfile流程可以看出，这种方法比较简单直接，省去了软件打包的过程，省去了管理安装包的麻烦，直接安装在构建镜像中。但是也带来了一些缺点，比如为防止源码泄露需要清理，在闭源的情况下，只能发布构建好的镜像；深入一点分析，各种测试结果无法复用，比如集成测试有其他部件出现bug，这可能要重新从头执行整个流程。</p><h2 id="用源码编译成可执行包构建部署"><a class="header-anchor" href="#用源码编译成可执行包构建部署"></a>用源码编译成可执行包构建部署</h2><p>这种思路相当于在上面的基础上进行了编译和部署的分离。分别用不同的镜像来构建。比如编译阶段，我可以预先构建好编译基础镜像，包含基本的编译工具，节省安装时间。而在构建部署阶段，直接用纯净的基础镜像，避免安装不必要的软件包，更利于环境一致性。</p><h3 id="容器化编译"><a class="header-anchor" href="#容器化编译"></a>容器化编译</h3><p>容器化编译可以参考docker本身的编译过程，这里简化一下，该过程需要额外构建以下文件：Makefile(用来自动化容器编译的Makefile，非app的Makefile)，编译脚本，编译镜像(Dockerfile)。</p><p>Makefile主要做了三件事：创建映射目录，构建编译镜像，启动编译容器进行编译。Makefile简单示例如下。</p><figure class="highlight plaintext"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">.PHONY: all</span><br><span class="line"></span><br><span class="line">BIND_DIR := package</span><br><span class="line">DOCKER_MOUNT := $(if $(BIND_DIR),-v &quot;$(CURDIR)/$(BIND_DIR):/home/$(BIND_DIR)&quot;)</span><br><span class="line">DOCKER_IMAGE := myapp-compile</span><br><span class="line">DOCKER_RUN := docker run --rm -it --privileged $(DOCKER_MOUNT) &quot;$(DOCKER_IMAGE)&quot;</span><br><span class="line"></span><br><span class="line">default: all</span><br><span class="line">all: build</span><br><span class="line">    $(DOCKER_RUN) /home/build.sh</span><br><span class="line"></span><br><span class="line">build: package</span><br><span class="line">    docker build -t &quot;$(DOCKER_IMAGE)&quot; .</span><br><span class="line"></span><br><span class="line">package:</span><br><span class="line">    mkdir -p ./package</span><br></pre></td></tr></table></figure><p>编译脚本封装了源码的编译，以及编译后的打包等工作。可执行文件与编译出来的依赖库以及打包文件都放在package目录下，这样在host上也可以访问。</p><figure class="highlight plaintext"><figcaption><span>build.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"># make it like a atom operate</span><br><span class="line">cd /home/myapp \</span><br><span class="line">&amp;&amp; ./configure --prefix=/home/package \</span><br><span class="line">&amp;&amp; make \</span><br><span class="line">&amp;&amp; make install</span><br><span class="line"></span><br><span class="line">#build rpm/deb/tar package if needed</span><br><span class="line">#cd /home/package \</span><br><span class="line">#&amp;&amp; tar -czvf myapp.tar.gz ./bin ./lib ./doc install.sh</span><br></pre></td></tr></table></figure><p>编译镜像的Dockerfile和上面的源码直接编译的差不多，只不过不包括编译部分。同时基础镜像也可以用已经构建好的编译基础镜像。这里只需要安装myapp依赖的库以及相应的下载工具即可。</p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example for compile</span><br><span class="line">FROM ubuntu-compile:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    git \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home/ &amp;&amp; git clone http://github.com/yygcui/myapp.git</span><br><span class="line"></span><br><span class="line">COPY build.sh /home/build.sh</span><br></pre></td></tr></table></figure><p>这样，你的下一步流程可以对该软件包进行各种测试，通过后可以上传到二进制包管理库。后续用到该软件时，都直接从二进制库下载。</p><h3 id="容器化部署"><a class="header-anchor" href="#容器化部署"></a>容器化部署</h3><p>这里部署的概念只是紧接着编译测试后如何构建部署镜像。部署镜像依赖于上一步的二进制包。其Dockerfile可能是这样的。</p><figure class="highlight plaintext"><figcaption><span>Dockerfile</span></figcaption><table><tr><td class="code"><pre><span class="line"># A Dockerfile example for deploy</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER YYGCui&lt;yygcui@cuicc.com&gt;</span><br><span class="line"></span><br><span class="line"># set proxy if needed</span><br><span class="line"># set ubuntu to noninteractive </span><br><span class="line">ENV DEBIAN_FRONTEND noninteractive</span><br><span class="line"></span><br><span class="line"># copy apt-get sources list to image</span><br><span class="line">COPY sources.list /etc/apt/</span><br><span class="line"></span><br><span class="line"># keep ubuntu up-to-date</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get -qqy upgrade</span><br><span class="line"></span><br><span class="line"># install tools for compile</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    wget \</span><br><span class="line">   # and the libraries needed by your app</span><br><span class="line">   --no-install-recommends \</span><br><span class="line">   &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># download your app source code to /home/myapp</span><br><span class="line">RUN cd /home \</span><br><span class="line">    &amp;&amp; wget http://artifactory.com/yygcui/0.0.1/myapp.tar.gz \</span><br><span class="line">    &amp;&amp; tar -xzvf myapp.tar.gz \</span><br><span class="line">    &amp;&amp; cd myapp \</span><br><span class="line">    &amp;&amp; ./install.sh</span><br><span class="line"></span><br><span class="line"># set run cmd</span><br><span class="line">ENTRYPOINT [&quot;myapp.bin&quot;]</span><br><span class="line">CMD [&quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><h2 id="总结一下"><a class="header-anchor" href="#总结一下"></a>总结一下</h2><p>从源码直接构建部署镜像，流程简单易行，自动化比较容易；但高度依赖于测试自动化，在构建的过程中需要完成基本的测试。而且每次都从源码构建，不利于前一步结果的复用(如进程测试、系统测试)。</p><p>容器化编译和容器化部署分成独立的两个过程，更像传统的流程。各种测试结果基本可以复用，但是增加了自动化的难度，管理二进制包的麻烦。</p><p>两种方法最终产生的部署镜像是一样的，具体用哪一种取决于你的构建流程。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;容器不是一个新技术，lxc已经存在了很长时间，但Docker却使它更加方便易用。Docker火了之后，我一直没有明白它为啥这么火，除了它宣称的轻量化之外，还有什么。它能做的事情，虚拟机都可以做，并且虚拟机有更好的隔离性。&lt;/p&gt;
&lt;p&gt;在使用场景上，貌似布道的更多的是环境一致性，即开发、测试、部署环境都能很好的保持一致。而至于在生产环境中使用它有什么好处，除了DevOps所倡导的自动化，简化运维，我就没有其他概念了。&lt;/p&gt;
&lt;p&gt;最近在研究微服务的东西，那么微服务必然需要DevOps，必然也就需要高度自动化。Docker，或者说容器，很好的迎合了这一契机。可以说Docker极大的简化了自动化部署的难度。本文就从最近的实践看一看以前没发现的好处。&lt;/p&gt;</summary>
    
    
    
    <category term="技术积累" scheme="http://blog.cuicc.com/categories/%E6%8A%80%E6%9C%AF%E7%A7%AF%E7%B4%AF/"/>
    
    
    <category term="docker" scheme="http://blog.cuicc.com/tags/docker/"/>
    
    <category term="compile" scheme="http://blog.cuicc.com/tags/compile/"/>
    
    <category term="deploy" scheme="http://blog.cuicc.com/tags/deploy/"/>
    
  </entry>
  
</feed>
